[{"categories":["游记"],"content":"摄影作品和我们的眼睛的区别是什么？","date":"2023-09-03","objectID":"/%E6%91%84%E5%BD%B1%E5%92%8C%E7%9C%BC%E7%9D%9B/","tags":["游记","艺术"],"title":"[游记]摄影和眼睛","uri":"/%E6%91%84%E5%BD%B1%E5%92%8C%E7%9C%BC%E7%9D%9B/"},{"categories":["游记"],"content":"故事要从虎跳峡的一段徒步说起。走过人满为患的虎跳峡主景区之后，我们迅速远离了商业化的景区服务（不到三层楼的台阶居然修了收费的电梯，破坏了自然的景色不论，居然是封闭的，看不到半点峡谷和河流，甚是乏味）和拍游客照的熙熙攘攘的人群之后，心里略有不甘。眼见太阳已经走过了头顶，徒步的心又痒了起来，于是和朋友们驱车继续深入，前往中虎跳。 行车没有多久，一段曲折的山路就出现在了我们面前。路一看就没有完全修好，一眼就能看到夸张的U形弯，不仅狭窄到仅能一车通过，还有很多细碎的石子。我们下车观望，齐齐看向了队伍中驾驶经验丰富的唐，但路线的艰难和我们超长的9座商务车也只让唐无奈地点起了烟。于是我们讨论了几分钟，便留下了一部分体力不足的朋友原地等待，剩下人徒步上山（后来证明了这是极其明智的选择，路上搭到的便车阿姨已经在这条山路上开了19年，高超的驾驶技术和艰难的路况实在令我们汗颜）。 阿姨把我们送到了徒步的起点，茶马客栈。客栈后是三三两两的韩国人和美国人，看来远道而来的不止我们几个朋友。客栈后的玉龙雪山已经被夕阳渲染成了金色，颇为壮观。我们意识到自己来对地方了，便绕过客栈，顺着路标牌走了起来。 徒步路程并不劳累，但却颇具特色。路上有当地的农户，种植了一些蔬菜，我们不禁讨论起这里拉货和盖房子的困难，他们是如何把生活物资运上山。路上还有很多各种语言的路标牌，指向法国人和美国人开的客栈，我们朝着路标望去，却发现是一条蜿蜒的山路，还要攀爬数百米，只能望洋兴叹。再有很多面对圣山的堆叠起来的石片，我们后来才了解到这是一种古老的祈福仪式，在西南地区十分常见。我们一路走走拍拍，每绕过一座山就能看到远处的雪顶金山又近了一点，在愉悦的心情中行程迅速过半。 即使一路已经看过了各种美景，按理来说应该对大多数景色免疫，但是再次穿过一个山头后，我们还是对眼前的景象大为震惊。被劈的几乎垂直的峭壁中间，是一条极其深邃的山涧，里面传出清脆流水的声音，而我们的小路恰到好处地在山涧上方穿过。走过小桥的时候，虽然双腿发软，但是下面的深谷仿佛有一种魔力，让我的眼睛贪婪地搜刮着峡谷中的诸多细节。再补一眼陡峭的山壁，再看看山壁对面的金山当做佐料，一种壮阔的感觉油然而生。 朋友小W忍不住拿起手机，试图把这种壮阔记录下来，但是尝试过各种角度之后，不免垂头丧气，发现拍到的照片似乎表达不出眼前景色的百分之一。是啊，眼前的景色是流动的，我们心中的印象是由一段时间的感受组合而成，相机只能框选其中一部分，自然无法还原。朋友说要是眼睛里有个无限分辨率的摄像机该多好，就可以完整记录我们看到的景色，可惜现在的科技还无法达到。我思考了下，总觉得即使完全如他所说，却还差了一些什么，但又说不上来。 直到云南的行程过去大半年，一次偶然听到一位写生的画家讲起写生和摄影的区别，我才幡然醒悟。这位老师说，“绘画写生可不是去找哪个合适的角度，而是寻找我们感受最深的一个瞬间”，我终于意识到，除了一双无限分辨率和能看到各种角度的大脑记忆，无论如何都无法描述当时的美；因为美不仅仅包含了峭壁、小溪和雪山的各种角度，还包含了流水的声音，徒步过程的愉悦，曲折的上山过程，和朋友在一起欣赏的心情，甚至从嘈杂游客中回归自然的焕然一新，都是我们感受到美的原因，但这似乎是每个人都迥异的感受，是一张照片远远无法表达的信息。这就是摄影和眼睛的区别。 但如果认为静态的图片无法给人带来相同美的感受，也未免过于武断。艺术史已经告诉我们前人做了诸多尝试，比如捕捉瞬间极美感受的印象派，从各种视角去描绘事物本身特点的立体主义，以及描绘内心感情的抽象主义，甚至他们摒弃的写实流派，都是用不同方法试图还原美的成功案例。当产生强烈的美感时，记住美，了解美，思考美，无论是眼前的画面、景物的角度或组合、声音气味还是心情，都可以体现在照片中，让我们的摄影作品也会成为别人的眼睛。 ","date":"2023-09-03","objectID":"/%E6%91%84%E5%BD%B1%E5%92%8C%E7%9C%BC%E7%9D%9B/:0:0","tags":["游记","艺术"],"title":"[游记]摄影和眼睛","uri":"/%E6%91%84%E5%BD%B1%E5%92%8C%E7%9C%BC%E7%9D%9B/"},{"categories":["管理"],"content":"刚毕业的高材生小姜，有着浑厚的知识储备和满怀热情的心脏来到了某厂，在做了一段时间需求后，发现自己对做事靠谱的老司机老梁倍加羡慕；为什么人家有条不紊，好评如潮？自己确手忙脚乱，频频提测delay，加班到深夜？","date":"2022-08-15","objectID":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/","tags":["管理","项目管理"],"title":"[管理]对新人友好的项目管理手册","uri":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/"},{"categories":["管理"],"content":"刚毕业的高材生小姜，有着浑厚的知识储备和满怀热情的心脏来到了某厂，在做了一段时间需求后，发现自己对做事靠谱的老司机倍加羡慕；为什么人家有条不紊，好评如潮？自己确手忙脚乱，频频提测delay，加班到深夜？ 今天我们来帮帮小姜，看看小姜为什么技术扎实，态度积极确总是使不上劲？ （故事仅供参考，切勿对号入座） ","date":"2022-08-15","objectID":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/:0:0","tags":["管理","项目管理"],"title":"[管理]对新人友好的项目管理手册","uri":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/"},{"categories":["管理"],"content":"需求详评 这周产品新提了一个需求，拉了小姜和老梁一起做，在详评会议上： 小姜：听的云里雾里，昏昏欲睡，听产品讲完后准备下来仔细看看代码哪里要改 老梁：对产品频频犀利发问：这个细节A为什么这样做，我感觉体验并不好？我们这个需求预期什么时候上线？是不是倒排？我看到这个项目需要我们合作方A做开发，定容了吗？ 小姜恍然大悟的笔记（详评阶段应该做的）： 敲定需求细节，可以给出自己视角的建议 对产品考虑不周全的需求，结合现状进行扩充 对于欠缺价值的需求点，合理挑战 对于破坏系统设计过大的需求点，提早商量 敲定需求整体节奏和预期上线时间，为做方案做准备 对于涉及到前置依赖的需求，一定要尽早确认好工作节奏 UE稿什么时候出 下游是否已经定容、什么时候完成开发，下游依赖接口什么时候给 ","date":"2022-08-15","objectID":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/:1:0","tags":["管理","项目管理"],"title":"[管理]对新人友好的项目管理手册","uri":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/"},{"categories":["管理"],"content":"技术评审 小姜：往文档里贴了下代码截图片段，告诉大家我要改这里，其他人听的一脸懵 老梁：给了一个完整的方案，涉及到合作方的关注点的内容写的非常详细，获得一致好评 小姜复制了一份老梁的模板： 排期概览（开发、联调、测试、上线的准确时间） 业务背景（问题、目标、收益） 技术方案 设计模块和改动点列举 架构图、流程图、状态机、时序图、ER图 异常情况和处理 AB实验方案 老数据兼容 依赖下游方案 风险点（需求自身风险、产品影响风险、可维护性/效率风险） 存储设计 DB/TCC/MQ/Redis/ES的schema变更 数据量级、key、分片、索引、选型、异常处理 接口文档 http接口定义和使用文档 rpc接口定义和使用文档 服务治理 异常兜底 监控报警 工作量评估 工作拆分和估分 进度计划 自测用例 冒烟测试用例（描述、步骤、期望结果） 希望测试测到的地方 发布计划 MR 发布顺序 ","date":"2022-08-15","objectID":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/:2:0","tags":["管理","项目管理"],"title":"[管理]对新人友好的项目管理手册","uri":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/"},{"categories":["管理"],"content":"开发 评审之后大家迅速都加入了如火如荼的开发当中： 小姜：早早地做完了自己的工作，等着联调。联调前一天突然发现下游依赖的接口还没数据，一问原来是有个工作没有对齐漏掉了，心急如焚 老梁：按照之前拆分的开发计划，列出了一个详细的进度追踪表，可以看到工作分配到的人、完成时间、里程碑，还有风险；提前把问题消灭了，大家笑盈盈进入联调 功能点 开发状态 人力预估 开发者 自测完成 风险记录 功能A 未开始 5 小A 是 暂无 功能A适配 进行中 2 小B 否 下游接口延迟一天 功能B适配 已完成 2 小B 否 功能B 已完成 0.25 小B 否 功能C 已完成 1.5 小C 否 功能C2 已完成 1 小A 否 功能A2 已完成 1 小A 否 距离联调还剩 2 个工作日 当前时间进度 50.0% 当前完成进度 45.1% 小姜恍然大悟的笔记（开发阶段应该做的）： 进度追踪 可视化，有详细追踪进度的记录表，或者通过工具（比如meego）周知大家进度 精细化，工作做尽量细的拆分，到人到天，每天追踪 里程碑，重要的节点设置里程碑 buffer预留，根据同学们的熟练程度和项目的不确定性，留25%~100%的buffer 日会，根据项目的大小可以设置日会/双日会/线上追踪的方法，灵活管理风险 风险管理 提升重要性，多问一句有没有风险，可能会得到意外的答案 提早暴露，在风险还没发生或者刚被发现时就暴露并讨论 及早解决，有进度风险马上协调人力或者改善方案，迅速和产品、测试达成一致，不要拖到最后延期了才解决 前紧后松，前期尽量把进度往前敢，越往后不确定性越大 灵活处理，如果不得已有些次要工作无法完成，可以和测试、产品商量分批提测，不影响主项目进度 小姜的嘀咕：道理我都懂，但是我做拉会的时候总觉得自己在向上汇报；关心别人工作进度、指出别人问题的时候总觉得得罪了同事；自己暴露自己模块的风险的时候总害怕给别人留下不好的印象 老梁：风险是几乎每次跑项目都会发生的，如果发生了我们就要积极应对，克服恐惧的最好方法就是面对恐惧，奥利给！ ","date":"2022-08-15","objectID":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/:3:0","tags":["管理","项目管理"],"title":"[管理]对新人友好的项目管理手册","uri":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/"},{"categories":["管理"],"content":"联调 终于万事俱备只查把代码跑起来了！ 小姜：提前做好了自测，把上游的接口都调了一遍，看着数据没问题，联调完成！结果提测当天，很多地方都没跑通，测试打回提测，delay一天 老梁：拆分了团队内联调、全链路联调，继续用进度会议管理风险。提测当天，自己提前测完了所有冒烟测试用例，并给测试做了showcase，解决了全部问题，顺利提测 小姜恍然大悟的笔记（联调阶段应该做的）： case评审 确认开发、测试、产品理解是否一致，方案互相覆盖 给出开发的改动点和希望测试重点测试的内容 注意需要回归的范围 联调 联调前需要自测完成 团队内部联调，外部依赖可以先mock 全链路联调，从前端用户操作到数据库都保证准确 冒烟测试 提前准备好冒烟测试用例，覆盖主流程 自己跑完冒烟测试用例，推动大家解决所有问题 给开发、产品、测试一起做showcase，记录问题并解决 ","date":"2022-08-15","objectID":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/:4:0","tags":["管理","项目管理"],"title":"[管理]对新人友好的项目管理手册","uri":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/"},{"categories":["管理"],"content":"测试 接力棒交给测试同学后，测试同学非常给力，迅速提出了一堆bug 小姜：测试同学提一个修一个，但是修复的速度始终赶不上bug发现的速度，一会就因为卡顿了测试同学测试而怨声载道，测试同学宣布排期+1天 老梁：和测试同学沟通了P0~P3的优先级，P0为卡顿问题，会在每天下班前保证高优解决；每天下班的时候拉会检查bug修复进度，协助所有同学保障测试进度 小姜恍然大悟的笔记（测试阶段应该做的）： bug优先级沟通和时效保障 提测后2~3天不排需求，留着解决问题（大项目） 此时主owner是测试同学，可以让测试同学主持进度会议 ","date":"2022-08-15","objectID":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/:5:0","tags":["管理","项目管理"],"title":"[管理]对新人友好的项目管理手册","uri":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/"},{"categories":["管理"],"content":"上线 耗时一个多月，剩余工作终于做完，bug也终于收敛。产品、UE验收一遍通过，就等着上线了！ 小姜：搭车上线，上线到一半突然发现日志疯狂打error，原来是有个配置忘记改了，吓出一身冷汗，还好没造成线上事故 老梁：和大家开会做CR，制定发布计划、小心翼翼发布观察，沉稳地完成了上线 小姜恍然大悟的笔记（上线阶段应该做的）： 发布前CR 最好在测试快结束的时候就做CR，而不是合master的时候 重新check代码和产品的功能是否完全一致 对接口QPS和延迟做重新预估 发布计划制定 按照依赖顺序列出发布的模块和负责人 处理好并发和依赖的关系 周知负责人发布时间 发布中 严格执行流水线（内含ppe验证、diff流量、panic检测、强制观察） 做好小流量验证 观察核心监控，包括qps、延时、业务大盘 观察告警群 发布后 预演，大项目可以组织产品、运营、测试、灰度用户做预演 值班，类似618项目，发布后过几天才有大量用户0点涌入，需要值班 ","date":"2022-08-15","objectID":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/:6:0","tags":["管理","项目管理"],"title":"[管理]对新人友好的项目管理手册","uri":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/"},{"categories":["管理"],"content":"复盘 上线了一周，效果貌似还不错。线上零星的几个反馈也平息了，这次需求似乎做完了？ 小姜：终于搞完一个大项目了，下一个！ 老梁：这次项目的效果怎么样？产品效果达标了吗？我们服务的架构有没有被破坏，预期的性能达到了吗？ 小姜复制了一份老梁的模板： 功能复盘 业务数据 设计复盘 当初的设计 实现的和设计的有没有差异？为什么产生了差异？ 上线后，线上的问题和后续迭代，暴露了系统的哪些问题？体现了系统的哪些价值 未来的改进和规划 性能复盘 接口QPS，实际的峰值情况，预估的QPS是否准确 接口延迟，有没有性能隐患 机器、DB负载水位，是否符合预期 问题复盘 产生的原因、行为 影响范围 详细timeline 根因分析（设计、开发、自测环节？流程？监控？系统容错？响应速度？SOP？） 改进措施 经过了这次和老梁一起做项目，小姜终于明白了自己的问题在哪，原来是项目管理啊！不过还好做大项目学到了很多，下次就是靠谱的小姜了~ ","date":"2022-08-15","objectID":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/:7:0","tags":["管理","项目管理"],"title":"[管理]对新人友好的项目管理手册","uri":"/%E5%AF%B9%E6%96%B0%E4%BA%BA%E5%8F%8B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%89%8B%E5%86%8C/"},{"categories":["杂谈"],"content":"折腾了这么久笔记软件，终于有了一个最终的方案，给大家分享下。","date":"2022-08-10","objectID":"/notes/","tags":["杂谈","软件"],"title":"[杂谈]我怎么选择笔记软件","uri":"/notes/"},{"categories":["杂谈"],"content":"折腾了这么久笔记软件，终于有了一个最终的方案，给大家分享下 用过的软件对比 软件 优点 缺点 用途 印象笔记 云/多端 丑，难用，残疾md 手机查看 OneNote 多目录/手写 同步难，没有md 读书、网课笔记 Typora 好看/导出 没有云、收费 离线编辑 马克飞象 比较好看 没有云、收费 离线编辑 Obsdian 比较好看 没有云、不能导出 离线编辑 CmdMarkdown 有云 难看 备份，网页版查看 StackEdit 简单 太卡了 没用 MarginNote 知识图谱 无win 读pdf书 备忘录 多端同步、轻量 格式难用 速记 Notion 多端同步、复杂 md不好用，手写不支持 替代onenote 诉求 支持markdown，且美观 支持Latex，脚注 支持云存储，移动端同步 支持mac/windows/ios/网页版 支持3级目录，支持搜索 支持手写插入 支持网页剪裁 支持离线编辑 可以导出pdf，html 支持代码块，代码块染色，行号 支持大纲 工作流 没有一个通用的工作流，所以我需要根据不同的场景来决定采用哪些软件。 ","date":"2022-08-10","objectID":"/notes/:0:0","tags":["杂谈","软件"],"title":"[杂谈]我怎么选择笔记软件","uri":"/notes/"},{"categories":["杂谈"],"content":"速记 （todo list，check list） 备忘录 ","date":"2022-08-10","objectID":"/notes/:0:1","tags":["杂谈","软件"],"title":"[杂谈]我怎么选择笔记软件","uri":"/notes/"},{"categories":["杂谈"],"content":"写博客 Obsdian -\u003e github -\u003e hugo 版本以Obsdian和git共享的目录为准 云备份以git为准 ","date":"2022-08-10","objectID":"/notes/:0:2","tags":["杂谈","软件"],"title":"[杂谈]我怎么选择笔记软件","uri":"/notes/"},{"categories":["杂谈"],"content":"写不公开的md Obsdian -\u003e Notion ","date":"2022-08-10","objectID":"/notes/:0:3","tags":["杂谈","软件"],"title":"[杂谈]我怎么选择笔记软件","uri":"/notes/"},{"categories":["杂谈"],"content":"写读书笔记、学习笔记 Obsdian -\u003e Notion 或 Notion ","date":"2022-08-10","objectID":"/notes/:0:4","tags":["杂谈","软件"],"title":"[杂谈]我怎么选择笔记软件","uri":"/notes/"},{"categories":["杂谈"],"content":"写笔记（游戏攻略、菜谱、碎片） Notion ","date":"2022-08-10","objectID":"/notes/:0:5","tags":["杂谈","软件"],"title":"[杂谈]我怎么选择笔记软件","uri":"/notes/"},{"categories":["杂谈"],"content":"读书脑图 Margin Note ","date":"2022-08-10","objectID":"/notes/:0:6","tags":["杂谈","软件"],"title":"[杂谈]我怎么选择笔记软件","uri":"/notes/"},{"categories":null,"content":"关于我","date":"2022-07-21","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"现居杭州。曾就职于腾讯、字节，多年服务端开发经验，写一些技术类的东西给自己看（但是可读性很高）。以后多写一些生活的东西。 爱好： 摄影📷 ：Sony α7IV、Nikon F3 风光、棚拍。移步图虫 游戏🎮 ：我的世界、GTA、怪猎、宝可梦、骑砍、空洞骑士、饥荒 电影🎬 ：250刷子，昆汀、姜文、宫崎骏、李安 音乐：古典（巴赫、莫扎特）爵士（冷 大乐队 swing 巴萨诺瓦）民谣摇滚嘻哈 运动：游泳🏊🏻混合泳爱好者 滑雪🏂🏻双修实习生 亚文化：老二次元但不新二次元，油画，赛博朋克，复古，核吧，梦核，超现实 其他：爱吃！必吃榜打卡，有时间就去旅游，尤克里里，钢琴，德式桌游爱好者，折腾nas，游戏王 有什么问题欢迎交流。可以在下面回复或者 QQ:1085912251 ","date":"2022-07-21","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"友链","date":"2022-07-21","objectID":"/freinds/","tags":null,"title":"友链","uri":"/freinds/"},{"categories":null,"content":"欢迎志同道合的、有独立博客的朋友们添加友链，按照下面的格式评论即可。 先加好我，我会回加~ 博客: 子恒的博客 描述：后台、互联网、读书和旅行 网址: https://chestnutheng.cn/ RSS订阅地址（可选）: https://chestnutheng.cn/index.xml 以下是我的朋友们： wangbicong easonzero，很酷的命令行博客 wangzhpp shawnzeng，giligili作者 wendajiang，开源，论文和翻译，C++ 推荐的博客： 胡涂说，「任抛星汉归园圃，留取乾坤盛酒囊」 月神夜的博客 ，网络工程本科大三学生，Web与机器学习 中文独立博客： 中文独立博客 ","date":"2022-07-21","objectID":"/freinds/:0:0","tags":null,"title":"友链","uri":"/freinds/"},{"categories":["互联网"],"content":"笔者曾在腾讯商业化、字节广告变现承担过多年广告后台相关工作，对业界的广告套路和广告架构比较熟悉。本文旨在以尽量容易理解的方式来分享广告相关的知识，来给对广告业务了解较少的同学形成一个基本的认知。","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"笔者曾在腾讯商业化、字节广告变现承担过多年广告后台相关工作，对业界的广告套路和广告架构比较熟悉。本文旨在以尽量容易理解的方式来分享广告相关的知识，来给对广告业务了解较少的同学形成一个基本的认知： 广告是如何赚钱的？ 广告系统的组成是什么样的？ 广告系统有哪些值得学习的策略？ 商业模型 广告在平台内部的“永动机” 用户产品：把平台拉新进来的用户留存，转化成活跃用户 商业化：在活跃用户的浏览行为中插入广告，获得收入 UG：把部分商业化的收入用来拉新、激励，使得有源源不断的新用户进来 广告做的是下面三个人群的生意 用户：需要使用平台的服务，如新闻、推文、博客、视频 广告主：需要构建自己的品牌价值、推销自己的产品等 平台：需要用自己产品的DAU变现 广告业务 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:0:0","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"广告形态 常见的广告形态 硬广 开屏广告 原生开屏广告 信息流广告 搜索广告 软广 图文视频软广 非标 锚点 彩蛋 hashtag DOU+ ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:1:0","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"交易链路 如果广告主想要在多个媒体（网站、广告网络、交易平台）投放广告 ，是一个非常繁琐的过程。因为每一个网站、广告网络、交易平台的媒体购买系统、操作规则不同，需要人工进行调整，费时低效；而且跨渠道媒体购买很可能重复购买同一部分人群。 DSP平台把广告主、代理人员从庞杂的重复手工操作中解放出来。广告主只要在DSP平台投放广告即可，由DSP平台帮助广告在多个媒体投放广告。 同理，如果流量主想在自己的网站流量位置上插入广告，如果自己去招商，也是个非常消耗人力的事情，寻找广告主、和广告主对接、广告主提供的素材匹配自己的广告位都需要很多时间。SSP平台可以快速满足流量主接入广告的需求，帮助流量主快速变现。 名词解释 DSP (Demand-Side Platform)： 需求方平台，可以简单理解为需要采买流量的平台（广告主自建或者第三方技术公司） SSP (Supply-Side Platform)：供应方平台/媒体平台，管理流量和坑位。可以简单理解为流量（抖火西头） DMP (Data Management Platform）：数据管理平台，管理人群，生成定向人群包 ADX (AD Exchange)：程序化广告****交易平台，通过技术对接的方式，支持客户（DSP）进行媒体的流量（用户）采买 ADN (Ad Network )： 广告网络，聚合了大量App内的展示广告资源，主要包含中长尾App流量，帮助广告主实现媒体精准、灵活的投放。汇集了很多媒体的余量 各种公司的布局： ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:2:0","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"行业角色 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:3:0","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"变现公式 **广告收入 = 活跃用户数 * 人均展示数 * 广告负载 *** 广告点击率 * 广告价格 $$（Ad Revenue = DAU * Avg Imps * AdLoad * CTR * AdPrice）$$ 活跃用户数（DAU）：产品每天至少使用产品一次的用户数 人均展示数（Avg Imps）：活跃用户平均每天请求次数 广告负载（AdLoad）：活跃用户中进入广告场景的用户占比，即有可能看到广告的用户比例 广告点击率（CTR）：实际点击广告的次数在整体广告展示次数中的占比，即广告点击率 = 广告点击次数 / 广告展示次数 单次点击广告价格（AdPrice）：每一次广告点击广告平台愿意支付给我们的价格 通过这个收入公式，我们尝试看看能有什么办法提升收入： DAU和用户请求次数不由商业产品控制，由UG保证，商业产品只关注广告位 AdLoad一般不做改动，商业产品会针对新老用户做不同策略 CTR * AdPrice / eCPM *PV / CTR * CVR * AdPrice 是商业产品主要操作的方向（如下图） 提升填充率：无满足要求的广告、请求超时的时候兜底余量 提升展示率：提高用户页面停留时长，预加载大体积广告，提升广告加载速度等 提高点击率：采用原生广告，优化广告素材，增大button和点击区域 提高转化率：双链直达，App自动下载，内跳 广告架构 广告的服务架构和一般推荐的链路非常相似，也分为召回、粗排、精排几层，越往上，数据量级越大，对应的模型越简单，检索速度越快；往下，数据量级迅速下降，对应的模型也更加精准和复杂 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:4:0","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"召回 召回主要负责从千万级的广告计划中快速检索出可以下发的广告候选集。首先要求检索要快，然后要准确（符合广告主要求），最后要足够好（符合用户喜好）。我们分三块看下，其中targeting负责把“好”的广告加入候选，频控负责把“不好”的广告干掉；倒排索引则是检索速度的关键。 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:5:0","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"targeting 在满足定向条件的前提下，从广告全库中获得足够多的「好」候选。 硬要求（人工）：广告主对希望投放的人群有清晰的认知 广告属性：比如限定安卓应用 人群属性：比如限制年龄、性别、地理位置 软要求（算法）：广告主希望广告的效果好，但是没有明确诉求 兴趣定向：用模型预测用户是否对某些类别的长期兴趣 行为定向：用户的短期行为（转发过美妆视频，点击过游戏广告等等） lookalike：给定一组种子用户，根据模型学习找到和这组种子用户相似的用户。种子用户一般由广告主直接提供，比如产品的购买者，下载app的用户email，看过广告主官网页面的人等等 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:5:1","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"频控 频控是一种常见的新鲜度控制策略，可以提高用户对所推荐内容的满意度和广度，有效减轻过度拟合导致推荐越来越窄的问题 防止用户反感/审美疲劳：对同一用户重复曝光同一广告素材的意义不大，还可能导致反感 提升点击率和转化率：节省出来的流量可以投放不同创意的广告，提升广告效果 频控一般有下面几种： send（下发）频控，一般几个小时到一天 show（曝光）频控，补充下发了看不到的情况 dislike（负反馈）频控 还可以做更复杂的策略，比如给用户send了某个ad group里面的一条，或者用户主动dislike了某个ad group里面的一条，会在一定时间内整个组内的广告素材都不会下发 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:5:2","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"倒排索引 如何在数千万的广告计划中快速匹配用户的特征和广告主的诉求呢？倒排索引是广告定向检索的关键。 考虑下面4个广告计划，他们有性别和年龄段两个定向配置 计划1：投男性 计划2：投青年/中年，不可投男性 计划3：投女性，老年 计划4：不可投老年，不可忽略性别 分别构建正定向索引和反定向两个倒排索引，key是定向的维度，value是广告id的bitmap： 特征X不可投 = 正向all - 正向特征命中X + 反向特征命中X 可投广告 = 全集 - (特征1不可投 + 特征2不可投 + …) ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:5:3","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"粗排 粗排的主要目的是在召回的大量数据中对数据进行初筛，缩小到几千的数量级喂给精排。粗排不关心具体的数值，只关心精排的排序，在目标上和精排是一致的。 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:6:0","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"预估 因为最终决定广告价值排序的是精排，所以如果我们把粗排的优化目标和精排设定为完全一致是最好的。但是粗排处理的广告量级显然决定了不能和精排完全一致，必须要设计一个简单版本，来快速处理大量数据。我们考虑几种方案： 也把粗排的排序当做一个二分类问题来看，使用精排的某一个指标：比如只做CVR预估，放弃CTR预估？ 使用精排的弱化版本，比如训练改成离线的？降低性能需求？ 使用另一套简单的预估模型？ 无论是哪种方案，都会带来一些不一致的问题，比如精排里最高打分的TopN还没有来得及打分就被粗排干掉了，这在推荐里是致命的badcase。 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:6:1","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"learning2rank 所以，直接预估的方法是不行的，我们还是要把粗排的目标设定为和精排保持一致，用模型学模型的方法去做。 假如精排的队列有100个排好序的样本，我们可以在前10里面取出一个A，作为好样本。再从后10个取出一个B当做坏样本。粗排的目标，就是要让自己也认为A好于B。越是这样，它就和精排越像，就越能帮精排分担压力。 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:6:2","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"精排 精排会对粗排的结果集做进一步筛选，并对广告素材进行打分，来确定最终的广告展示顺序。 精排是推荐系统的核心，直接对推荐系统的结果负责。推荐系统一般都有一个核心的优化指标，比如在短视频平台上，推荐看的就是观看时长、点赞，而广告看的则是eCPM（出价乘以CTR乘以CVR，参考上面的变现公式）。在电商平台上看的是GMV。线上提升是由线下的一个一个模型提升带来的。比如在广告场景下，既要提升CTR，也要提升CVR，还要改善出价机制，还要考虑隐匿成本（用户体验）。 精排学习的目标的范围一般是所有存在曝光的样本。以点击率（CTR）预估为例，以有曝光但没有点击的是负样本，有曝光也有点击的就是正样本。所以，一般会采取二分类模型来实现精排。 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:7:0","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"CTR预估 我们用一个最简单的LR模型为例子，看看精排怎么解决预估的问题。虽然业界目前采用的模型比这个简单版本要复杂的多得多，但是大多都是在一些特征的选取和加工、模型选取、专门针对模型问题的优化和解决上做工作，我们通过这个简单版依然可以看出一些基本的解决手段： 学习集合：用户的特征，广告的特征，是否点击的历史数据 输入：用户的特征，广告的特征 输出：点击的概率？ 假设点击率和用户特征、广告特征是线性相关的，我们可以给每个特征加个参数w，用历史数据计算w $$f(x) = w_0 + w_1 * 用户性别 + w_2 * 广告颜色 $$ （男，广告是红色，点击） （男，广告是白色，未点击） （女，广告是白色，未点击） 求出每个参数的值后，当有新的用户或者广告进来，就可以用我们的公式算出用户会点击广告的概率，然后把概率大的排在前面 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:7:1","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"计费/竞价 精排在给广告做排序的时候，需要根据广告类型的不同对CTR/CVR做预估，当预估出结果后，计算出预估的eCPM参与竞价。竞价结束后，广告会下发并且曝光，我们的系统再根据广告实际的曝光/点击/转化结合不同的广告类型进行计费，确认广告主的消耗。 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:8:0","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"计费方式 广告系统根据不同广告主的诉求，推出了多种售卖方式，可以让广告主在目标上有偏重和权衡。比如品牌广告，广告主更加在意品牌的曝光，给用户留下深刻印象；效果广告的广告主则只为用户的行为买单，比如下载、购买、注册等实际能产生收益的行为。 广告类型 计费方式 竞价指标 特点 品牌广告 CPT (Cost Per Time) 不参与 包断时段内整个位置，价格高 品牌广告 GD (Guaranteed Delivery) 不参与 购买特定数量，价格较高 效果广告 CPM (Cost Per Mille) eCPM= bid 受众广，但是不精确 效果广告 CPC (Cost Per Click) eCPM = bid * CTR 1. 受众精确 2. 但是和最终转化目标较远，广告主成本不可控 效果广告 CPA (Cost Per Action) eCPM = cpa_bid * CTR * CVR 1. 和转化直接挂钩，对广告主友好 2. 需要广告主回传转化，有作弊风险 3. 转化很低时，平台承担前期成本 效果广告 oCPC (Optimized Cost Per Click) eCPM = cpa_bid * CTR * CVR 1. 按照转化出价，但是按照点击计费（price * CVR） 2. 广告主和平台的利益相对统一 所以 平台风险大 广告主风险大 ←———- —– ———-→ CPA（按转化） oCPC oCPM（按曝光） ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:8:1","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"广告竞价 上面我们讲精排的时候讲过，精排会根据最终的eCPM排序来做出下发哪条广告的决定。那除了用户喜好、广告素材的预估点击率，广告主自己怎么来控制自己的素材可以下发呢？直接的手段就是通过竞价，让自己的出价处在广告主中比较有竞争力的水平。竞价系统做了这样一些工作： 目标1：让广告主觉得公平，没有多收钱 目标2： 广告平台收益最大化 广义一价 最终价格 == 最高用户出价 计算简单，容易理解，也常用于土地拍卖 / 股票市场 无法让广告主能够出内心真实价格。在该机制下，广告主有向下调价的动力。即如果广告主出100元达到了效果，下次可能就会想出90元试试看行不行 广义二价 最终价格 == 出价第二高的用户的出价 考虑两个广告： X (bid $100, eCTR_X = 0.01), Y (bid $80, eCTR_Y = 0.02)。 计算可得： eCPM_X = 100 * 0.01 = 1， eCPM_Y = 80 * 0.02 = 1.6 因为eCPM_Y \u003e eCPM_X， 因此Y赢得竞价。但是在收钱时，Y的每次点击只收取 1 / 0.02 = $50 。代表Y其实只需要出价 $50就可以赢得这次竞价，因此$50对Y而言是公平的价格。 对广告主而言较为公平，能出“内心价” 只适用于一个拍卖位置 策略工程 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:8:2","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"实验 怎么吹都不为过的一种思想，应该是广告系统里每一次新的需求的必经之路。每个用户量足够的产品都应该接入来辅助决策 流量切分，均匀地哈希用户到不同的桶中 建立AB实验，给实验组、对照组的用户打上标签 给实验组的用户生效特殊策略，观察核心指标波动 全量，反转实验，对换实验组和对照组，确保结果正向 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:8:3","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"定向 优点：确保投放到准确的人群上，“不浪费”每一个流量 缺点 向覆盖范围外的人群连触达机会都没有 容易让用户产生疲劳 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:8:4","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["互联网"],"content":"流控 超投问题：当广告计费到达额度，即将下线的时候，广告链路上依然有很多广告在请求、定向、筛选、排序、曝光等等流程中，所以到量的那一瞬间依然会有很多广告在投放状态，产生扣费 如何解决？出价会根据PID算法做适当的调整，来影响eCPM改变排序，以保量的合约广告为例子： 当模型发现某个广告投快了，降低出价，放弃本次展示机会 当模型发现某个广告投慢了，提高出价，pk掉其他合约广告，并且有可能在精排里pk掉后续的竞价广告（如果本次pk失败，下次仍会继续提高出价），最终获得广告展示机会 ","date":"2022-01-04","objectID":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/:8:5","tags":["互联网","广告"],"title":"[互联网]广告业务的前世今生","uri":"/%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"categories":["后台"],"content":"能不能扛得住xx流量？能不能P99达到x毫秒？某操作能不能立即生效？某服务CPU飙升了，某服务OOM了，某服务超时率暴涨了？这些灵魂的质问，其实就是在保障服务端的高并发、高性能、高可用、高一致性等等，是我们服务端同学必备的扎实基本功。","date":"2021-09-28","objectID":"/high_perf_1/","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"如果你在服务端的工区，常常会听到同学们激烈的讨论，包括能不能扛得住xx流量？能不能P99达到x毫秒？某操作能不能立即生效？某服务CPU飙升了，某服务OOM了，某服务超时率暴涨了？ 这些灵魂的质问，其实就是在保障服务端的高并发、高性能、高可用、高一致性等等，是我们服务端同学必备的扎实基本功。 克服系统瓶颈 服务端的代码都跑在各种版本的Linux之上，所以高性能的第一步要和操作系统打交道。我们的服务需要通过操作系统进行I/O、CPU、内存等等设备的使用，同时在使用各种系统调用时避免各种资源的开销过大。 ","date":"2021-09-28","objectID":"/high_perf_1/:0:0","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"零拷贝 认识零拷贝之前，我们先要对Linux系统I/O机制有一定的了解。当我们执行一个write(2)或者read(2)的时候（或者recv和send），什么时候操作系统会执行读写操作？什么时候又最终会落到磁盘上？ 以一个简单的echo服务器为例，我们模拟下每天都在发生的请求和回包： sockfd = socket(...); //打开socket buffer = new buffer(...); //创建buffer while((clientfd = accept(socketfd...)){ // 接收一个请求 read(clientfd, buffer, ...); //从文件内容读到buffer中 write(clientfd, buffer, ...); //将buffer中的内容发送到网络 } 看一下这段代码的拷贝流程（下图）： 数据包到达网卡，网卡进行DMA操作，把网卡寄存器的数据拷贝到内核缓冲区 CPU把内核缓冲区的数据拷贝到用户空间的缓冲区 用户空间处理buffer中的数据（此处不处理） CPU把用户空间的缓冲区的数据拷贝到内核缓冲区 网卡进行DMA操作，把内核缓冲区的数据拷贝到网卡寄存器，发送出去 整个过程触发了4次拷贝（2次CPU，2次DMA），2次系统调用（对应4次上下文切换） （注：DMA(Direct Memory Access)， I/O 设备直接访问内存的一个通道，可以完成数据拷贝，使得CPU 不再参与任何拷贝相关的事情，现在几乎所有的设备都有DMA） ","date":"2021-09-28","objectID":"/high_perf_1/:1:0","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"使用mmap mmap可以把用户空间的内存地址映射到内核空间，这样对用户空间的数据操作可以反映到内核空间，省去了用户空间的一次拷贝： 应用调用mmap，和内核共享缓冲区（只需一次） 数据包到达网卡，网卡进行DMA操作，把网卡寄存器的数据拷贝到内核缓冲区 CPU把接收到的内核缓冲区的数据拷贝到发送的内核缓冲区 网卡进行DMA操作，把内核缓冲区的数据拷贝到网卡寄存器，发送出去 整个过程触发了3次拷贝（1次CPU，2次DMA），2次系统调用（对应4次上下文切换） ","date":"2021-09-28","objectID":"/high_perf_1/:1:1","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"使用sendfile/splice Linux 内核版本 2.1 中实现了一个函数sendfile(2)： 他把read(2)和write(2)合二为一，成为一次系统调用，实现了把一个文件读取并写到另一个文件的语义 系统调用中不再切换回用户态，而是在内核空间中直接把数据拷贝过去（2.4 之后这一步支持了DMA拷贝，实现了CPU零拷贝） 我门看下使用sendfile之后的流程： 整个过程触发了3次拷贝（0次CPU，3次DMA），1次系统调用（对应2次上下文切换） Linux 内核版本 2.6 中实现了一个函数splice(2)，类似sendfile，但是接收/发送方必须有一个文件是管道，通过管道的方式连接发送方和接收方的内核缓冲区，不再需要拷贝（0次CPU，2次DMA，1次系统调用） transferTo（内部调用sendfile）的性能对比： ","date":"2021-09-28","objectID":"/high_perf_1/:1:2","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"对于我们的启发 零拷贝能带来显著的性能提升，目前kafka，nginx默认都开启了零拷贝（大文件传输可以提升60%以上） 部分场景对时效性或者拷贝次数有严格的要求时（比如数据库、消息队列的实现），可以考虑用mmap或者直接I/O，配合自己实现的缓存替代操作系统的缓存方案 拷贝很可能是CPU消耗的主要原因，比如业务代码中的大结构体复制，所以我们要谨慎控制复制操作，尽量使用指针或者引用类型 ","date":"2021-09-28","objectID":"/high_perf_1/:1:3","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"无锁 多线程、多协程、多机器、多地部署是我们服务端实现高并发和强容灾的必备解决方案，这些方案都有一个共性，把数据或者过程分而治之。问题在于，几乎所有的并发场景都会涉及到数据竞争，涉及到共享数据的地方就会涉及到锁，协程有锁，线程有锁，多机部署的服务有分布式锁。 服务中的锁会带来很多问题，随着并发数量的加大，会带来更大的上下文切换、用户态切换的开销，出现CPU飙升且都在做一些无用功的现象，也会导致性能快速下降，甚至还不如单线程模型的效率高。除此以外，各种锁还会带来很高的复杂度，和并发的复杂度相叠加，非常容易出现死锁和各种并发问题。 因此，我们使用锁一定是去解决某种问题而去用的，能无锁就无锁，能轻量级就轻量级。 ","date":"2021-09-28","objectID":"/high_perf_1/:2:0","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"无锁的替代方案 单线程 最简单的方案就是单线程reactor模式，redis、nginx都用了这种方式来避免加锁带来的损耗和复杂性，适用于功能简单的场景。 如图，redis的单线程模型有这么几个部分： 通过I/O多路复用组件来接收请求 把请求解析为任务放入一个串行的任务队列（队列是无锁的） 事件分派器分发事件，若干个处理/回复/应答的事件处理器会处理 如果把事件分派器设计成多消费者模型呢？这时候队列就要加锁了 乐观锁 CAS机制： 三个变量：进行比较的原值A，需要读写的内存位置V，拟写入的新值B func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) 如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。 需要注意的是，CAS失败的时候需要重试，相当于在用户态自旋，所以在频繁写入的场景CAS并不适合，会有较高的性能损耗 例子1：数据库乐观锁 取出记录时，获取当前version 更新时，带上这个version并校验，version不相等则失败，version相等则更新业务字段并给version+1 update table set name = 'Aron', version = version + 1 where id = #{id} and version = #{version}; 例子2：netpoll的轻量级锁，是朴素的if锁的加强版 // 有bug的轻量级锁 if locker == 0 { locker = 1 do somthing... } // netpoll的轻量级锁 type locker struct { // keychain use for lock/unlock/stop operation by who. // 0 means unlock, 1 means locked keychain [total]int32 } func (l *locker) lock(k key) (success bool) { return atomic.CompareAndSwapInt32(\u0026l.keychain[k], 0, 1) } func (l *locker) unlock(k key) { atomic.StoreInt32(\u0026l.keychain[k], 0) } func (l *locker) isUnlock(k key) bool { return atomic.LoadInt32(\u0026l.keychain[k]) == 0 } 无锁结构 开源社区用CAS、搭建了很多无锁的数据结构，包括无锁链表，无锁跳表，无锁队列，无锁的map，无锁的LRU，ringbuffer等等。 MemSQL, RocksDB 用Lock Free Skip List做索引 SQL SERVER用Lock Free B+ Tree做索引 OceanBase 用了大量的无锁queue，无锁容器（B+tree，slide window，hashmap） 除此之外，还有很多近似无锁的结构，大部分情况下都是不需要加锁的： go的sync.Map java的新版cocurrent map 我们用一个例子来感受下无锁结构的思维： // 一个无锁队列的入队操作 void queue_enqueue(Queue *q, gpointer data) { Node *node, *tail, *next; node = g_slice_new(Node); node-\u003edata = data; node-\u003enext = NULL; // 实际上就做了两步： // tail-\u003enext = node // q-\u003etail = node while (TRUE) { tail = q-\u003etail; next = tail-\u003enext; if (tail != q-\u003etail) // tail被修改，重试 continue; if (next != NULL) { // next被其他线程增加了新节点，更新tail并重试 CAS(\u0026q-\u003etail, tail, next); continue; } if (CAS(\u0026tail-\u003enext, null, node) // node被添加到队尾，成功 break; } CAS(\u0026q-\u003etail, tail, node); // 给队尾赋值 } 有兴趣可以看看《C++ Concurrency In Action》里面有无锁结构的入门。还有一些论文可以参考 Yet another implementation of a lock-free circular array queue ","date":"2021-09-28","objectID":"/high_perf_1/:2:1","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"更小的锁粒度 原子操作 很多原子操作是CPU指令集直接支持的，大部分语言都会支持一些原子原语，所以会比加锁要快一些（约10%-20%），比如Go里面的： // 加减 func AddInt32(addr *int32, delta int32) (new int32){} func AddUintptr(addr *uintptr, delta uintptr) (new uintptr){} // CAS func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool){} func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool){} // Load/Store func LoadInt64(addr *int64) (val int64){} func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer){} func StoreInt64(addr *int64, val int64){} func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer){} // atomic.Value var config atomic.Value config.Store(loadConfig()) 细粒度锁 以一个场景举例：有一些用户信息放在一个很大的内存hashmap里，大约有100w条数据，会不断有请求对这些用户信息读，偶尔写 设计1：（map + lock）插入/更新/读取的时候对整个hashmap加锁 设计2：（shard map+lock）hashmap按照用户id的区间分为10个子hashmap，各自持有一把读写锁，每次操作只锁一个子hashmap 设计3：（cocurrent map）只有哈希冲突发生的时候才会对某个哈希桶加锁，没发生冲突的时候用CAS插入头结点 设计4：（sync.Map）两份存储，一份只使用原子操作的数据，和一份冗余了只读数据的加锁数据，实现一定程度上的读写分离，使得大多数读操作和更新操作是原子操作，写入新数据才加锁 类似mysql的行锁、页锁、表锁，不同的粒度会带来不同的性能，粒度越大，性能越差，粒度越小，实现越复杂 ","date":"2021-09-28","objectID":"/high_perf_1/:2:2","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"序列化 序列化是服务端经常用到的操作，无论是数据存储还是数据交互，都需要对对象进行序列化或者反序列化之后才可以使用。同时，序列化也带来了很多的性能问题，序列化较多的服务中约有10~20的CPU消耗在序列化上，所以，序列化的选型也非常重要。 ","date":"2021-09-28","objectID":"/high_perf_1/:3:0","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"序列化的类型 语言内置类型，比如java的 java.io.Serializable ，go的encoding/gob，python的pickle 。这种方法非常方便,可以用很少的额外代码实现内存对象的保存与恢复，且性能非常高。这种方法有几个问题 与特定的编程语言深度绑定，没办法做到通用，其他语言不可读 解码过程会把字符串直接实例化为类，会带来安全问题 数据的版本控制/编解码效率/结构大小往往时候才考虑，不规范 可读的文本类型，比如json，csv和xml。这些编码是文本格式，所以可以直接阅读，在和外部项目组交流的时候非常直观，容易达成共识。同样的，这些方法也有一些问题： 没有固定数据格式，有很多歧义，xml和csv不能区分字符串和数字, json不能区分整数和浮点数 不支持二进制数据，只能通过base64支持，会增大编码大小 太占地方，不够紧凑 二进制类型， 比如thrift，protobuf，msgpack。这些编码都需要一个模式定义文档（IDL）,用于约束数据类型和数据的行为。这些方法有一些很好的特性： IDL本身就是很好的理解数据格式的文档，而且容易实现版本控制，确保大家用最新的协议 IDL可以用来生成静态代码，这样就可以在编译时进行类型检查，鲁棒性更高 IDL中可以写详细的验证规则，比如正则匹配，范围匹配 更紧凑，字段名只有编号 ","date":"2021-09-28","objectID":"/high_perf_1/:3:1","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"性能 字节大小 json编码，81个字节 { \"userName\": \"Martin\", \"favoriteNumber\": 1337, \"interests\": [\"daydreaming\", \"hacking\"] } thrift IDL： struct Person { 1: required string userName, 2: optional i64 favoriteNumber, 3: optional list\u003cstring\u003e interests } thrift编码，34字节 没有字段名，字段名用编号来表示 字段类型和标签号只占用了开头的1个字节 数据都是采用数据长度+数据内容的表示方式，这样-64~63只用一个字节，-8192~8191只占用一个字节，以此类推 速度和资源损耗 速度 protobuf \u003e thrift \u003e json 资源损耗 protobuf \u003c thrift \u003c json 参考benchmark结果： https://github.com/smallnest/gosercomp https://github.com/alecthomas/go_serialization_benchmarks ","date":"2021-09-28","objectID":"/high_perf_1/:3:2","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"选型 一般会有三种情况会使用数据的编解码： 数据库或者其他需要持久化的时候，会把内存对象编码后落入磁盘 RPC和REST API，客户端对请求编码，服务器对请求解码、响应并进行编码，再由客户端解码 使用消息队列等异步消息传递的时候，生产者需要编码，消费者需要解码 我们要考虑几个问题： 可读性：编码是否要求易读？是否有手动编写编码的情况？是否要在日志中简便打印？是否有多个团队需要理解编码方式？ 性能：是否有频繁的编码行为？编码的对象是不是很大？ 可扩展性：编码是否需要经常修改删除，并向前向后兼容？是否需要支持版本控制？ 跨语言支持：客户端是否可能会是不同的语言和操作系统？ 举例： 抖音用户的视频点赞消息，每天有上亿条 抖音某业务需要在数据库中存储extra字段，作为配置信息 服务端需要提供一个给前端用来查个人主页详情的RPC接口 除了序列化方式之外呢？ 序列化/反序列化非常耗时，且重复率高的对象可以缓存起来 即使是json，也有各种针对json场景的极致优化的开源仓库，有时候并不亚于thrift，所以选择lib库很重要 代码中不要做重复的序列化，业务流程上一个优化远远大于基础库的性能优化 结合服务特性 ","date":"2021-09-28","objectID":"/high_perf_1/:3:3","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"池化-预先分配和复用 大家一定都用过很多种池子，线程池、协程池、内存池、对象池、连接池等等，其实都是一类思想，就是预先创造并锁定一批资源，在随后的业务过程中不断复用。就像我们作为工程师，在PM眼里也是一个开发池；预先招好一定人数定好一个方向，组成一个池子，然后不断复用我们去接一个一个需求（类似任务队列），这样减少了招人成本（类似线程/链接/内存创建销毁）。 ","date":"2021-09-28","objectID":"/high_perf_1/:4:0","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"内存池 内存分配的系统调用malloc/new和内存释放的系统调用free/delete，会带来很大的性能损耗，重复分配和释放内存会带来很多的消耗和内存碎片。所以，一些需要手动管理内存的语言（C/C++）发展出了tcmalloc等内存池，自动管理内存的语言或者中间件更是直接内置了内存池的实现，如go，java，memcached等等。 Go的内存池 我们以go的内存管理中内存池的部分为例，看看内存池有哪些思路： Go内存管理 Go内存分配那些事 分配者按大小分级： Page：操作系统内页的整数倍，一般Page大小是8KB。 Span：一组连续的Page被称为Span（2^n个），内存管理的基本单位。 ThreadCache：线程内部的cache，不需要加锁，每种大小的空闲内存块以链表的形式连在一起 CentralCache：所有线程共享的缓存，和ThreadCache结构相同，但是需要加锁 PageHeap：PageHeap是堆内存的抽象，PageHeap存的也是若干链表，链表保存的是Span，当CentralCache没有内存的时，会从PageHeap取，把1个Span拆成若干内存块，添加到对应大小的链表中，当CentralCache内存多的时候，会放回PageHeap 申请者按大小分级：按大小分为 微对象 (0, 16B) 小对象 [16B, 32KB] 大对象 (32KB, +∞) 小对象：计算对象大小，对应到span class，存入span的空闲内存中。如果内存不够，像CentralCache申请，如果还不够，向PageHeap申请 大对象：直接向PageHeap申请，如果不够像操作系统申请 总结：Go内存管理的核心在于分级管理（线程本地、线程共用、堆内存、系统内存逐级申请）和分对象管理（对微对象，小对象，大对象做不同的策略），大而全的完成了语言级内存池的任务 Bigcache的内存池 我们在优化内存申请/释放时间的时候，如果是针对有内存管理的语言，其实也是在优化gc效率。下面通过Bigcache看下内存池的另一种思路： // cacheShard可以被认为是一个map的一个分片 type cacheShard struct { hashmap map[uint64]uint32 // key对应的value在entries中的起始位置 entries queue.BytesQueue // 实际是[]byte，新数据来了后copy到尾部 } 这里面有几个点： 每个cacheShard都是一个map中的一个分片，加锁的时候对分片上读写锁 属性hashmap存放的是key对应的值的偏移量，而不是值的指针（避免被gc扫描，性能能快出40倍） entries是一个非常大的byte数组，存放了map中所有的元素。新加的元素会被放置在byte数组尾部 删除元素后entries里会有很多空洞 对于我们的启发 如果我们在Go里面需要设计一个内存缓存，即便是语言层面给我们提供了兜底的内存池，但是还是需要结合使用场景进行缜密的考虑和设计： 直接用go的map：实现最简单，性能最差 改造go的map：改成shard map+读写锁的方式，实现复杂，性能一般 使用sync.Map：开箱即用，实现简单，但是性能和shard map+读写锁差距不明显 使用bigcache或者groupcache：能兼顾锁粒度、gc等多方面的损耗，性能较高 ","date":"2021-09-28","objectID":"/high_perf_1/:4:1","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"对象池 go提供了语言级对象池sync.Pool ，可以将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能。一般用于多协程需要重复构建的对象，new的代价非常大的时候，我们会使用对象池做对象级的缓存。 一些使用了对象池的组件： fmt包和encoding/json包 开源框架gin中的context RPC框架kitex，比如里面的RPCInfo 以gin为例，看看他是如何复用对象的： engine.pool.New = func() interface{} { return engine.allocateContext() } func (engine *Engine) allocateContext() *Context { return \u0026Context{engine: engine, KeysMutex: \u0026sync.RWMutex{}} } // ServeHTTP conforms to the http.Handler interface. func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { c := engine.pool.Get().(*Context) c.writermem.reset(w) //复用对象要清空 c.Request = req c.reset() engine.handleHTTPRequest(c) engine.pool.Put(c) } 要点： 放入pool的对象会直接复用，gc很高的时候可以用来减少gc负担，rpc收发包的场景有奇效 get到的对象有可能是新的，有可能是老的，要么get之后清空，要么put之前清空 用完后一定要put，有存入才有得对象用 初次之外，redis和java都有常量池、unity中也有用于对物体和动画复用的对象池，这种模式还是比较常见的。 ","date":"2021-09-28","objectID":"/high_perf_1/:4:2","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"连接池 连接池广泛用于解决连接的创建/销毁的成本，现在几乎都默认在可以需要长连接的场景中，包括各种数据库的中间件，rpc的长连接，没有特殊的理由，能用就用。自己实现一个连接池是不推荐的，里面还是有不少细节。 我们以database/sql中的连接池为例，看下需要考虑哪些内容： 获取连接 如果连接池不为空，则直接从池子里面获取连接使用即可 如果连接池为空，且当前连接数\u003emaxConn，则把任务放入等待队列并设置超时时间。 如果连接池为空，且当前连接数\u003cmaxConn，则新建一个新连接。 释放连接 如果等待队列有任务，把连接交给等待的任务，并pop出来 等待队列没任务则放回连接池 连接超时 连接到达maxLifeTime后，连接close掉 连接有效性检测和保活 每次使用前检测连接是否被关闭，被关闭则重连 到达mysql的8小时超时连接后，重连 这里面涉及到三个参数： SetMaxOpenConns 最大连接数，默认无穷大 SetMaxIdleConns 最大空闲连接数，默认为2，就是没任务的时候还会有2个链接空闲等待 SetConnMaxLifeTime 最大链接生存时间 ","date":"2021-09-28","objectID":"/high_perf_1/:4:3","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"线程池 线程也是一种创建和销毁非常消耗资源的结构。因为线程池大家都很熟悉，就不详细展开，想讨论的是一个优秀的线程池应该优化哪些方向。我们看看GMP在Go 1.0时候的版本，非常朴素，和我们手写的第一版线程池非常类似（G是routine，M是工作线程）： 单一全局互斥锁和集中状态存储的存在，导致所有 goroutine 相关操作，如创建、重新调度等都要上锁； routine 传递问题，M 经常在 M 之间传递可运行的 goroutine，这导致调度延迟增大以及额外的性能损耗（比如M’创建了G’，G’是从G中分出来的，G在M上跑，那最好把G’传给M，不然局部性很差，需要拷贝内存）； M之间的切换，会带来很多阻塞线程和取消阻塞的系统调用，开销很大 思考：看到过很多同学的做法，我们在routinue调度器上面套一层协程池，把协程抽象为工作线程，把函数抽象为job，这和第一代GMP是非常相似的，比如： https://github.com/panjf2000/ants ","date":"2021-09-28","objectID":"/high_perf_1/:4:4","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"缓存-空间换时间 单独作为一节 ","date":"2021-09-28","objectID":"/high_perf_1/:5:0","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"异步-同时执行 ","date":"2021-09-28","objectID":"/high_perf_1/:6:0","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"业务流程 业务流程的异步，核心就一句话，有严格先后调用关系的服务保持顺序执行，对于能够同步执行的所有服务均采用异步化方式处理。这种方法应该从设计之初就注意，确保一个流程的执行时间等于最长同步流程的耗时： 上图介绍了一个简单的售后换货的流程。从商家操作，web页面调用换货接口开始，我们把换货记为四个独立的过程，每个过程都可以并行执行；所有过程执行结束后，返回发货结果。这样，这个接口的耗时就等于处理时间最长的四个过程之一的耗时。 除此之外，其他重要性较低的业务逻辑，统一放在异步流程里执行。我们会发送订单状态转换消息、发货消息、售后单状态转换消息来通知所有有关的下游，让他们去自行消费。 ","date":"2021-09-28","objectID":"/high_perf_1/:6:1","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["后台"],"content":"并发模型 共享内存 Java、C++、或者Python，他们线程间通信都是通过共享内存的方式来进行的。非常典型的方式就是，在访问共享数据（例如数组、Map、或者某个结构体或对象）的时候，通过锁来访问，因此，在很多时候，衍生出一种方便操作的数据结构，叫做“线程安全的数据结构”。 Actor模型 Actor是erlang采用的并发模型。它的基本思想是，每个Actor都有一个专用的MailBox来接收消息。当一个Actor实例向另外一个Actor发消息的时候，并非直接调用Actor的方法，而是把消息传递到对应的MailBox里，就好像邮递员，并不是把邮件直接送到收信人手里，而是放进每家的邮箱，这样邮递员就可以快速的进行下一项工作。 Actor用消息取代了函数调用，天生异步 Actor内部无锁，Actor之间物理隔离，互相不影响，只通过消息通信 Actor是一个简单的对象，占用资源很少，万量级的Actor没有问题 CSP CSP（communicating sequential processes）并发模型是Go使用的一种并发模型。它提倡“不要以共享内存的方式来通信，相反，要通过通信来共享内存”，在Go中的实现就是routine和channel。 Go用到了 CSP 理论中的 Process/Channel（对应到语言中的 goroutine/channel）：这两个并发原语之间没有从属关系， Process 可以订阅任意个 Channel，Channel 也并不关心是哪个 Process 在利用它进行通信；Process 围绕 Channel 进行读写，形成一套有序阻塞和可预测的并发模型。 Worker1 --\u003e Channel --\u003e Worker2 ","date":"2021-09-28","objectID":"/high_perf_1/:6:2","tags":["后台","服务端高性能架构之道"],"title":"[后台]服务端高性能架构之道（系统和服务篇）","uri":"/high_perf_1/"},{"categories":["Go"],"content":"本文介绍了Go的语言设计和一些容易踩坑的细节： 理解Go为什么X，摆脱原语言的思维 解决写代码时比较困惑和不满的点，对容易出错的语法有个印象 Go学起来非常简单，但是这是语言设计者刻意为之，很多复杂的细节都藏在语言实现里，导致我们迅速学会Go之后不断踩坑 Why Go 2007年，Google设计Go，目的在于提高在并行编程（多核CPU越来越多）、分布式部署、大型代码库（以及维护他们的非常多的开发人员）的情况下的开发效率。设计时，在吸收C++优点的基础上，收集于很多工程师之间流传的的“不要像C++” Go like C++： 内存消耗少 执行速度快 启动快 Go not like C++： 程序编译时间短（按照我过去的经验，一个C++大型项目即使make -j8也需要编译一个小时以上） 像动态语言一样灵活（runtime、interface、闭包、反射） 内置并发支持（C++的协程至少得等到std23才有，非常落后） 丰富的原生库（C++解析json，建立http服务器，使用redis这种都很难找到靠谱的库） 多语义（取消了指针运算、取消隐式类型转换、取消类型别名，取消重载，++和赋值作为表达式…） Go的优点： 面向工程：简单。只有25个关键字，代码风格统一，可读性高，go mod包丰富 自动垃圾回收：语言运行时内置垃圾回收 语言级并发：非常好用的routine和channel，更高层次的并发抽象 静态语言动态特性 Go的缺点： runtime的性能还需要提高 没有泛型 冗余的错误处理 Go mod不够完善 Go语⾔将⾛向何⽅? 我为什么放弃Go语言 Go的设计哲学 创始人Rob Pike在SPLASH上的演讲，阐述了设计Go的初衷 许式伟，Go和Java在继承观念上的对比 对面向对象的批评 王垠：解密“设计模式”，对设计模式的批评 少即是多（less is more）：如果一个特性并不对解决任何问题有显著价值，那么go就不提供它；如果需要一个特性，那么只有一种方法去实现 面向接口编程：非侵入式接口，反对继承、反对虚函数和虚函数重载（多态）、删除构造和析构函数 正交+组合的语言特性：语言的特性之间相互独立，不相互影响。比如类型和方法是互相独立的，类型之间也是相互独立的，没有子类，包也没有子包。不同特性用组合的方式来松耦合 并发在语言层面支持：并发更好利用多核，有更强的表现力来模拟真实世界 在设计上，Go秉承了C的简单粗暴。 ","date":"2021-02-02","objectID":"/go/:0:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"为什么没有继承？ Go没有子类型的概念，只能把类型嵌入到另一个类型中，所以没有类型系统。Go的作者认为类型系统被过度使用了，应该在这个方向上退一步。 使用伸缩性良好的组合，而不是继承 数据和方法不再绑定在一起，数据的集合用struct，方法的集合用interface，保持正交 类似子类父类的系统造成非常脆弱的代码。类型的层次必须在早期进行设计，通常会是程序设计的第一步，但是一旦写出程序后，早期的决策就很难进行改变了。所以，类型层次结构会促成早期的过度设计，因为程序员要尽力对软件可能需要的各种可能的用法进行预测，不断地为了避免挂一漏万，不断的增加类型和抽象的层次。这种做法有点颠倒了，系统各个部分之间交互的方式本应该随着系统的发展而做出相应的改变，而不应该在一开始就固定下来。 作者附了一个例子，是一些以接口为参数并且其返回结果也是一个接口的函数： // 入参是接口的函数，而不是成员方法 func ReadAll(r io.Reader) ([]byte, error) // 封装器 - 出入参都是接口 func LoggingReader(r io.Reader) io.Reader //读到的内容录入日志 func LimitingReader(r io.Reader, n int64) io.Reader //读n个字节停下来 func ErrorInjector(r io.Reader) io.Reader 这种组合+函数的模式是相当灵活的。如果用继承，我们可能会多三个io.Reader的定义；然后用多态去获得对应的功能 ","date":"2021-02-02","objectID":"/go/:1:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"为什么没有异常？ panic和recover这些函数是故意弄的不好用的，因为我们应该减少使用他们。不像Java库中使用异常那样，在go的库中这两个关键字几乎没有使用。 业务中的错误并不是真正的异常情况，if和return完全可以胜任，无需控制流 如果错误要使用特殊的控制结构，错误处理就会扭曲程序的控制流，非常复杂 显式的错误检查会迫使程序员在错误出现的时候对错误进行思考，并进行相应的处理，而不是推给前面的调用堆栈 毫无疑问这会使代码更长一些，但如此编码带来的清晰度和简单性可以弥补其冗长的缺点 ","date":"2021-02-02","objectID":"/go/:2:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"为什么没有X？ 总结：Go的设计着眼于编程的便利性、编译的速度、概念的正交性以及支持并发和垃圾回收等功能。如果你在Go中找不到其他语言的X特性，那么只能说明这个特性不适合Go，比如它会影响编译速度或设计的清晰度，或者使得基础系统变得特别复杂。 容易出错的细节 ","date":"2021-02-02","objectID":"/go/:3:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"创建对象 新建一个对象在go里面有好几种方法，让人迷惑，而且似乎和简洁这一设计原则违背。我们按照对象类型讨论一下： 对于结构体，new(T)和\u0026T{}是等价的，都会给对象赋零值（一般人很少用new）。 Note：直接var obj T;\u0026T也是等价的，只不过变量有可能在堆上，有可能在栈上 对于slice、map、chan，make(map[string]int)和map[string]int{}等价，会对对象进行初始化。 var a []int // nil a := []int{} // not nil a := *new([]int) // nil a := make([]int,0) // not nil ","date":"2021-02-02","objectID":"/go/:4:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"零值 零值和未初始化的值并不相同。不同类型的零值是什么？ 布尔类型是false，整型是0，字符串是\"\" 指针、函数、interface、slice、channel和map的零值都是nil 结构体的零值是递归生成的，每个成员都是对应的零值 我们来看一个例子。一个为nil的slice和map能做什么操作： // 一个为nil的slice，除了不能索引外，其他的操作都是可以的 // Note: 如果这个slice是个指针，不适用这里的规则 var a []int fmt.Printf(\"len(a):%d, cap(a):%d, a==nil:%v\\n\", len(a),cap(a), a == nil) //0 0 true for _, v := range a{// 不会panic fmt.Println(v) } aa := a[0:0] // 也不会panic，只要索引都是0 // nil的map，我们可以简单把它看成是一个只读的map var b map[string]string if val, ok := b[\"notexist\"];ok{// 不会panic fmt.Println(val) } for k, v := range b{// 不会panic fmt.Println(k,v) } delete(b, \"foo\") // 也不会panic fmt.Printf(\"len(b):%d, b==nil:%v\\n\", len(b), b == nil) // 0 true ","date":"2021-02-02","objectID":"/go/:5:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"值传递 Go语言中所有的传参都是值传递，都是原值的一个副本，或者说一个拷贝。传入的数据能不能在函数内被修改，取决于是不是指针或者含有指针的类型（指针被值传递复制后依然指向同一块地址）。这就让人很疑惑，什么时候传入的参数修改会生效，什么时候不会生效？ slice类型在 值传递的时候len和cap不会变，所以函数内append没有用： type slice struct { array unsafe.Pointer len int cap int } // badcase func appendMe(s []int){ s = append(s, -1) } map 和 chan类型，本来就是个指针，所以函数内修改一定会生效： // map实际上是一个 *hmap func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap { //省略无关代码 } // chan实际上是个 *hchan func makechan(t *chantype, size int64) *hchan { //省略无关代码 } 再比如一个结构体作为参数： // 这是一个典型的指针包裹类型 type Person struct { name string age *int } func modify(x Person){ x.name = \"modified\" *x.age = 66 } 这个结构体里的age是个指针类型，所以在函数内会被修改。 这种含有指针的结构体类型，里面的指针指向了其他的内存。在发生拷贝的时候，只有结构体本身的内存会被拷贝，指向的内存是和原值共享的。 更多细节参考 ：值部 但是我们一般希望的是，要么结构体的成员一起改变（这个简单，参数传person的指针），要么一起不改变（深拷贝）。那么另一个让人头疼的问题来了，那我如何深拷贝这个对象？ ","date":"2021-02-02","objectID":"/go/:6:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"深拷贝 对于slice，go提供了似乎还不错的方式： // 自己复制 s1 := []int{1,2,3} s2 := append([]int{}, s1...) // 效率更高的复制 s1 := []int{1,2,3} s2 := make([]int, len(s1)) copy(s2, s1) 如果你要拷贝一个map，只能用for循环依次把键值对赋值到新map里。 切记：需要拷贝map一定要深拷贝，不然如果后续在不同的协程里操作map会panic 如果有其他更复杂的结构体需要深拷贝呢？目前还没有很好的办法： 自己写一个复制值的函数 用序列化/反序列化的方法来做，json，bson 用反射来做 age := 22 p := \u0026Person{\"Bob\", \u0026age} v := reflect.ValueOf(p).Elem() vp2 := reflect.New(v.Type()) vp2.Elem().Set(v) ","date":"2021-02-02","objectID":"/go/:7:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"小心interface判等 go实现接口的时候有两个属性，type T和value V，判等的时候两个属性都要比较。比如一个interface存了3，那么T=int，v=3。只有当两个值都没有设置才等于nil。 var pi *int = nil var pb *bool = nil var x interface{} = pi var y interface{} = pb var z interface{} = nil fmt.Println(x == y) // false fmt.Println(x == nil) // false fmt.Println(x == z) // false // badcase type error interface { Error() string } func returnsError() error { var p *MyError = nil if bad() { p = ErrBad } return p // Will always return a non-nil error. } 还有一种常见的场景是我们容易漏掉的。int64和int的interface也不相等： var int1,int2 interface{} int1 = int64(0) int2 = int(0) fmt.Printf(\"%v %v = %v\", int1, int2, int1 == int2) // 0 0 false // 如果函数参数用了interface，如果我们很容易犯错 func (m *Map) Load(key, value interface{}) { if e, ok := read.m[key]; ok { ... } } // badcase 1: key的类型不一致导致缓存无法取出 m := sync.Map{} m.Store(0, \"ManualCache\") val, ok := m.Load(int64(0)) // nil false // badcase 2: value的类型不一致导致断言失败 m.Store(\"key\", 0) if val, ok := m.Load(\"key\"); ok { _ = val.(int64) // panic } ","date":"2021-02-02","objectID":"/go/:8:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"点点点 ...是个很常用的语法糖，能帮我们节省很多代码。 用作展开： x := []int{1,2,3} y := []int{4,5,6} x = append(x, y...) //而不是for循环 x = append(x, 4, 5, 6) //等价于上面的 用作可变参数列表： // Println prints to the standard logger in the manner of fmt.Println. func Println(v ...interface{}) { std.Output(2, fmt.Sprintln(v...)) // Output takes parameters (int, string) } 用作简化数组声明： var _ = [...]language{ {\"C\", 1972}, {\"Python\", 1991}, {\"Go\", 2009}, } var b = [...]string{0: \"foo\", 2: \"foo\"} // [3]string{\"foo\", \"\", \"foo\"} ","date":"2021-02-02","objectID":"/go/:9:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"闭包里的局部变量是引用 闭包里起的go协程里面引用的是变量i的地址。所有的go协程启动后等待调用，在上面的协程中，部分协程很可能在for循环完成之后才被调用，所以输出结果很多都是最后一个i的值 // bad case done := make(chan bool) for i := 0; i \u003c 5; i++ { go func() { println(i) done \u003c- true }() } for _ = range values { \u003c-done } // 5 5 5 5 5 // good sample 1 for i := 0; i \u003c 5; i++ { defer func(i int) { println(i) done \u003c- true }(i) } // good sample 2 for i := 0; i \u003c 5; i++ { i := i // 新建变量 go func() { println(i) done \u003c- true }() } //1 3 5 4 2 ","date":"2021-02-02","objectID":"/go/:10:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"不要引用大数组 被切片引用的数据不会被释放（即使你仅仅引用了很小一部分），会大幅降低代码性能 headerMap := make(map[string][]byte) for i := 0; i \u003c 5; i++ { name := \"/path/to/file\" data, err := ioutil.ReadFile(name) if err != nil { log.Fatal(err) } headerMap[name] = data[:1] // better: headerMap[name] = append([]byte{}, data[:1]...) } ","date":"2021-02-02","objectID":"/go/:11:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"赋值不是原子操作 在64位的机器上，赋值很可能被拆成mov两次的汇编代码，因此不是原子的。我们可以用atomic里的方法帮助我们做原子操作。 考虑一个内存cache定时刷新的协程：因为随时有请求在读cache，所以刷新cache的时候需要保证cache的指针存取是原子操作。 举例：mycache *map[string]*Cache // 加载（读取） var _ = (*T)(atomic.LoadPointer((*unsafe.Pointer)(unsafe.Pointer(mycache)))) // 存储（修改） atomic.StorePointer( (*unsafe.Pointer)(unsafe.Pointer(mycache)), unsafe.Pointer(\u0026newMycache)) 所有的操作，只要存在同时存在多个goroutine同时操作一个资源（临界区），除了带有sync，atomic，或者channel关键字的，都不安全。包括但不限于： 并发读写map 并发append切片 自增变量 赋值 ","date":"2021-02-02","objectID":"/go/:12:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"接收器用指针还是值 Go的接收器可以传指针进来，也可以传值。注意传值的时候接收器不会被改变。官方推荐下面两种情况该用指针： MyStruct很大，需要拷贝的成本太高 方法需要修改MyStruct 否则Go推荐使用值接收器 Note：如果对象有可能并发执行方法，指针接收器中可能产生数据竞争，记得加锁 func（s * MyStruct）pointerMethod（）{ // 指针方法 s.Age = -1 // useful } func（s MyStruct）valueMethod（）{ // 值方法 s.Age = -1 // no use } ","date":"2021-02-02","objectID":"/go/:13:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"for循环里的变量都是副本 for key, element = range aContainer {...} 关于上面for循环有几个点： 实际遍历的aContainer是原始值的一个副本 element是遍历到的元素的原始值的一个副本 key和element整个循环都是同一个变量，而不是每次迭代都生成新变量 这里涉及到几个问题。一个是aContainer和element的拷贝成本。aContainer是数组的时候的拷贝成本比较大，而切片和map的拷贝成本比较小。如果想要缩小拷贝成本，我们有几个建议： 遍历大数组时，可以先创建大数组的切片再放在range后面 element结构比较大的时候，直接用下标key遍历，舍弃element 还有一个问题是遍历的时候修改，能不能生效？ 当aContainer是数组时，因为数组是整个复制，所以直接修改aContainer不会生效 直接修改key或者element，？ 因为切片和map是浅复制，在循环中操作aContainer或者aContainer[key]可以生效 因为循环里的副本和函数参数的副本非常类似，所以我们可以参考上面的“值传递”中的内容来判断修改副本是否会使得修改达到想要的效果。 ","date":"2021-02-02","objectID":"/go/:14:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"map的值不可取址 map是哈希表实现的，所以值的地址在哈希表动态调整的时候可能会产生变化。因此。存着map值的地址是没有意义的，go中直接禁止了map的值的取地址。这些类型都不能取址： map元素 string的字节元素 常量（有名常量和字面量都不可以） 中间结果值（函数调用、显式值转换、各种操作） // 下面这几行编译不通过。 _ = \u0026[3]int{2, 3, 5}[0] //字面量 _ = \u0026map[int]bool{1: true}[1] //字面量 const pi = 3.14 _ = \u0026pi //有名常量 m := map[int]bool{1: true} _ = \u0026m[1] //map的value lt := [3]int{2, 3, 5} _ = \u0026lt[1:1] //切片操作 一般来说，一个不可寻址的值的直接部分是不可修改的。但是map的元素是个例外。 map的元素虽然不可寻址，但是每个映射元素可以被整个修改（但不可以被部分修改）： type T struct{age int} mt := map[string]T{} mt[\"John\"] = T{age: 29} // 整体修改是允许的 ma := map[int][5]int{} ma[1] = [5]int{1: 789} // 整体修改是允许的 // 这两个赋值编译不通过，因为部分修改一个映射元素是非法的。这看上去确实有些反直觉。 ma[1][1] = 123 // error mt[\"John\"].age = 30 // error // 读取映射元素的元素或者字段是没问题的。 fmt.Println(ma[1][1]) // 789 fmt.Println(mt[\"John\"].age) // 29 逃逸分析 关心变量在栈或者堆上有助于我们对变量的生命周期有所了解，写出更好性能的代码。比如一些短周期的变量的指针如果和长生命周期的变量绑定，就会使得这个变量迟迟不能回收，影响性能。 Go在栈上的变量不会产生GC成本，因为变量会随着函数的退出一起销毁（当然这样性能也是最高的）。但是，变量是否在栈上，不能简单的通过是否局部变量或者是否使用new构建的引用类型来判断。有一个基本的判断原则： 情况1：如果变量的引用被声明它的函数返回了，那么这个变量就会逃逸到堆上 func ref(z S) *S { return \u0026z } // go run -gcflags '-m -l' main.go ./escape.go:10: moved to heap: z ./escape.go:11: \u0026z escapes to heap 情况2：返回的结构体引用的对象会逃逸 func refStruct(y int) (z S) { z.M = \u0026y return z } // go run -gcflags '-m -l' main.go ./escape.go:12: moved to heap: y ./escape.go:13: \u0026y escapes to heap 情况3：map、slice、chan引用的对象会逃逸 func main() { a := make([]*int,1) b := 12 a[0] = \u0026b } // go run -gcflags '-m -l' maint.go ./maint.go:5:2: moved to heap: b ./maint.go:4:11: make([]*int, 1) does not escape 我们看一个例子，逃逸使得性能下降了不少： func BenchmarkHeap(b *testing.B) { b.ResetTimer() c := make(chan *T, b.N) // c := make(chan T, b.N) for i := 0; i \u003c b.N; i++ { b := T{a: 3, b: 5} c \u003c- \u0026b // c \u003c- b } } // go test -bench=. -run=none BenchmarkStack-12 32297865 32.1 ns/op BenchmarkHeap-12 28062832 40.2 ns/op routine ","date":"2021-02-02","objectID":"/go/:15:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"Golang并发注意点 最好确认routine任务的开销大于上下文切换的开销时，才使用routine。 要尽量控制routine的数量，不然会起到反效果 channel要注意缓冲区的大小和每次写入的数量，尽量打包写入 ","date":"2021-02-02","objectID":"/go/:16:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"防止泄漏 如果routine在运行中被阻塞，或者速度很慢，就会发生泄漏（routine的数量会迅速线性增长） routinue卡死在读取chan却没数据 理想情况下，我们设计的读取chan的routine会把所有的内容读取完毕后才会关闭。但是，一旦读取者在读取完成之前退出，写入方写满chan之后就会卡死。 routinue处理的速度过慢 这个情况有点类似消息队列消费者的堆积，如果新起的routine处理速度比主协程还慢的话，堆积起来的routine会越来越多，最终打爆内存 ","date":"2021-02-02","objectID":"/go/:17:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"复用timer来替代timer.After timer.After会创建很多的timer，引发很大的GC消耗。 // 如果有100w个msg推进来，就会有100w个timer被销毁 func longRunning(messages \u003c-chan string) { for { select { // 消息间隔超过1min会return case \u003c-time.After(time.Minute): return case msg := \u003c-messages: fmt.Println(msg) } } } func longRunning(messages \u003c-chan string) { timer := time.NewTimer(time.Minute) defer timer.Stop() for { select { case \u003c-timer.C: // 过期了 return case msg := \u003c-messages: fmt.Println(msg) // 此if代码块很重要。 if !timer.Stop() { \u003c-timer.C } } // 必须重置以复用。 timer.Reset(time.Minute) } } 我们在每次处理完消息后调用timer.Stop()以便于复用。如果timer已经过期，stop会返回false，C里面还有一条过期消息，我们需要把它取出来；如果timer没有过期，stop会返回true，继续执行循环 在一个Timer终止（stopped）之后并且在重置和重用此Timer值之前，我们应该确保此Timer的通道C中肯定不存在过期的通知 常用的仓库 ","date":"2021-02-02","objectID":"/go/:18:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"sync和atomic ","date":"2021-02-02","objectID":"/go/:19:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"strings Strings库是重复造轮子的重灾区，很多人试图自己再写一遍 var s = \"abaay森z众xbbab\" o := fmt.Println o(strings.TrimPrefix(s, \"ab\")) // aay森z众xbbab o(strings.TrimSuffix(s, \"ab\")) // abaay森z众xbb o(strings.TrimLeft(s, \"ab\")) // y森z众xbbab o(strings.TrimRight(s, \"ab\")) // abaay森z众x o(strings.Trim(s, \"ab\")) // y森z众x o(strings.TrimFunc(s, func(r rune) bool { return r \u003c 128 // trim all ascii chars })) // 森z众 分割与合并 // \"1 2 3\" -\u003e [\"1\",\"2\",\"3\"] func Fields(s string) []string // 用空白字符分割字符串 // \"1|2|3\" -\u003e [\"1\",\"2\",\"3\"] func Split(s, sep string) []string // 用sep分割字符串，sep会被去掉 // [\"1\",\"2\",\"3\"] -\u003e \"1,2,3\" func Join(a []string, sep string) string // 将一系列字符串连接为一个字符串，之间用sep来分隔 // Note: // \"1||3\" -\u003e [\"1\",\"\",\"3\"] ","date":"2021-02-02","objectID":"/go/:20:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["Go"],"content":"演化中的错误处理 满足下面的诉求： 可以把异常传递下去，并不丢失自己的类型 可以保存堆栈信息 Go的错误处理一直在讨论和演进，目前官方已经有几种不同的方案。对于反复写错误处理代码的问题，有几种解决的设想，可以看看上面的（Go语⾔将⾛向何⽅?） import ( \"golang.org/x/xerrors\" ) func bar() error { if err := foo(); err != nil { return xerrors.Errorf(\"bar failed: %w\", foo()) } return nil } func foo() error { return xerrors.Errorf(\"foo failed: %w\", sql.ErrNoRows) } func main() { err := bar() if xerrors.Is(err, sql.ErrNoRows) { fmt.Printf(\"data not found, %v\\n\", err) fmt.Printf(\"%+v\\n\", err) return } } /* Outputs:data not found, bar failed: foo failed: sql: no rows in result set bar failed: main.bar /usr/four/main.go:12 - foo failed: main.foo /usr/four/main.go:18 - sql: no rows in result set */ 参考资料 《Go Tour》（一个小时学会Go）https://tour.go-zh.org/welcome/1 《The Go Programming Language Specification》（语法细节）https://golang.org/ref/spec#Introduction（中文版《Go语言编码规范》） 《Go语言圣经》（语法细节）https://docs.hacknode.org/gopl-zh/ 《Effective Go》（适合刚学完Go的基础语法时候读）https://www.kancloud.cn/kancloud/effective/72199 《Go语言设计和实现》（适合想了解Go某个特性实现原理的时候参考）https://draveness.me/golang/docs/part1-prerequisite/ch02-compile/golang-compile-intro/ 《Go Q\u0026A 101》（可以和官方QA结合看）https://gfw.go101.org/article/unofficial-faq.html#time-sleep-after 《Go 语言高级编程》https://chai2010.cn/advanced-go-programming-book/ 《Go语言原本》https://golang.design/under-the-hood/ 《uber go规范》https://github.com/xxjwxc/uber_go_guide_cn ","date":"2021-02-02","objectID":"/go/:21:0","tags":["Go"],"title":"[Go]Go语言的设计和坑","uri":"/go/"},{"categories":["后台"],"content":"本文介绍了Redis的一些应用，包括分布式锁、消息/延迟队列、hyperloglog、位图、布隆过滤器、限流、地理位置等。","date":"2020-09-24","objectID":"/redis_1/","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"分布式锁 ","date":"2020-09-24","objectID":"/redis_1/:0:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"简单加锁 // 思想：利用setnx检测有没有set过，如果set过就表示没有抢到锁 \u003e setnx locker true OK // ... do somthing ... \u003e del locker ","date":"2020-09-24","objectID":"/redis_1/:1:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"处理set之后进程崩溃的死锁问题 // 思想：给锁加上过期时间，即使set之后进程挂掉，也不会死锁 \u003e setnx locker true OK \u003e expire locker 5 // ... do somthing ... \u003e del locker ","date":"2020-09-24","objectID":"/redis_1/:2:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"处理非原子性问题 setnx之后，expire之前，进程挂了，也会死锁。怎么处理这种情况？ 使用redis事务吗？事务里没有if else，要么全部执行，要么全部不执行。需求是setnx成功才执行expire，有依赖关系，没法用事务 使用新的原子命令，如下 \u003e set locker true ex5 nx OK // ... do somthing ... \u003e del locker ","date":"2020-09-24","objectID":"/redis_1/:3:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"处理超时问题 上面的方案设定了超时时间。但是如果少数操作的时间超过了超时时间怎么办？有两个问题： 这个时候其他线程就会抢占到锁，导致资源发生竞争。 如果锁是超时释放的，当前进程处理完操作之后又会释放锁，会把别人的锁释放 我们先来解决问题2。我们可以把locker的value设置为随机数，保证锁只会被当前线程释放。这个操作也要保证原子性，我们用lua脚本实现： // del lua if redis.call(\"get\", key) == tag then return redis.call(\"del\", key) else return 0 end // set java tag = random.nextint() if redis.set(key, tag, nx=True, ex=5): do_somthing() // eval del lua ","date":"2020-09-24","objectID":"/redis_1/:4:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"获得不了锁的处理 上面介绍了锁的实现，现在我们需要关注获取锁失败的分支。这个时候资源正在被其他过程占用，我们有几个处理办法： 直接抛出异常，比如管理端场景 sleep一会重试，但是sleep会阻塞处理线程，并不好 把请求放到一个延时队列，延后处理 消息队列 使用list和lpush/rpop，生产者使用lpush推入队列，消费者通过rpop推出队列。因为redis的命令是原子的，所以这里不会有竞争的问题。 我们该什么时候调用pop？ 一种常见的方法是pull，定时去消费（pop），比如每隔1s，但是这样消息会有一定的延时 另一种方法是调用b开头的阻塞函数，比如brpop，会阻塞到队列里有消息才会返回。需要注意的是，如果阻塞过久，redis会认为这个网络连接是闲置连接，会断开这些连接，所以客户端里要做好重试 还会有什么问题？ 做消费确认ACK比较麻烦，就是不能保证消费者在读取之后，未处理后的宕机问题。导致消息意外丢失。通常需要自己维护一个Pending列表，保证消息的处理确认。 不能广播、分组消费、重复消费 ","date":"2020-09-24","objectID":"/redis_1/:5:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"多次消费 如果要有多个消费者需要消费同一条消息，list就无法满足。Redis提供了pub/sub模式来解决这一问题。有下面几个操作： SUBSCRIBE，用于订阅信道 PUBLISH，向信道发送消息 UNSUBSCRIBE，取消订阅 生产者和消费者通过一个队列进行交互。通常会有多个消费者，多个消费者订阅同一个信道，当生产者向信道发布消息时，该信道会立即将消息逐一发布给每个消费者。 优点： 典型的广播模式，一个消息可以发布到多个消费者 多信道订阅，消费者可以同时订阅多个信道，从而接收多类消息 消息即时发送，消息不用等待消费者读取，消费者会自动接收到信道发布的消息 缺点： 消息一旦发布，不能接收。换句话就是发布时若客户端不在线，则消息丢失，不能寻回 不能保证每个消费者接收的时间是一致的 若消费者客户端出现消息积压，到一定程度，会被强制断开，导致消息意外丢失。通常发生在消息的生产远大于消费速度时 可见，Pub/Sub 模式不适合做消息存储，消息积压类的业务，而是擅长处理广播，即时通讯，即时反馈的业务。 ","date":"2020-09-24","objectID":"/redis_1/:6:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"延时队列 我们实现一个五秒后再处理消息的延时队列。 使用一个zset，score存放到期的时间戳。 然后用一个循环，zrangebyscore查出到期的消息，进行处理，如果没有消息就sleep一小会 如果有消息，用zrem先删除消息，然后再处理，确保只有一个线程处理 def delay(msg): msg.id = str(uuid.uuid4()) # 保证 value 值唯一 value = json.dumps(msg) retry_ts = time.time() + 5 # 5 秒后重试 redis.zadd(\"delay-queue\", retry_ts, value) def loop(): while True: # 最多取 1 条 values = redis.zrangebyscore(\"delay-queue\", 0, time.time(), start=0, num=1) if not values: time.sleep(1) # 延时队列空的，休息 1s continue value = values[0] # 拿第一条，也只有一条 success = redis.zrem(\"delay-queue\", value) # 从消息队列中移除该消息 if success: # 因为有多进程并发的可能，最终只会有一个进程可以抢到消息 msg = json.loads(value) handle_msg(msg) ","date":"2020-09-24","objectID":"/redis_1/:7:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"Redis Stream Redis对消息队列（MQ，Message Queue）的完善实现 hyperloglog 做基数(UV)统计 对于一些网站统计uv的场景，常见的做法用set是记录下访问过站点的uid，然后返回set的大小。 hyperloglog不存储具体的uid，只是做一个数学估计。 每次进来一个数字，我们看他从低位开始全是0的位有多少个。然后取 maxbit = max(maxbit, now0bit) 我们看看一次添加后发生了什么。比如这个命令： PFADD runoobkey \"r\" // 第一步，r的二进制为 01110010，得到最后只有1个0 // now0bit=1，maxbit=max(maxbit, now0bit)=1 我们会发现maxbit和总共的基数N有一定的关系。多次测试后，发现N和maxbit的关系大概是： $$N=2^{maxbit}$$ 但是这里可能会有很大的误差。只要有一个数字的now0bit非常大，就会把这个估计拉的很远。所以这里要用分组平均一下。 假设我们分为1024个桶，然后对每个桶分别估计的N取调和平均值，这样误差就会比较小。当取1024个桶时，误差大概在10%以内。此时N和maxbit的关系大概是（n=1024）： $$ N={\\frac{n}{\\sum_{i=1}^{n}{\\frac{1}{maxbit_{i}}}}}$$ Note: redis把数字分为16384(2^14)个桶，每个桶的maxbit占用6bit，所以占用的空间大概为2^14*6/8=12KB，误差在1%以内。 位图和布隆过滤器 ","date":"2020-09-24","objectID":"/redis_1/:8:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"位图 redis提供了位图操作 setbit key offset value 设置某个位 getbit key offset 获取某个位 bitcount key start end 获取某个区间之间的1的数量 bitop and/or/not/xor key1 key2 数据结构：这里面的存储结构实际上是一个SDS。在Redis Object里有一个char数组buf，里面存放着位信息，每个char能存8个位。在buf数组的末尾有一个'\\0'表示位图的结尾。 ","date":"2020-09-24","objectID":"/redis_1/:9:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"setbit/getbit 如何实现：setbit和getbit，都只要通过模余运算得到对应的buf下标和位，就可以拿到对应的值。 我们怎么拿到第n位的值？需要一个第n位为1的掩码 1\u003c\u003c(7 - n) // getbit // 计算出 offset 所指定的位所在的字节 = offset/8 byte = bitoffset \u003e\u003e 3; // 计算出位所在的位置 = offset%8, bitoffset \u0026 0x7得到后三位（offset%8） bit = 7 - (bitoffset \u0026 0x7); bitval = ((uint8_t*)buf)[byte] \u0026 (1 \u003c\u003c bit); // 第17位为例子 getbit [key] 17 // 除以8得到第几个byte，byte = 17 \u003e\u003e 3 = 2 // 模8取得字节数，取后三位 17 \u0026 0111 = 01 0001 \u0026 0111 = 0001 // 得到掩码 7 - 0001 = 6，1 \u003c\u003c 6 = 0100 0000 // 取出第3个字节的第二位 buf[2] \u0026 0100 0000 setbit稍微麻烦一些。在设置位的基础上还要考虑到SDS扩容的情况，如果setbit的offset超过了最大值，那么需要进行扩容并把扩好的空间初始化位0。 ","date":"2020-09-24","objectID":"/redis_1/:9:1","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"bitcount 计算二进制中1的个数，有几种方法： 查表。预处理好0000 0001 ~ 1111 1111 和其中1的个数的映射，比如0000 0001(1)，后面来了直接查表。我们最高可以建16位的表，仅需百KB左右的内存 variable-precision swar算法。 i = (i \u0026 0x55555555) + ((i \u003e\u003e 1) \u0026 0x55555555); i = (i \u0026 0x33333333) + ((i \u003e\u003e 2) \u0026 0x33333333); i = (i \u0026 0x0F0F0F0F) + ((i \u003e\u003e 4) \u0026 0x0F0F0F0F); i = (i * (0x01010101) \u003e\u003e 24); return i Redis中，不足128位的bitmap会查表，有一个8位的表查16次；超过8位的，每次载入128位，然后调用四次SWAR算法计算汉明重量。 ","date":"2020-09-24","objectID":"/redis_1/:9:2","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"布隆过滤器 布隆过滤器，是用来判断元素在不在set里的一种方法。上面的hyperloglog只能支持count操作，但是不支持contains操作。要大概地判断元素是否出现过就可以用布隆过滤器，他会用很多个哈希函数对元素进行哈希，把对应的位都设置；查找时也同样哈希，并查看对应的位是否被设置。布隆过滤器有一定的概率会把不存在的元素判定为存在（取决于要求的占用空间，），但是存在的元素一定不会判断错。 bf.add bf.exists 限流 ","date":"2020-09-24","objectID":"/redis_1/:10:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"简单限流 每一个行为到来时，都维护一次时间窗口。将时间窗口外的记录全部清理掉，只保留窗口内的记录。zset 集合中只有 score 值非常重要，value 值没有特别的意义，只需要保证它是唯一的就可以了（也可以用uuid，这里用了毫秒）。 # 业务代码 调用这个接口 , 一分钟内只允许最多回复 5 个帖子 can_reply = is_action_allowed(\"laoqian\", \"reply\", 60, 5) if can_reply: do_reply() def is_action_allowed(user_id, action_key, period, max_count): key = 'hist:%s:%s' % (user_id, action_key) now_ts = int(time.time() * 1000) # 毫秒时间戳 with client.pipeline() as pipe: # client 是 StrictRedis 实例 # 记录行为 pipe.zadd(key, now_ts, now_ts) # value 和 score 都使用毫秒时间戳 # 移除时间窗口之前的行为记录，剩下的都是时间窗口内的 pipe.zremrangebyscore(key, 0, now_ts - period * 1000) # 获取窗口内的行为数量 pipe.zcard(key) # 设置 zset 过期时间，避免冷用户持续占用内存 # 过期时间应该等于时间窗口的长度，再多宽限 1s pipe.expire(key, period + 1) # 批量执行 _, _, current_count, _ = pipe.execute() # 比较数量是否超标 return current_count \u003c= max_count ","date":"2020-09-24","objectID":"/redis_1/:11:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["后台"],"content":"漏桶限流 Redis-Cell Redis4.0之后提供了更好用的限流组件。 CL.THROTTLE reply 15 30 60 1 CL.THROTTLE key 初始容量 次数 秒数 每次加几个资格 这条命令限定了回复行为的频率为每 60s 最多 30 次(漏水速率)，漏斗的初始容量为 15，也就是说一开始可以连续回复 15 个帖子，然后才开始受漏水速率的影响。返回值也很有用： 参数1： 0 表示允许，1 表示拒绝 参数2： 漏斗容量 capacity 参数3： 漏斗剩余空间 left_quota 参数4： 如果拒绝了，需要多长时间后再试(漏斗有空间了，单位秒) 参数5： 多长时间后，漏斗完全空出来(left_quota==capacity，单位秒) 我们来看漏桶的一个python实现。每个漏桶 会存一个上一次漏水时间； 每次有请求过来就得到新增资格数=(计算当前时间-上次漏水时间)*每秒加入资格数，加到剩余空间上，但要保证剩余空间不大于capacity 剩余空间减掉请求的空间，并更新上次漏水时间 import time class Funnel(object): def __init__(self, capacity, leaking_rate): self.capacity = capacity # 漏斗容量 self.leaking_rate = leaking_rate # 漏嘴流水速率 self.left_quota = capacity # 漏斗剩余空间 self.leaking_ts = time.time() # 上一次漏水时间 def make_space(self): now_ts = time.time() delta_ts = now_ts - self.leaking_ts # 距离上一次漏水过去了多久 delta_quota = delta_ts * self.leaking_rate # 又可以腾出不少空间了 if delta_quota \u003c 1: # 腾的空间太少，那就等下次吧 return self.left_quota += delta_quota # 增加剩余空间 self.leaking_ts = now_ts # 记录漏水时间 if self.left_quota \u003e self.capacity: # 剩余空间不得高于容量 self.left_quota = self.capacity def watering(self, quota): self.make_space() if self.left_quota \u003e= quota: # 判断剩余空间是否足够 self.left_quota -= quota return True return False funnels = {} # 所有的漏斗 # capacity 漏斗容量 # leaking_rate 漏嘴流水速率 quota/s def is_action_allowed(user_id, action_key, capacity, leaking_rate): key = '%s:%s' % (user_id, action_key) funnel = funnels.get(key) if not funnel: funnel = Funnel(capacity, leaking_rate) funnels[key] = funnel return funnel.watering(1) for i in range(20): print is_action_allowed('laoqian', 'reply', 15, 0.5) GeoHash 附近的人 业务中经常有判断两个地址是否靠近，寻找某个地址周边的餐厅或超市，类似这样的需求。请求量不大时，我们可以用mysql解决，用一个半径圈出范围： select id from positions where x0-r \u003c x \u003c x0+r and y0-r \u003c y \u003c y0+r 请求量比较大时，我们就要借助redis 3.2以后的GeoHash的指令： // 添加地址 geoadd company 116.48105 39.996794 juejin geoadd company 116.489033 40.007669 meituan // 列出地址 geodist company juejin meituan km // 列出某个地址周围20km的最近三个地址 georadiusbymember company juejin 20 km count 3 asc // 列出某个经纬度附近的三个地址 georadius company 116.514202 39.905409 20 km withdist count 3 asc 实际上，GeoHash内部是一个zset，score是经纬度映射到一维后的一个数字。平面上靠的越近，zset中score值也会越接近。那么要怎么做这种映射呢？数学上有很多二位空间到一维空间的映射，参见 https://halfrost.com/go_spatial_search/ https://www.jianshu.com/p/2fd0cf12e5ba ","date":"2020-09-24","objectID":"/redis_1/:12:0","tags":["Redis","中间件","后台"],"title":"[Redis]Redis 应用篇","uri":"/redis_1/"},{"categories":["C++"],"content":"本部分介绍了c++11的并发编程。这些笔记是未完成的。 语法参考这里： 现代C++教程 实现参考这里： C++11中的mutex, lock，condition variable实现分析 std::thread C++ 11为我们带来了语言级的线程支持，包括线程的创建和等待： //g++ -o t main.cpp -lpthread --std=c++11 #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cchrono\u003e void foo(int sec) { // sleep_for() 休眠sec秒后唤醒 std::this_thread::sleep_for(std::chrono::seconds(sec)); } int main() { // join() 阻塞等待线程 // joinable() 是否可以join（没设置任务函数不可以join） std::thread t; std::cout \u003c\u003c \"before starting, joinable: \" \u003c\u003c t.joinable() \u003c\u003c '\\n'; t = std::thread(foo, 1); std::cout \u003c\u003c \"after starting, joinable: \" \u003c\u003c t.joinable() \u003c\u003c '\\n'; t.join(); // detach() 将当前线程对象所代表的执行实例与该线程对象分离，使得线程的执行可以单独进行。一旦线程执行完毕，它所分配的资源将会被释放。 // 永远不要用detach()。失去控制的线程会有很多问题 // get_id() 打印线程id std::thread t1(foo, 2); std:🧵:id t1_id = t1.get_id(); std::cout \u003c\u003c \"t1_id: \" \u003c\u003c t1_id \u003c\u003c '\\n'; t1.detach(); } std::mutex和std::lock_guard同步 有了线程就必然需要锁。我们看一个例子，用RAII 的方式管理线程和锁： // g++ -o t th.cpp --std=c++11 -lpthread int v = 1; void critical_section(int change_v) { static std::mutex mtx; std::lock_guard\u003cstd::mutex\u003e lock(mtx); // 执行竞争操作 v = change_v; // 离开此作用域后 mtx 会被释放 } int main() { std::thread t1(critical_section, 2), t2(critical_section, 3); t1.join(); t2.join(); std::cout \u003c\u003c v \u003c\u003c std::endl; return 0; } 看看源码，很简单地用构造和析构包了一下锁： 发生异常时也可以析构，所以锁是异常安全的 禁止拷贝构造、赋值 锁状态是adopt_lock_t（已获得锁），会调用不加锁的构造函数 template \u003cclass _Mutex\u003e class lock_guard { public: typedef _Mutex mutex_type; private: mutex_type\u0026 __m_; public: explicit lock_guard(mutex_type\u0026 __m) : __m_(__m) {__m_.lock();} lock_guard(mutex_type\u0026 __m, adopt_lock_t) : __m_(__m) {} ~lock_guard() {__m_.unlock();} private: lock_guard(lock_guard const\u0026);// = delete; lock_guard\u0026 operator=(lock_guard const\u0026);// = delete; }; std::unique_lock缩小锁的粒度 lock_guard 是一种RAII的思想管理锁，但是有时候我们需要自己加更小粒度的锁。 同样，构造时加锁，析构时释放锁 提供了lock、unlock、trylock、release等额外的功能，当然，开销也更大 void critical_section(int change_v) { static std::mutex mtx; std::unique_lock\u003cstd::mutex\u003e lock(mtx); // 执行竞争操作 v = change_v; std::cout \u003c\u003c v \u003c\u003c std::endl; // 将锁进行释放 lock.unlock(); // 在此期间，任何人都可以抢夺 v 的持有权 // 开始另一组竞争操作，再次加锁 lock.lock(); v += 1; // 析构也会自动释放 } std::future 期物 在 C++11 的 std::future 被引入之前，并行获取数据的通常的做法是： 创建一个线程 A，在线程 A 里启动任务 B，当准备完毕后发送一个事件，并将结果保存在全局变量中。 而主函数线程 A 里正在做其他的事情，当需要结果的时候，调用一个线程等待函数来获得执行的结果。 而 C++11 提供的 std::future 简化了这个流程，可以用来获取异步任务的结果： 使用packaged_task把我们的任务函数包起来得到task 获得期物result=task.get_future()（此时他还没有结果） 在另一个线程中执行task 阻塞等待result.wait() 获取结果result.get() #include \u003ciostream\u003e #include \u003cfuture\u003e #include \u003cthread\u003e int main() { // 将一个返回值为7的 lambda 表达式封装到 task 中 // std::packaged_task 的模板参数为要封装函数的类型 std::packaged_task\u003cint()\u003e task([](){return 7;}); // 获得 task 的期物 std::future\u003cint\u003e result = task.get_future(); // 在一个线程中执行 task std::thread(std::move(task)).detach(); std::cout \u003c\u003c \"waiting...\"; result.wait(); // 在此设置屏障，阻塞到期物的完成 // 输出执行结果 std::cout \u003c\u003c \"done!\" \u003c\u003c std:: endl \u003c\u003c \"future result is \" \u003c\u003c result.get() \u003c\u003c std::endl; return 0; } 原子操作 std::atomic C++11 中多线程下共享变量的读写这一问题上，还引入了 std::atomic 模板，使得我们实例化一个原子类型，将一个 原子类型读写操作从一组指令，最小化到单个 CPU 指令。 #include \u003catomic\u003e #include \u003cthread\u003e #include \u003ciostream\u003e std::atomic\u003cint\u003e count = {0}; int main() { std::thread t1([](){ count.fetch_add(1); }); std::thread t2([](){ count++; // 等价于 fetch_add count += 1; // 等价于 fetch_add }); t1.join(); t2.join(); std::cout \u003c\u003c count \u003c\u003c std::endl; return 0; } 条件变量 std::condition_variable 条件变量 std::condition_variable 是为了解决死锁而生，当互斥操作不够用而引入的。 比如，线程可能需要等待某个条件为真才能继续执行， 而一个忙等待循环中可能会导致所有其他线程都无法进入临界区使得条件为真时，就会发生死锁。 所以，condition_variable 实例被创建出现主要就是用于唤醒等待线程从而避免死锁。 std::condition_variable的 notify_one() 用于唤醒一个线程； notify_all() 则是通知所有线程。下面是一个生产者和消费者模型的例子： #include \u003cqueue\u003e #include \u003cchrono\u003e #include \u003cmutex\u003e #include \u003cthread\u003e #include \u003ciostream\u003e #include \u003ccondition_variable\u003e int main() { std::queue\u003cint\u003e produced_nums; std::mutex mtx; std::condition_variable cv; bool notified = false; // 通知信号 // 生产者 auto producer = [\u0026]() { for (int i = 0; ; i++) { std::this_thread::sleep_for(std::chrono::milliseconds(900)); std::unique_lock\u003cstd::mutex\u003e lock(mtx); std::cout \u003c\u003c \"producing \" \u003c\u003c i \u003c\u003c std::e","date":"2020-08-18","objectID":"/cpp_11_4/:0:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（四）","uri":"/cpp_11_4/"},{"categories":["C++"],"content":"宽松模型 relaxed 在此模型下，单个线程内的原子操作都是顺序执行的，不允许指令重排，但不同线程间原子操作的顺序是任意的。类型通过 std::memory_order_relaxed 指定。 下面的例子中，每个线程内的fetch_add都是顺序执行，但不同线程间的fetch_add顺序是乱序的。 std::atomic\u003cint\u003e counter = {0}; std::vector\u003cstd::thread\u003e vt; for (int i = 0; i \u003c 100; ++i) { vt.emplace_back([\u0026](){ counter.fetch_add(1, std::memory_order_relaxed); }); } for (auto\u0026 t : vt) { t.join(); } std::cout \u003c\u003c \"current counter:\" \u003c\u003c counter \u003c\u003c std::endl; ","date":"2020-08-18","objectID":"/cpp_11_4/:1:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（四）","uri":"/cpp_11_4/"},{"categories":["C++"],"content":"释放/消费模型 release/consume 在此模型中，加了一个限制，任何一次读操作都能读到数据最近一次写入的数据。 比如线程A写了三次，B线程来读，必须保证B线程看到的是最后一次。A线程写的顺序则不作要求。 // 初始化为 nullptr 防止 consumer 线程从野指针进行读取 std::atomic\u003cint*\u003e ptr(nullptr); int v; std::thread producer([\u0026]() { int* p = new int(42); v = 1024; ptr.store(p, std::memory_order_release); }); std::thread consumer([\u0026]() { int* p; while(!(p = ptr.load(std::memory_order_consume))); std::cout \u003c\u003c \"p: \" \u003c\u003c *p \u003c\u003c std::endl; std::cout \u003c\u003c \"v: \" \u003c\u003c v \u003c\u003c std::endl; }); producer.join(); consumer.join(); ","date":"2020-08-18","objectID":"/cpp_11_4/:2:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（四）","uri":"/cpp_11_4/"},{"categories":["C++"],"content":"释放/获取模型 release/acquire 在此模型下，我们可以进一步加紧对不同线程间原子操作的顺序的限制。release/acquire模型保证了线程 A 中所有发生在 release x 之前的写操作，对在线程 B acquire x 之后的任何读操作都可见。 std::memory_order_release确保了它之后的写行为不会发生在释放操作之前，是一个向前的屏障 std::memory_order_acquire确保了它之前的写行为，不会发生在该获取操作之后，是一个向后的屏障 std::memory_order_acq_rel则结合了这两者的特点，唯一确定了一个内存屏障，使得当前线程对内存的读写不会被重排到此操作的前后。 ","date":"2020-08-18","objectID":"/cpp_11_4/:3:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（四）","uri":"/cpp_11_4/"},{"categories":["C++"],"content":"顺序一致模型 sequential consistency 在此模型下，原子操作满足顺序一致性，进而可能对性能产生损耗。可显式的通过 std::memory_order_seq_cst 进行指定。 std::atomic\u003cint\u003e counter = {0}; std::vector\u003cstd::thread\u003e vt; for (int i = 0; i \u003c 100; ++i) { vt.emplace_back([\u0026](){ counter.fetch_add(1, std::memory_order_seq_cst); }); } for (auto\u0026 t : vt) { t.join(); } std::cout \u003c\u003c \"current counter:\" \u003c\u003c counter \u003c\u003c std::endl; 实现一个线程池 我们用一个例子C++11线程池学习一下c11提供的这些新特性。 ","date":"2020-08-18","objectID":"/cpp_11_4/:4:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（四）","uri":"/cpp_11_4/"},{"categories":["后台"],"content":"负载均衡是集群中一个重要的组成部分。这个模块一般集成了名字服务、负载均衡、过载保护、限流等功能。第二部分是针对限流算法和实现的介绍。","date":"2020-07-27","objectID":"/load_balance3/","tags":["负载均衡","限流"],"title":"[后台]负载均衡 （三）限流篇","uri":"/load_balance3/"},{"categories":["后台"],"content":"限流 限流能力是高并发系统中，对于服务提供方的一种保护手段。通过限流功能，我们可以通过控制QPS的方式，以避免被瞬时的流量高峰冲垮，从而保障系统的高可用性。 考虑的问题 完成一个限流系统， 我们可以结合场景的需要做下面的考虑 多规则匹配：是否会存在有多重规则的限流？比如有的规则限制每天1000次，有的规则限制每分钟1次？是同时生效还是优先生效某个？ 资源类型：能限流什么？QPS，连接数，并发数 全局限流/单机限流：多个服务的实例共享一个全局的流量限额，比如所有机器共享1000QPS。或者单个实例的限流，比如被调限定每台机器不超过1000QPS 限流阈值：单位时间内的最大配额数。是按照每秒种一次，还是按照每分钟60次？ 限流处理：客户端如何处理超出限额的请求？超额后直接拒绝，还是超额后进行排队？ 抽象出一个方案 接口级别限流：每个接口分配一个appid和key，各自计算各自的配额 多维度限流：支持每秒N次、每分钟N次、每天N次等维度 匀速防刷：假设配置了每分钟60次，依然可能出现第一秒访问了60次用光了配额。匀速防刷可以匀速消耗配额，解决这个问题 多级限流：支持不同的限流规则，并有采用的优先级，采用优先级最高的方案进行限流 限流算法 ","date":"2020-07-27","objectID":"/load_balance3/:0:0","tags":["负载均衡","限流"],"title":"[后台]负载均衡 （三）限流篇","uri":"/load_balance3/"},{"categories":["后台"],"content":"固定窗口 固定窗口是在一段时间内可以限制访问次数的方法。 将时间划分为多个窗口 在每个窗口内每有一次请求就将计数器加一 如果计数器超过了限制数量,则本窗口内所有的请求都被丢弃。当时间到达下一个窗口时,计数器重置 这样有一定的限流效果，但是限制住的流量可能是有毛刺的。比如1000次/分钟，可能00:59的时候有1000流量，01:00的时候也有1000流量，这样这两秒内就有2000流量！ 具体实现：用一个变量C标记访问次数，一个事件定时过期，并在过期时把变量C清零： type FixedWindowCounter struct { TimeSlice time.Duration NowCount int32 AllowCount int32 } func (p *FixedWindowCounter) Take() bool { once.Do(func() { go func() { for { select { case \u003c-time.After(p.TimeSlice): atomic.StoreInt32(\u0026p.NowCount, 0) } } }() }) nowCount := atomic.LoadInt32(\u0026p.NowCount) if nowCount \u003e= p.AllowCount { return false } if !atomic.CompareAndSwapInt32(\u0026p.NowCount, nowCount, nowCount+1) { return false } return true } ","date":"2020-07-27","objectID":"/load_balance3/:1:0","tags":["负载均衡","限流"],"title":"[后台]负载均衡 （三）限流篇","uri":"/load_balance3/"},{"categories":["后台"],"content":"滑动窗口 滑动窗口把一个固定窗口划分为多个小区间，以固定的窗口大小在区间上滑动，在一定程度上缓解了固定窗口的毛刺问题（我们假设某一区间qps非常高）。当然性能损耗也比较大。 将时间划分为多个区间 在每个区间内每有一次请求就将当前区间的计数器加一 每经过一个区间的时间,则抛弃窗口中最老的一个区间,并纳入最新的一个区间； 如果当前窗口内区间的请求计数总和超过了限制数量,则本窗口内所有的请求都被丢弃 type SlideWindowCounter struct { lastWindowCount int32 // 当前区间请求计数 window chan int32 // 滑动窗口 windowSlice time.Duration // 单区间大小 nowCount int32 // 滑动窗口请求计数 AllowCount int32 // 滑动窗口内允许的请求数 } func NewSlideWindowCounter(timeSlice time.Duration, windowLen int32, AllowCount int32) *SlideWindowCounter { obj := \u0026SlideWindowCounter{ window: make(chan int32, windowLen), windowSlice: timeSlice / time.Duration(windowLen), AllowCount: AllowCount, } go obj.sliding() return obj } func (l *SlideWindowCounter) Take() bool { nowCount := atomic.LoadInt32(\u0026l.nowCount) if nowCount \u003e= l.AllowCount { return false } if !atomic.CompareAndSwapInt32(\u0026l.nowCount, nowCount, nowCount+1) { return false } // 当前区间的请求数 atomic.AddInt32(\u0026l.lastWindowCount, 1) return true } func (l *SlideWindowCounter) sliding() { // 窗口没满的时候 notFull := true for notFull { select { case \u003c-time.After(l.windowSlice): // 经过了一个区间的时间，把这个区间的请求数放入窗口，并开始新的区间 // 等于 l.window \u003c- l.lastWindowCount; l.lastWindowCount = 0 t := atomic.SwapInt32(\u0026l.lastWindowCount, 0) l.window \u003c- t if len(l.window) == cap(l.window) { notFull = false } } } // 窗口满了，开始滑动，每经过一个区间的时间,则抛弃最老的一个区间,并纳入最新的一个区间 for { select { case \u003c-time.After(l.windowSlice): t := \u003c-l.window if t != 0 { atomic.AddInt32(\u0026l.nowCount, -t) } newt := atomic.SwapInt32(\u0026l.lastWindowCount, 0) l.window \u003c- newt } } } ","date":"2020-07-27","objectID":"/load_balance3/:2:0","tags":["负载均衡","限流"],"title":"[后台]负载均衡 （三）限流篇","uri":"/load_balance3/"},{"categories":["后台"],"content":"漏桶 漏桶的思想其实大家都非常熟悉，就是一个用来缓冲的队列。不过，出队的速度是均匀的，比如每秒只出队一百个，就会有一百个请求发出去。入队的速度没有限制，但是如果队列满了，请求就会被抛弃。 漏洞算法其实是一种流量整形算法， 优点：简单、高效，能恰当拦截容量外的暴力流量。 缺点：无法对流量做频率处理。比如:桶设置的过大（比如每秒一百个），桶容量又不可以设置的过小，否则容易卡死正常用户 type LeakyBucket struct { TimeSlice time.Duration AllowCount int32 // 上面的时间段内匀速漏出多少请求 Bucket chan func() // 桶 } func NewLeakyBucket(timeSlice time.Duration, bucketSize int, allowCount int32) *LeakyBucket { obj := \u0026LeakyBucket{ TimeSlice: timeSlice, Bucket: make(chan func(), bucketSize), AllowCount: allowCount, } go func() { // 定时漏出去一个请求 for { select { case \u003c-time.After(time.Duration(obj.TimeSlice.Nanoseconds() / int64(obj.AllowCount))): task := \u003c-obj.Bucket task() } } }() return obj } func (t *LeakyBucket) Take(task func()) bool { select { case t.Bucket \u003c- task: return true default: } return false } ","date":"2020-07-27","objectID":"/load_balance3/:3:0","tags":["负载均衡","限流"],"title":"[后台]负载均衡 （三）限流篇","uri":"/load_balance3/"},{"categories":["后台"],"content":"令牌桶 令牌桶的思想是在一个桶中按一定速度加入资格，接受流量的时候消耗资格，没有资格则拒绝请求 每秒会有 r 个令牌放入桶中，或者说，每过 1/r 秒桶中增加一个令牌； 桶中最多存放 b 个令牌，如果桶满了，新放入的令牌会被丢弃； 当一个 n 字节的数据包到达时，消耗 n 个令牌，然后发送该数据包； 如果桶中可用令牌小于 n，则该数据包将被缓存或丢弃。 优缺点: 令牌桶的一个好处是可以方便的改变速度。 一旦需要提高速率，则按需提高放入桶中的令牌的速率。 可以限制总请求大小，还限制平均频率大小；能允许某种程度的突发传输 还是容易导致误判等问题 type TokenBucket struct { TimeSlice time.Duration AllowCount int32 // 上面的时间段内生成多少个令牌 Bucket chan struct{} // 桶 } func NewTokenBucket(timeSlice time.Duration, bucketSize int, allowCount int32) *TokenBucket { obj := \u0026TokenBucket{ TimeSlice: timeSlice, Bucket: make(chan struct{}, bucketSize), AllowCount: allowCount, } go func() { // 定时漏出去一个令牌 for { select { case \u003c-time.After(time.Duration(obj.TimeSlice.Nanoseconds() / int64(obj.AllowCount))): obj.Bucket \u003c- struct{}{} } } }() return obj } func (t *TokenBucket) Take() bool { select { case \u003c-t.Bucket: return true default: } return false } ","date":"2020-07-27","objectID":"/load_balance3/:4:0","tags":["负载均衡","限流"],"title":"[后台]负载均衡 （三）限流篇","uri":"/load_balance3/"},{"categories":["后台"],"content":"预热桶 在机器刚刚启动时，可能缓存尚未建立，或者正在初始化，直接打入大量请求可能会导致系统崩溃。所以我们需要一个预热的过程，在请求较少时，缓慢放开请求的量级；在请求正常后恢复正常量级。这里就要用到预热桶。 预热桶其实就是令牌桶的升级版，主要区别在于：我们假设系统的阈值QPS为count，在令牌桶中获取单个令牌的时间是固定的1/count 。而从预热桶中获取单个令牌的时间是随着存量令牌的数量而变化的。 我们假设系统刚启动或者长时间没有收到请求处于冷却状态，这个时候令牌达到令牌数上限（饱和状态）。此时从预热桶中获取令牌的时间要比稳定状态要长。随着令牌的减少，获取单个令牌的时间会慢慢变短，最终到达一个稳定值。 所以我们可以设一个函数，获取单个令牌的时间 = k * 1 / QPS 假设我们用一条垂直于X轴的竖线表示当前的请求状态，竖线从右向左移动时，表示系统接收到请求（预热中），令牌正在被消耗，假设系统连续接收到 k 个请求，获取对应令牌所需要的时间为[令牌数上限-k, 令牌数上限]的定积分，就是包围的面积。 反过来，竖线从左向右移动时，表示系统正在冷却。 ","date":"2020-07-27","objectID":"/load_balance3/:5:0","tags":["负载均衡","限流"],"title":"[后台]负载均衡 （三）限流篇","uri":"/load_balance3/"},{"categories":["后台"],"content":"redis实现的简单限流模型 http://doc.redisfans.com/string/incr.html 多机限流的方案中，使用redis的自增incr和过期expire是一种最简单的方案。假设我们要在1秒内限制100次，那么只需要保留一个一秒过期的key，每次incr并判断incr之后的值是否会超过100。 要注意： incr这个操作本身是原子的，并且每次递增后会返回incr的值 incr和expire这两个操作必须当一个事务，否则expire失败了，或者incr和expire之间插入的别的incr都会有问题。我们这里用一个lua脚本在redis中EVAL解决这个问题 local current current = redis.call(\"incr\",KEYS[1]) if tonumber(current) == 1 then redis.call(\"expire\",KEYS[1],1) end ","date":"2020-07-27","objectID":"/load_balance3/:6:0","tags":["负载均衡","限流"],"title":"[后台]负载均衡 （三）限流篇","uri":"/load_balance3/"},{"categories":["后台"],"content":"负载均衡是集群中一个重要的组成部分。这个模块一般集成了名字服务、负载均衡、过载保护、限流等功能。第二部分是针对名字服务、负载均衡、过载保护手段的介绍。","date":"2020-05-21","objectID":"/load_balance2/","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"名字服务 ","date":"2020-05-21","objectID":"/load_balance2/:0:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"基础设计 名字服务考虑的基本设计 客户端发现： 服务提供者的实例在启动时或者位置信息发生变化时会向服务注册表注册自身，在停止时会向服务注册表注销自身，如果服务提供者的实例发生故障，在一段时间内不发送心跳之后，也会被服务注册表注销。 服务消费者的实例会向服务注册表查询服务提供者的位置信息，然后通过这些位置信息直接向服务提供者发起请求。 服务端发现： 第一步与客户端发现相同。 服务消费者不直接向服务注册表查询，也不直接向服务提供者发起请求，而是将对服务提供者的请求发往一个中央路由器或者负载均衡器，中央路由器或者负载均衡器查询服务注册表获取服务提供者的位置信息，并将请求转发给服务提供者。 这两种模式各有利弊，客户端发现模式的优势是，服务消费者向服务提供者发起请求时比服务端发现模式少了一次网络跳转，劣势是服务消费者需要内置特定的服务发现客户端和服务发现逻辑； 服务端发现模式的优势是服务消费者无需内置特定的服务发现客户端和服务发现逻辑，劣势是多了一次网络跳转，并且需要基础设施环境提供中央路由机制或者负载均衡机制。目前客户端发现模式应用的多一些，因为这种模式的对基础设施环境没有特殊的要求，和基础设施环境也没有过多的耦合性。 主调调用被调时，根据被调的名字从服务注册中心获取服务实例列表，包括节点ip、端口、权重、地理位置等；一般采取分钟级别的定时任务去拉取，本地做缓存，异步更新。 实现方式 DNS，传播速度太慢，没法发现端口。SkyDNS解决了这个问题，在k8s里大量使用 zookeeper或者etcd，如SmartStack，能保证强一致，但是要做很多开发 Eureka。Netflix的java生态里的优秀方案 Consul，提供服务配置、服务的内存和磁盘监测等 ","date":"2020-05-21","objectID":"/load_balance2/:1:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"服务注册信息 ","date":"2020-05-21","objectID":"/load_balance2/:2:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"IP和端口 一个服务端要接入名字服务，必须要先提供自己的IP和端口信息。 IP的获取方法： 通过遍历网卡的方式去获取，找到第一个不为本地环回地址的 IP 地址。dubbo就是这种方法 指定网卡名interfaceName，来获取IP 直接与服务注册中心建立 socket 连接，然后通过socket.getLocalAddress() 这种方式来获取本机的 IP 端口的获取方法： 一般的RPC服务或者Web服务监听的端口都在配置中写好，可以直接获取上报。 ","date":"2020-05-21","objectID":"/load_balance2/:2:1","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"扩展设计 除了IP和端口，可能还有一些常用的服务信息需要注册上来，提供更高级的功能： 1.支持TLS：想知道某个 HTTP 服务是否开启了 TLS。 2.权重：对相同服务下的不同节点设置不同的权重，进行流量调度。 3.环境分配：将服务分成预发环境和生产环境，方便进行AB Test功能。 4.机房：不同机房的服务注册时加上机房的标签，以实现同机房优先的路由规则。 ","date":"2020-05-21","objectID":"/load_balance2/:2:2","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"无损注册/下线 虽然服务注册一般发生在服务的启动阶段，但是细分的话，服务注册应该在服务已经完全启动成功，并准备对外提供服务之后才能进行注册。 1.有些 RPC 框架自身提供了方法来判断服务是否已经启动完成，如 Thrift ，我们可以通过 Server.isServing() 来判断。 2.有一些 RPC 框架本身没有提供服务是否启动完成的方式，这时我们可以通过检测端口是否已经处于监听状态来判断。 3.而对于 HTTP 服务，服务是否启动完毕也可以通过端口是否处于监听状态来判断。 下线也是一样的，可以注册服务下线的回调，或者监听服务下线的信号，或者做健康检查 ","date":"2020-05-21","objectID":"/load_balance2/:3:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"健康检查 客户端主动心跳上报健康： 客户端每隔一定时间主动发送“心跳”的方式来向服务端表明自己的服务状态正常，心跳可以是 TCP 的形式，也可以是 HTTP 的形式。 也可以通过维持客户端和服务端的一个 socket 长连接自己实现一个客户端心跳的方式。 客户端的健康检查只能表明网络可达，不能代表服务可用。服务端的健康检查可以准确获得服务的健康状态： 服务端调用服务发布者某个 HTTP 接口来完成健康检查。 对于没有提供 HTTP 服务的 RPC 应用，服务端调用服务发布者的接口来完成健康检查。 可以通过执行某个脚本的形式来进行综合检查，覆盖多个场景。 服务端检查也有问题，一个是调用服务的方式不通用，需要额外实现，还有就是服务注册中心可能和服务的网络不互通。 ","date":"2020-05-21","objectID":"/load_balance2/:4:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"节点变化通知 当服务有节点退出或新的节点加入时，订阅者如何及时收到通知？经典的push和pull的问题 Push 的经典实现有两种，基于 socket 长连接的 notify，典型的实现如 zookeeper；另一种为 HTTP 连接所使用 Long Polling。 但是基于 socket 长连接的 notify 和基于 HTTP 协议的 Long Polling 都会存在notify消息丢失的问题。 Pull 的定时轮询也需要支持，要选好查询的间隔时间，在服务性能和业务规模之间权衡 还有一种真push，客户端开启一个 UDP server，服务注册中心通过 UDP 的方式进行数据推送，当然这个也受限于网络的连通性 ","date":"2020-05-21","objectID":"/load_balance2/:5:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"容灾 客户端容灾： 首先，本地内存缓存，当运行时与服务注册中心的连接丢失或服务注册中心完全宕机，仍能正常地调用服务。 然后，本地缓存文件，当应用与服务注册中心发生网络分区或服务注册中心完全宕机后，应用进行了重启操作，内存里没有数据，此时应用可以通过读取本地缓存文件的数据来获取到最后一次订阅到的内容。 最后，本地容灾文件夹。正常的情况下，容灾文件夹内是没有内容的。当服务端完全宕机且长时间不能恢复，同时服务提供者又发生了很大的变更时，运维可以通过在容灾文件夹内手动添加文件的方式来开启本地容灾。此时客户端会忽略原有的本地缓存文件，只从本地容灾文件中读取配置。 服务端容灾： 由于地址服务是无状态的，服务端容灾可以做的很薄，主要有两点：新的服务端加入，地址服务器会更新并和其他地址服务器保持同步；服务端删除，地址服务器能保证快速删除。 熔断 ","date":"2020-05-21","objectID":"/load_balance2/:6:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"熔断器模式 熔断器模式是一种用于故障恢复的设计模式，也常用在负载均衡中。它可以防止一个应用不断地去尝试一个很可能失败的操作，避免服务持续过载。他由几个状态组成： 关闭(Closed)：默认情况下Circuit Breaker是关闭的，此时允许操作执行。Circuit Breaker内部记录着最近失败的次数，如果对应的操作执行失败，次数就会续一次。如果在某个时间段内，失败次数（或者失败比率）达到阈值，Circuit Breaker会转换到开启(Open)状态。 开启(Open)：在此状态下，执行对应的操作将会立即失败并且立即抛出异常。在开启状态中，Circuit Breaker会启用一个超时计时器，设这个计时器的目的是给集群相应的时间来恢复故障。当计时器时间到的时候，Circuit Breaker会转换到半开启(Half-Open)状态。 半开启(Half-Open)：在此状态下，Circuit Breaker 会允许执行一定数量的操作。如果所有操作全部成功，Circuit Breaker就会假定故障已经恢复，它就会转换到关闭状态，并且重置失败次数。如果其中 任意一次 操作失败了，Circuit Breaker就会认为故障仍然存在，所以它会转换到开启状态并再次开启计时器（再给系统一些时间使其从失败中恢复）。 我们可以借鉴此设计模式设计一种负载均衡的熔断策略： 请求失败比例过高熔断：当服务端在上一个时间窗（比如10秒）内，成功的请求量小于最低请求量要求requestVolumeThreshold（默认100个），且成功率小于最低成功率errorThresholdPercentage（比如50%），服务端就会进入隔离状态，熔断器开启。 请求连续失败熔断：当服务端在上一个时间窗（比如10秒）内，连续失败的请求超过连续失败上限bound2（默认10个），服务器进入隔离状态，熔断器开启 熔断隔离时间sleepWindowInMilliseconds：默认隔离30s，支持可配置。 ","date":"2020-05-21","objectID":"/load_balance2/:7:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"熔断器发现-时间窗上报 要想再问题发生的时候熔断，首先要发现问题。我们看看Hystrix的熔断器模型怎么收集上报： Hystrix滑动窗口策略，以秒为单位来统计请求处理情况，上面每个格子代表1秒，格子中的数据就是1秒内各请求的处理结果，称为一个桶。 我们假设每次决策都以最近的十个桶来决定是否熔断，比如失败率超过50%就熔断。这10秒就是一个滑动窗口，每经过一秒，最老的一个桶就会被丢弃，同时增加一个新的桶。 ","date":"2020-05-21","objectID":"/load_balance2/:8:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"熔断器恢复-探针 熔断器在半开状态时，如果用请求来检测服务可用，那么还是会有一些请求会丢失的风险。一种比较好的办法是使用探针来检测服务的可用性。探针一般有TCP、UDP、HTTP几种，还要支持用户自定义探针。 主调需要在配置中指定要用的探针类型和探针的使用顺序，在需要探测时会以这个顺序调用探测插件进行探测；只要有一个探测插件成功，就认为服务已经恢复，停止探测。 比如一个udp探针： 探测插件名：udp 探测请求包：0x0001 期望回包：0x000F 超时时间：100ms 探测次数：5 过载保护 微信的过载保护 操作系统里有CPU、内存、网卡、磁盘等各种资源，当程序处理海量请求时很容易使得某一种资源到达处理性能瓶颈，从而使得服务的处理能力迅速下降。一般的后台服务可能会有几个下面的瓶颈： CPU，计算密集型服务 内存，内存消耗型服务 CPU LOAD，多线程型服务（进程调度频繁导致CPU空跑） IO，包括磁盘IO（比如随机IO导致cache性能下降，机械臂移动频繁，swap频繁），网络IO、网络连接数多的服务（网络拥塞） 这些瓶颈中的某一个因素打破平衡后，会传播和放大（比如用户不断失败重试），形成滚雪球效应，导致整个系统崩溃。此时就需要我们的负载均衡理论来保障系统的可用性。 ","date":"2020-05-21","objectID":"/load_balance2/:9:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"四大方法 ","date":"2020-05-21","objectID":"/load_balance2/:10:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"轻重分离 轻重分离是一种类似高内聚，低耦合的方法论，用来限制服务崩溃的影响扩大。 按服务的重要性对服务分别隔离部署，避免一些不重要的服务影响要重要的服务。服务的隔离最好能做到物理隔离，包括服务器、带宽、IDC级别的隔离。 按重要性分离：比如微博热点出现时大家都去访问某明星的主页，我们尽量只让个人主页服务挂掉，不要影响其他的资讯、推送服务 按部署分离：电信、联通、教育网、海外用户之间的分离 按快慢分离：下载资源服务和资讯页面服务的分离 按set分离用户：按游戏区服、用户uid的哈希值分离，从逻辑分离到物理隔离 ","date":"2020-05-21","objectID":"/load_balance2/:10:1","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"及早拒绝 问题解决的阶段越早，成本越低，影响越小的一种思想。 原则：前端保护后端，后端不信任前端。 前后端要交流：后端把自己的负载情况也报告给前端 前端收到后端的负载情况后，要用正确的策略调度后端，后端负载满时不再发起请求 后端接到前端的请求后，如果自己负载很高，要拒绝发来的新请求 这里面有两个关键点： 高负载识别 负载能力需要一些具体的指标来识别，比如包量、并发连接数 拒绝方法 拒绝的时候要有降级策略，用有损服务和柔性可用来保障体验 ","date":"2020-05-21","objectID":"/load_balance2/:10:2","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"量力而为 每个服务要先做好自我保护，再考虑对关联系统的保护。 对自己的保护需要做好过载监控要做好告警机制，比如在系统负载达到70%的时候发出预警，在后台负载90%的时候启动过载保护 ","date":"2020-05-21","objectID":"/load_balance2/:10:3","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"动态调节 结合上面的三个方法，持续监控服务过载状态，形成一个良性的正反馈循环： 业务正常状态-\u003e 过载保护状态 -\u003e 业务灰度恢复 -\u003e 业务正常状态 ","date":"2020-05-21","objectID":"/load_balance2/:10:4","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"LB和过载保护 LB和容灾解决的是大容量业务的平行扩展及可用性问题，在做好容量管理的前提下具备一定的应对突发流量的能力（因为具备一定的资源冗余），但是LB只做到流量的均衡分布处理，却没有实现流量超出系统总体容量时的保护、控制。 WRR仅仅实现了根据运营配置的静态负载均衡策略，当集群中某个节点过载时，不能及时调整负载均衡策略以保护该节点，使得过载节点雪上加霜最终假死，更可怕的是节点假死（或者某节点故障）后，LB会马上摘除该节点，并把该节点的负载分担到其它正常节点上，从而可能造成正常节点的过载，如此循环往复，过载不断扩散，最终使得系统整体雪崩。 我们可以优化一下LB的机制，把过载时多出来的请求直接抛弃掉。但是该机制还未能很好的解决过载的源头问题，即用户失去耐心后的无效请求倍增的滚雪球效应，同时也未能给用户较好的有损体验。 还有一种方法是一损俱损，当整个后台集群不可用时，LB把所有的机器都返回，这样在极端情况下也能保障系统的部分可用性。 ","date":"2020-05-21","objectID":"/load_balance2/:11:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"请求队列和过载保护 实现请求队列的目的是通过非阻塞方式实现异步系统，优化系统架构，从而提升系统性能。 异步系统的问题是在分层系统中，各层次所维护的请求/响应队列与原始请求发起方失去了直接的联系，这就造成队列数据有效性（通常是采用轮询超时的方式处理）无法保障。 当过载发生时，用户不断的刷新请求，这也就意味着此时系统请求队列中大部分访问请求已经无效（用户用新的刷新访问代替了上一次的访问请求），但此时队列中的“无效访问请求“尚未超出设定的超时阀值，后端系统（往往是系统的瓶颈所在）还在按FIFO的原则继续处理，这样的结果是： 系统的宝贵资源都用来处理无效的访问请求，极大的浪费了资源； 用户得不到及时的反馈，不断的刷新访问请求，导致滚雪球效应； 请求的涌入使得瓶颈资源无法处理，LB作出调度使得过载扩散，导致多米诺骨牌效应； 从以上分析我们可知，请求队列机制无法及时剔除无效数据，从而控制雪球的增长，也无法控制过载的扩散，故 有了请求队列，仍然需要丰富的过载保护机制 ","date":"2020-05-21","objectID":"/load_balance2/:12:0","tags":["负载均衡","后台","名字服务","过载保护"],"title":"[后台]负载均衡（二）能力篇","uri":"/load_balance2/"},{"categories":["后台"],"content":"负载均衡是集群中一个重要的组成部分。这个模块一般集成了名字服务、负载均衡、过载保护、限流等功能。第一部分是针对均衡本身算法的介绍。","date":"2020-05-06","objectID":"/load_balance/","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"当单机的访问压力很大时，就需要引入集群。集群一个很重要的事情就是把请求均匀地分配在各个机器上，这就是负载均衡的雏形。 有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。 二层负载均衡会通过一个虚拟MAC地址接收请求，然后再分配到真实的MAC地址；三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址； 四层通过虚拟IP+端口接收请求，然后再分配到真实的服务器（比如LVS，F5）；七层通过虚拟的URL或主机名接收请求，然后再分配到真实的服务器（Haproxy和Nginx）。 四层和七层是最常见的负载均衡模型。 **四层：**以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN请求时，通过负载均衡算法选择服务器，并对报文中目标IP地址进行修改（改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。 **七层：**以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上设置的负载均衡算法，选择内部某台服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。 参考资料：四层和七层负载均衡的区别 nginx用的负载均衡算法 Nginx可以作为HTTP反向代理，把访问本机的HTTP请求，均分到后端集群的若干台服务器上。负载均衡的核心就是负载均衡所使用的平衡算法，适用于各种场景。 Nginx的负载均衡算法 Nginx目前提供的负载均衡模块： ngx_http_upstream_round_robin，加权轮询，可均分请求，是默认的HTTP负载均衡算法，集成在框架中。 ngx_http_upstream_ip_hash_module，IP哈希，可保持会话。 ngx_http_upstream_least_conn_module，最少连接数，可均分连接。适用于链接数体现资源的服务，比如FTP。 ngx_http_upstream_hash_module，一致性哈希，可减少缓存数据的失效。 ","date":"2020-05-06","objectID":"/load_balance/:0:0","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"随机访问 在介绍nginx的模式前，先介绍下普通的负载均衡方法。假设有7个请求，我们给A、B、C三个节点分别4、2、1的权重。最朴素的负载均衡方式有下面几种： 完全轮询：访问完A去访问B，访问完B去访问C，再去访问A。缺点是没有权重，不能根据负载调节。 列表轮询：构造一个数组[A, A, A, A, B, B, C]，每次pop出去一个访问。缺点是pop出去的元素太随机，可能一次集中访问A ，而且占用内存太大，对于几万的权重范围不合适。 随机数：我们按照A、B、C的权重划分好区间，A（0、1、2、3），B（4、5），C（6），然后取一个随机数，模余7，看看最后的结果在哪个区间内，就取哪个节点。缺点是完全随机，无法避免集中访问。 ","date":"2020-05-06","objectID":"/load_balance/:1:0","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"加权轮询 假设有7个请求，我们给A、B、C三个节点分别4、2、1的权重。如果随机按照概率来选，那么很可能出现连续四个请求都在A上面的情况，这样只能保证结果看起来均衡，但是时间段内不均衡。Nginx采用了一种平滑的加权平均算法来选取节点（Weighted Round Robin）。 先引入三个概念，都用来描述服务器节点的权重： $W$ : weight 我们指定的权重，就是上面例子中的4、2、1。 $W_{ew}$: effective_weight 有效权重，初始值为$W$。用来对故障节点降权。 如果通信中有错误产生，就减小effective_weight。（故障降权） 此后有新的请求过来时，再逐步增加effective_weight，最终又恢复到weight。（自动恢复） $W_{cw}$ : current_weight 当前真实权重，每次都会选到最大的真实权重的节点去请求 真实权重$W_{cw}$计算方式： 初始化：$W_{cw}$ 起始值为0 获得实时权重：请求到来后，给每个节点的真实权重加上有效权重，即$每个节点 W_{cw} = W_{cw} + W_{ew}$ 选出最大权重：选择真实权重最大的节点最为本次请求的目标 回避刚选的节点：最选择的节点的实时权重减去所有节点（包括自己）的有效权重和。即$选中节点 W_{cw} = W_{cw} - (W_{ew1} + W_{ew2} + … + W_{ewn})$ 来看一个具体的例子： 假设A、B、C三个节点的权重分别为4、2、1。 请求序号 请求后的current_weight 选择的节点 选择后的current_weight 未请求 {0,0,0} / / 1 {4,2,1} A {-3,2,1} 2 {1,4,2} B {1,-3,2} 3 {5,-1,3} A {-2,-1,3} 4 {2,1,4} C {2,1,-3} 5 {6,3,-2} A {-1,3,-2} 6 {3,5,-1} B {3,-2,-1} 7 {7,0,0} A {0,0,0} 三个结论：每个节点被选中的次数是符合权重的；A没有被连续选取；七次之后权重会归零，是一个循环。 static ngx_http_upstream_rr_peer_t *ngx_http_upstream_get_peer(ngx_http_upstream_rr_peer_data_t *rrp) { time_t now; uintptr_t m; ngx_int_t total; ngx_uint_t i, n, p; ngx_http_upstream_rr_peer_t *peer, *best; now = ngx_time(); best = NULL; total = 0; ... /* 遍历集群中的所有后端 */ for (peer = rrp-\u003epeers-\u003epeer, i = 0; peer; peer = peer-\u003enext, i++) { n = i / (8 * sizeof(uintptr_t)); m = (uintptr_t) 1 \u003c\u003c i % (8 * sizeof(uintptr_t)); /* 检查该后端服务器在位图中对应的位，为1时表示不可用 */ if (rrp-\u003etried[n] \u0026 m) continue; /* 永久不可用的标志 */ if (peer-\u003edown) continue; /* 在一段时间内，如果此后端服务器的失败次数，超过了允许的最大值，那么不允许使用此后端了 */ if (peer-\u003emax_fails \u0026\u0026 peer-\u003efails \u003e= peer-\u003emax_fails \u0026\u0026 now - peer-\u003echecked \u003c= peer-\u003efail_timeout) continue; peer-\u003ecurrent_weight += peer-\u003eeffective_weight; /* 对每个后端，增加其当前权重 */ total += peer-\u003eeffective_weight; /* 累加所有后端的有效权重 */ /* 如果之前此后端发生了失败，会减小其effective_weight来降低它的权重。 * 此后在选取后端的过程中，又通过增加其effective_weight来恢复它的权重。 */ if (peer-\u003eeffective_weight \u003c peer-\u003eweight) peer-\u003eeffective_weight++; /* 选取当前权重最大者，作为本次选定的后端 */ if (best == NULL || peer-\u003ecurrent_weight \u003e best-\u003ecurrent_weight) { best = peer; p = i; } } if (best == NULL) /* 没有可用的后端 */ return NULL; rrp-\u003ecurrent = best; /* 保存本次选定的后端 */ n = p / (8 * sizeof(uintptr_t)); m = (uintptr_t) 1 \u003c\u003c p % (8 * sizeof(uintptr_t)); /* 对于本次请求，如果之后需要再次选取后端，不能再选取这个后端了 */ rrp-\u003etried[n] |= m; best-\u003ecurrent_weight -= total; /* 选定后端后，需要降低其当前权重 */ /* 更新checked时间 */ if (now - best-\u003echecked \u003e best-\u003efail_timeout) best-\u003echecked = now; return best; } ","date":"2020-05-06","objectID":"/load_balance/:2:0","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"ip_hash ip_hash是基于客户端IP的哈希值来选择服务器。同一个客户端的请求，都会发往同一台后端，除非该后端不可用了。ip_hash能够达到保持会话的效果。 和随机加权哈希一样，ip哈希借鉴了权重分段的思想，先算出哈希值, 然后模余total_weight，得到初始权重W [0, total_weight)，开始遍历节点。如果哈希值小于当前节点的权重，就选择当前节点；如果哈希值大于等于当前节点的权重，就减去当前节点的权重，再去尝试下个节点。我们还是讨论A，B，C三个节点的情况，假设权重分别为2、4、1 。 权重的和是7，那么哈希值应该是0~6 （因为模了哈希值） 6的情况：6 \u003e= 2 , 所以不选A，减去2。 6-2 \u003e= 4，所以不选B，减去4。2-4 \u003c 1，所以选C 5的情况：5 \u003e= 2 , 所以不选A，减去2。 5-2 \u003c 4，所以选B 4的情况：4 \u003e= 2 , 所以不选A，减去2。 4-2 \u003c 4，所以选B 。哈希值为3、2的情况也一样。 1、0的情况：1 \u003c 2，所以选A 可以看到最后四个选B，两个选A，一个选C，还是均衡的。 for ( ; ; ) { /* 1.根据客户端IP、本次选取的初始hash值，计算得到本次最终的hash值 */ /* hash1 = (hash0 * 113 + addr[0]) % 6271; hash2 = (hash1 * 113 + addr[1]) % 6271;...; */ for (i = 0; i \u003c (ngx_uint_t) iphp-\u003eaddrlen; i++) hash = (hash * 113 + iphp-\u003eaddr[i]) % 6271; /* 2. 先给w赋值为所有节点的权重和。total_weight和weight都是固定值 */ w = hash % iphp-\u003errp.peers-\u003etotal_weight; peer = iphp-\u003errp.peers-\u003epeer; /* 第一台后端 */ p = 0; /* 3.遍历后端链表时，依次减去每个后端的权重，直到w小于某个后端的权重 */ while (w \u003e= peer-\u003eweight) { w -= peer-\u003eweight; peer = peer-\u003enext; p++; } break; } choose(p); ","date":"2020-05-06","objectID":"/load_balance/:3:0","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"least_conn 有的场景下，把请求转发给连接数较少的后端，能够达到更好的负载均衡效果。 least_conn算法很简单，首选遍历后端集群，比较每个后端的conns/weight，选取该值最小的后端。如果有多个后端的conns/weight值同为最小的，那么对它们采用加权轮询算法。 for (peer = peers-\u003epeer, i = 0; peer; peer = peer-\u003enext, i++) { /* 检查此后端在状态位图中对应的位，为1时表示不可用 */ n = i / (8 * sizeof(uintptr_t)); m = (uintptr_t) 1 \u003c\u003c i % (8 * sizeof(uintptr_t)); if (rrp-\u003etried[n] \u0026 m) continue; /* server指令中携带了down属性，表示后端永久不可用 */ if (peer-\u003edown) continue; /* 在一段时间内，如果此后端服务器的失败次数，超过了允许的最大值，那么不允许使用此后端了 */ if (peer-\u003emax_fails \u0026\u0026 peer-\u003efails \u003e= peer-\u003emax_fails \u0026\u0026 now - peer-\u003echecked \u003c= peer-\u003efail_timeout) continue; /* 比较各个后端的conns/weight，选取最小者； * 如果有多个最小者，记录第一个的序号p，且设置many标志。 */ if (best == NULL || peer-\u003econns * best-\u003eweight \u003c best-\u003econns * peer-\u003eweight) { best = peer; many = 0; p = i; } else if (peer-\u003econns * best-\u003eweight == best-\u003econns * peer-\u003eweight) many = 1; } /* 如果有多个后端的conns/weight同为最小者，则对它们使用轮询算法 */ if (many) { for (peer = best, i = p; peer; peer-\u003epeer-\u003enext, i++) { /* conns/weight必须为最小的 */ if (peer-\u003econns * best-\u003eweight != best-\u003econns * peer-\u003eweight) continue; peer-\u003ecurrent_weight += peer-\u003eeffective_weight; /* 对每个后端，增加其当前权重 */ total += peer-\u003eeffective_weight; /* 累加所有后端的有效权重 */ /* 如果之前此后端发生了失败，会减小其effective_weight来降低它的权重。 * 此后在选取后端的过程中，又通过增加其effective_weight来恢复它的权重。 */ if (peer-\u003eeffective_weight \u003c peer-\u003eweight) peer-\u003eeffective_weight++; /* 选取当前权重最大者，作为本次选定的后端 */ if (best == NULL || peer-\u003ecurrent_weight \u003e best-\u003ecurrent_weight) { best = peer; p = i; } } } ","date":"2020-05-06","objectID":"/load_balance/:4:0","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"一致哈希 当后端是缓存服务器时，经常使用一致性哈希算法来进行负载均衡。使用一致性哈希的好处在于，增减集群的缓存服务器时，只有少量的缓存会失效，回源量较小。常见的CDN架构都是使用一致性哈希。 我们知道的一致性哈希是一个环，每个哈希值对应的请求属于哈希值在环上遇到的下一个节点。为了使得请求分布更加均衡，我们建立了很多虚拟节点，请求会对应到虚拟节点的真实节点上。 创造虚拟节点 在nginx中，为了保证节点的权重，一般一个真实节点对应weight * 160个虚拟节点。 每个虚拟节点的hash值hash = crc32(base_hash PREV_HASH)，其中，PREV_HASH表示上个虚拟节点的哈希值，这样就可以不断产出虚拟节点。base_hash 表示对应真实节点的哈希值（crc32(HOST 0 PORT)）。 创造完所有数量后，我们对虚拟节点按照哈希值排序。 请求分配 先对请求做哈希，得出hash值，然后使用二分查找，寻找第一个hash值大于等于请求的哈希值的虚拟节点，即顺时针方向最近的一个虚拟节点。 找到真实节点 遍历真实节点数组，寻找可用的、该虚拟节点归属的真实节点(server成员相同)，如果有多个真实节点同时符合条件，那么使用轮询来从中选取一个真实节点。 for ( ; ; ) { /* 在peer.init中，已根据请求的哈希值，找到顺时针方向最近的一个虚拟节点， * hash为该虚拟节点在数组中的索引。 * 一开始hash值肯定小于number，之后每尝试一个虚拟节点后，hash++。取模是为了防止越界访问。 */ server = point[hp-\u003ehash % points-\u003enumber].server; best = NULL; best_i = 0; total = 0; /* 遍历真实节点数组，寻找可用的、该虚拟节点归属的真实节点(server成员相同)， * 如果有多个真实节点同时符合条件，那么使用轮询来从中选取一个真实节点。 */ for (peer = hp-\u003errp.peers-\u003epeer, i = 0; peer; peer = peer-\u003enext, i++) { /* 检查此真实节点在状态位图中对应的位，为1时表示不可用 */ n = i / (8 * sizeof(uintptr_t)); m = (uintptr_t) 1 \u003c\u003c i % (8 * sizeof(uintptr_t)); if (hp-\u003errp.tried[n] \u0026 m) continue; /* server指令中携带了down属性，表示后端永久不可用 */ if (peer-\u003edown) continue; /* 如果真实节点的server成员和虚拟节点的不同，表示虚拟节点不属于此真实节点 */ if (peer-\u003eserver.len != server-\u003elen || ngx_strncmp(peer-\u003eserver.data, server-\u003edata, server-\u003elen) != 0) continue; /* 在一段时间内，如果此真实节点的失败次数，超过了允许的最大值，那么不允许使用了 */ if (peer-\u003emax_fails \u0026\u0026 peer-\u003efails \u003e= peer-\u003emax_fails \u0026\u0026 now - peer-\u003echecked \u003c= peer-\u003efail_timeout) continue; peer-\u003ecurrent_weight += peer-\u003eeffective_weight; /* 对每个真实节点，增加其当前权重 */ total += peer-\u003eeffective_weight; /* 累加所有真实节点的有效权重 */ /* 如果之前此真实节点发生了失败，会减小其effective_weight来降低它的权重。 * 此后又通过增加其effective_weight来恢复它的权重。 */ if (peer-\u003eeffective_weight \u003c peer-\u003eweight) peer-\u003eeffective_weight++; /* 选取当前权重最大者，作为本次选定的真实节点 */ if (best == NULL || peer-\u003ecurrent_weight \u003e best-\u003ecurrent_weight) { best = peer; best_i = i; } } /* 如果选定了一个真实节点 */ if (best) { best-\u003ecurrent_weight -= total; /* 如果使用了轮询，需要降低选定节点的当前权重 */ goto found; } hp-\u003ehash++; /* 增加虚拟节点的索引，即“沿着顺时针方向” */ hp-\u003etries++; /* 已经尝试的虚拟节点数 */ } ","date":"2020-05-06","objectID":"/load_balance/:5:0","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"恐慌阈值 Envoy 负载均衡一般是根据集群中主机的健康情况灵活变动的。当某台主机跪了，LB算法将会把它从候选列表中踢出去，这也是很合理的。 但是我们假设这么一种情况，某一时间，所有服务主机的负载情况是最大负载的80%，（负载800；最大处理能力1000） 因为某种原因，导致20.0%的机器彻底崩溃。（负载800；最大处理能力800） LB策略忽略20%的机器，导致剩下的80%的机器都在最大处理负载上运行； 又来了一个网络波动，造成所有的服务器一个接一个崩溃，整个集群雪崩。 每拉起一台新的机器，LB策略立刻把所有的流量打到这么一台机器上，导致它再次崩溃。 如果有一个恐慌阈值，譬如50%，那么LB会在50%机器崩溃的时候，禁用淘汰策略，把所有机器都当做健康的，在整体集群上执行普通的Round-Robin策略。 多数机器恢复，整个集群的处理能力恢复80%的正确率。这使得整个集群能够在遇到极特殊情况的时候能够从困境中恢复 LB用的负载均衡算法 ","date":"2020-05-06","objectID":"/load_balance/:6:0","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"EDF调度算法 EDF调度算法 最早截止时间优先调度法 Earliest Deadline First (EDF) scheduler，是加权轮转调度算法（WRR，Weighted Round-Robin）的一种实现方式。 其核心思想是为每个条目截止时间赋值为当前时间加权重的倒数，然后采用最早截止时间优先的方式进行调度。 调度算法最主要的应用是操作系统调度进程，重要的调度理论基本上都是在此时涌现的。而后续反向代理对下游条目进行负载均衡，也可以参考一样的调度理论，只是进程的运行和切换转变为请求的接受与投递。 假设有三个条目可供调度，分别是A、B、C，他们的权重分别是3：2：1。 图上有一个数轴，从0到3，分别表示三个周期。 A条目的权重是3，我们以1/3为分隔不断重绘A，使得数轴的1/3，2/3，1，4/3等位置印上A； B条目的权重是2，我们以1/2为分隔不断重绘B，使得数轴的1/2，1，3/2，2等位置印上B； C条目的权重是1，我们以1为分隔不断重绘C，使得数轴的1，2，3等位置印上C； 最后，我们使用一个游标从左向右扫，扫描到的顺序就是调度的顺序，因此我们调度的顺序为A-B-A-C-B-A-A-B-A… 显而易见，调用的顺序含有一个循环节A-B-A-C-B-A，所以当调度足够多次数后，A、B、C的调度比值将会趋近于3：2：1 ","date":"2020-05-06","objectID":"/load_balance/:7:0","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"实现1 最简单的实现，是使用上述办法模拟一个周期，然后把周期存到数组中，用游标扫描即可。 以上述情形为例，首先我们定制一个数组 A-B-A-C-B-A，然后不断回环扫描这个数组，就可以完成加权轮转调度。 这种方法的每次调度的时间复杂度为O(1)，空间复杂度为O(M*N)，其中M是条目的平均权重，N是条目的数量。 优势： 实现简单，容易理解 单次调度的很快 多线程共享游标index即可，协作方便 劣势： 空间复杂度高 对条目修改很不友好（修改其中一个条目的权重，那么整个表需要重新构建，耗CPU） ","date":"2020-05-06","objectID":"/load_balance/:7:1","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["后台"],"content":"实现2 我们可以维护一个大小为节点数量的堆，按照最快到期时间来排序，每次取最快到期的节点（就是线段上最靠前的节点），返回后更新它的节点到期时间。 初始时 entry.deadline = 1.0/entry.Weight 调度的时候，从中选择 deadline 最小的使用，并把 deadline 设置为 ttl（当前时间）+ 1.0/entry.Weight，然后重新把这个条目放入优先队列中。重新排布优先队列，如此往复。 举个例子： 三个节点A、B、C权重分别为5、2、1 请求序号 选择的节点 选择节点后的堆 选择时的TTL 未请求 / [A(1/5), B(1/2), C(1)] 0 1 A [A(2/5), B(1/2), C(1)] 1/5 2 A [B(1/2), A(3/5), C(1)] 2/5 3 B [A(3/5), B(1), C(1)] 1/2 4 A [A(4/5), B(1), C(1)] 3/5 5 A [A(1), B(1), C(1)] 4/5 6 A [B(1), C(1), A(6/5)] 1 7 B [C(1), A(6/5), B(3/2)] 3/2 8 C [A(6/5), B(3/2), C(2)] 1 复杂度分析： 空间复杂度降低为 O(N) ，每次Pick的时间复杂度为 O(logN) 初始化的时间复杂度为 O(N)，也就是堆排序的复杂度 // 节点 type Entry struct { deadline float64 index int64 Value string Weight float64 } // EDF implements the Earliest Deadline First scheduling algorithm type EDF struct { pq *priorityQueue //这个优先级队列用deadline排序 curIndex int64 curDDL float64 } // Add a new entry for load balance func (e *EDF) Add(entry *Entry) { entry.deadline = e.curDDL + 1/entry.Weight e.curIndex++ entry.index = e.curIndex heap.Push(e.pq, entry) } // AddRaw add a new entry for load balance without sort func (e *EDF) AddRaw(entry *Entry) { entry.deadline = e.curDDL + 1/entry.Weight e.curIndex++ entry.index = e.curIndex *e.pq = append(*e.pq, entry) } // Delete an entry func (e *EDF) Delete(entry *Entry) { entry.Weight = -1 } // Pick an available entry func (e *EDF) Pick() *Entry { // if no available entry, return nil if len(*e.pq) \u003c= 0 { return nil } entry := heap.Pop(e.pq).(*Entry) if entry.Weight \u003c= 0 { // if Weight isn't positive, try another entry return e.Pick() } // curDDL should be entry's deadline so that new added entry would have a fair // competition environment with the old ones e.curDDL = entry.deadline entry.deadline = entry.deadline + 1/entry.Weight e.curIndex++ entry.index = e.curIndex heap.Push(e.pq, entry) return entry } // NewEDF create a new edf scheduler func NewEDF(entries []*Entry) *EDF { // make a new edf priorityQueue := make(priorityQueue, 0) edf := \u0026EDF{ pq: \u0026priorityQueue, curIndex: 0, } // put entries into priority queue // TODO(maziang): use O(N) heap.Init instead of O(NlogN) Add. for _, entry := range entries { edf.AddRaw(entry) } heap.Init(edf.pq) // avoid instance flood pressure for the first entry // start from a random one via pick random times rand.Seed(time.Now().UnixNano()) randomPick := rand.Intn(len(entries)) for i := 0; i \u003c randomPick; i++ { edf.Pick() } return edf } Note1 同样权重的情况: index是节点进入堆的次序。当deadline一样时，会选取index小的那一个。这是为了避免当所有节点权重一样时，变成完全随机调度。如果有了index，那么每次选取之后该节点的index会加一（相当于排到后面去），这样就能保证下一个节点能被调度到。 Note2 存储空间优化： Note3 起始随机化：如果有个节点权重很大，那么在调度器全部重启的时候可能都会调度到这个节点，导致这个节点压力过大。所以NewEDF的初始化阶段会有随机化操作。 ","date":"2020-05-06","objectID":"/load_balance/:7:2","tags":["负载均衡","算法","后台"],"title":"[后台]负载均衡 （一）算法篇","uri":"/load_balance/"},{"categories":["Linux"],"content":"Linux中一切皆文件。但是内核中设计了复杂的I/O缓存和文件结构，在带来方便的同时也带来了拷贝的成本。本文介绍了文件的基本API和数据结构，还有内核和标准库在I/O加速上所做的努力，以及如何灵活避免这些加速，做到零拷贝。","date":"2019-10-31","objectID":"/linux_io/","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"文件 ","date":"2019-10-31","objectID":"/linux_io/:1:0","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"文件描述符 文件描述符：在Linux中，所有的文件都是通过文件描述符引用。fd是一个非负整数。按照惯例，标准输入的fd是0，标准输出的fd是1，标准错误的fd是2。分别作为STDIN_FILENO、STDOUT_FILENO、STDERR_FILENO定义在unistd中。 文件描述符的上限：fd的范围是 0 ~ OEPN_MAX-1 。OPEN_MAX一般是20或者64。这代表一个进程最多打开19或63个文件。 ","date":"2019-10-31","objectID":"/linux_io/:1:1","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"文件内核API 文件的打开：int open(const char *pathname, int flags)参数填上要打开的文件的名字（甚至可以不存在），会返回打开的fd。下面是一些常用的选项： O_APPEND 文件将以追加模式打开，每次写操作之前，文件偏移量都会置于文件末尾。 O_CREAT 创建文件。如果文件已经存在，则会直接打开。 O_EXCL 和上面的O_CREAT联用时，表示如果文件已经存在，就会失败。可以保证多进程同时创建文件的原子操作。 O_SYNC 打开文件用于同步I/O。在数据写到磁盘之前写操作不会完成；一般的读操作已是同步的，所以这个标志对读操作没有影响。 O_NONBLOCK 如果可以，文件将在非阻塞模式下打开。任何其它操作都不会使该进程在I/O中阻塞。这种情况可能只用于FIFO。 O_DIRECT 打开文件用于直接I/O。将会绕过缓冲区操作。 文件的关闭：int close(int fd) 关闭一个文件会释放上面所有的记录锁。一个进程终止后，内核会自动关闭它打开的所有文件。 文件定位： off_t lseek(int fd, off_t offset, int whence) 参数whence指定了偏移地址（开始点SEEK_SET 当前点SEEK_CUR 结束点SEET_END），另一个参数offset是从参考点开始的偏移量（可正可负）。返回新的偏移地址。 空洞文件：如果写入一部分之后lseek到后面去写入，中间就会产生一个空洞，实际不占用磁盘大小。 文件读取：ssize_t read(int fd, void *buf, size_t nbytes) 返回读取到的字节数。下面的情况可能使得读取到的字节数少于需要的字节数： 1)再读这么多就到了文件尾 2)读网络缓冲区读完 3)读FIFO管道包含的字节少于需要的长度 4)读终端设备，一次一行 文件写入：ssize_t write(int fd, const void* buf, size_t nbytes) 返回写入的字节数。一般和nbytes相同。 文件属性编辑：int fcntl(int fd, int cmd, ... /* arg */ ) 提供了编辑fd属性标志的方法。 ","date":"2019-10-31","objectID":"/linux_io/:1:2","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"read buf该设置多大 在Linux ext4系统上，磁盘块长度st_blksize为4096字节。测试表明，在4096的整数倍上，读磁盘有更快的速率，可以根据需要选择4096或8192等字节的buf。 系统为了优化频繁写磁盘的情况，会使用预读取（read ahead）技术，在检测到顺序读时，会比本次读取需要的读出更多的数据，读入缓冲区。 ","date":"2019-10-31","objectID":"/linux_io/:1:3","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"文件结构 要设计一个多线程读取文件的程序，必须先知道文件和线程的关系。内核用3张表表示打开的文件，他们分别是： 进程中的文件表，记录着进程打开的所有文件。每个文件用了一个fd标志和一个文件指针（指向2）表示。 内核为每个进程打开的每个文件创建了一个文件表，包含了文件状态标志、文件偏移量和i-node指针。需要注意不同进程打开了不同文件的时候，会有两个文件表。所以并发读取是安全的。 每个文件都对应一个i-node。这个node里包含了文件的磁盘块位置、文件的长度、拥有者、权限等。这些信息会被读入内存。 Note1：磁盘划分为数据区和i-node区，一般每4个块（一个块为4K，8个扇区）就会有一个i-node，占地256字节。每创建一个文件，系统就分配一个i-node给文件，并把文件名和i-node编号关联起来。查找的时候，根据文件名找到编号，再找到文件的磁盘位置。 Note2：每次write完毕，内核文件表2中的文件偏移量都会增加写入的字节数。如果此时文件的偏移量大于i-node记录的文件长度，i-node记录会被更新为这个偏移量（文件变长）。 Note3：O_APPEND会被写内核文件表2中的文件状态标志中。这样，每次write发现这个标志，都会先把文件偏移量设置为i-node的文件长度，这样就可以写到尾端。 Note4：lseek只改变内核文件表2的文件偏移量，不进行任何I/O操作。 Note5：如果子进程是父进程fork出来的，那么他们会共享2中的内核文件表。 这三个表的关系如下图所示。下面有两个进程打开了同一文件： ","date":"2019-10-31","objectID":"/linux_io/:1:4","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"原子操作 假设有两个进程要不断往一个日志文件的结尾添加日志。你可能写出下面的代码： if (lseek(fd, OL, 2) \u003c 0)error(\"lseek error\"); if (write(fd, buf, 100) \u003c 0)error(\"write error\"); 即使linux保证了他的系统调用是原子的，但是还是肯能发生如下的操作序列： A进程seek到文件尾，文件长度1500，偏移量1500。 B进程seek到文件尾，文件长度1500，偏移量1500。 B进程write 100字节，从1500开始写，文件长度1500-\u003e1600。 A进程write 100字节，从1500开始写，覆盖了B的写入。 Linux提供了下面的原子函数，结合了lseek和读写，保证了这种操作的原子性。 ssize_t pread(int fd, void *buf, size_t count, off_t offset); ssize_t pwrite(int fd, const void *buf, size_t count, off_t offset); 另一种方式是采用O_APPEND。这种模式保证了每次写的时候偏移量都在文件尾，所以不同竞争进程间不会为了偏移量相互影响。一些开源软件的日志就是这么实现的。 除了这个例子外，O_EXCL也用于打开文件时保证原子性。如果没有这个标志，一个进程创建文件可能会分为检查文件是否存在、创建文件两步，有可能发生重复创建导致数据丢失的情况。 ","date":"2019-10-31","objectID":"/linux_io/:1:5","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"内核的I/O Cache read和write操作如果相当频繁，一方面会带来频繁的系统调用，另一方面，读写磁盘的效率远远跟不上。所以unix系统在I/O方面做了内核的优化，一方面用缓冲区削峰，把write调用再内存中整合后再写入磁盘（一般是list结构），另一方面把热点数据也缓存在内存中，使得read调用大部分都命中内存而不是磁盘（一般是hashmap）。 ","date":"2019-10-31","objectID":"/linux_io/:2:0","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"缓冲区缓存 Buffer Cache unix系统中最朴素的I/O加速技术就是缓冲区。在调用write时，内核将数据拷贝到缓冲区中，然后排入队列，晚些时候一起写入磁盘。这种方法称为延迟写（delayed write）。延迟写可能有一些问题需要担心： 此时read会不一致吗？如果一个read调用在写入磁盘前读取还未刷盘的这部分数据，内核将从缓冲区中读取，而不是读取磁盘上陈旧的数据。 会改变写顺序吗？内核将会把缓冲区队列的数据重新安排，所以写顺序会被改变。但是，写的位置并不会改变，很少有对写顺序有要求的程序。 刷盘时错误怎么办？刷盘错误程序不会感知，所以比如掉电等故障中没刷盘成功的数据会丢失。内核一般会用10ms的间隔来刷盘保证丢失的数据不会太多。 以下两个条件会触发刷盘： 当空闲内存小于设定的阈值时，脏的缓冲区就会回写到磁盘上，被清理的缓冲区可能会被移除，来释放内存空间。 当一个脏的缓冲区寿命超过设定的阀值时（一般为10ms），缓冲区被回写至磁盘。以此来避免数据的不确定性。 ","date":"2019-10-31","objectID":"/linux_io/:2:1","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"页缓存 Page Cache 相比起CPU而言，现在的磁盘速度远远落后。所以主存中会存有一份磁盘中常用数据的拷贝，以便于以后操作只操作主存，减少磁盘访问。那放哪些数据进去呢？这是一些思考： 时间局部性：该方法的思考是，刚被访问的资源很可能会在不久后再次被访问。页缓存是内核寻找文件系统数据的第一目的地。只有缓存中找不到时内核，才会调用存储子系统从磁盘中读取数据。当数据第一次读取后，就会从磁盘读 入页缓存中，并从缓存中返回给应用。如果那项数据被再次读取，就直接从缓 空间局部性：是关于数据的连续使用的性质。基于这个原理，内核实现了页缓存预读技术。预读是在每次读请求时从磁盘数据中读取更多的数据到页缓存中的动作一—多读一点点会很有效。当内核从磁盘读取一块数据时，也会读取接下来一两块数据。一次读取较大的连续数据块时磁盘不需要经常寻道，所以会比较有效。 ","date":"2019-10-31","objectID":"/linux_io/:2:2","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"Cache的同步 主动刷盘 fsync 同步I/O函数提供了针对单文件的主动刷盘： // 把缓冲区刷盘 void sync(viod); // 把某个fd的文件属性和文件刷盘 int fsync(int fd); // 把某个fd的文件刷盘 int fdatasync(int fd); 主动刷盘 O_SYNC O_SYNC看起来就像是在每个write操作后都隐式地执行fsync。尽管这在语法上是毫无问题的，但Linux内核实现的O_SYNC效率会更高。 O_SYNC 根据写入文件的大小，可能会使大量的时间消耗在进程的I/O等待时间上，此时的O_SYNC会使总耗时增加一到两个数量级。这种时间开销增长是非常可观的，所以同步I/O一般是在无计可施情况下的最后选择。一般情况下在关键操作之后使用fsync会更加合理。 直接IO 内核的I/O Cache给我们带来了很多便利，但是我们无法预知I/O系统的复杂行为。尤其在一些数据库的应用中，他们倾向于自己做缓存。使用O_DIRECT标志会使内核最小化I/O管理的影响，直接写到磁盘。使用这个标志时，注意下面几点： I/O操作将忽略页缓存机制，直接对用户空间缓冲区和设备进行初始化。 所有的I/O将是同步的，操作在完成之前不会返回。 当使用直接I/O时，请求长度，缓冲区对齐，和文件偏移必须是设备扇区大小（通常是512字节）的整数倍。 ","date":"2019-10-31","objectID":"/linux_io/:2:3","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"I/O Cache的一些思考 Buffer和Cache的区别是什么？ 1、Buffer（缓冲区）是系统两端处理速度平衡（从长时间尺度上看）时使用的。它的引入是为了减小短期内突发I/O的影响，起到流量整形的作用。比如生产者——消费者问题，他们产生和消耗资源的速度大体接近，加一个buffer可以抵消掉资源刚产生/消耗时的突然变化。 2、Cache（缓存）则是系统两端处理速度不匹配时的一种折衷策略。因为CPU和memory之间的速度差异越来越大，所以人们充分利用数据的局部性（locality）特征，通过使用存储系统分级（memory hierarchy）的策略来减小这种差异带来的影响。 Buffer和Cache需要同步吗？ buffer和cache在Linux 2.4之前是两种缓存，也就是说同一份数据有两份内容在内核中。这两份数据的同步和维护其实带来了一些麻烦。在Linux 2.4之后，人们想到了统一这两种缓存，就把buffer指向了cache，使得数据只剩下一份实体。对于为什么是cache作为了主要的语义，参见这里。 ","date":"2019-10-31","objectID":"/linux_io/:2:4","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"IO栈 我们上面只说明了内核中的文件系统做的操作，在写入磁盘之前还有几个步骤。Linux下的IO栈致大致有三个层次： 文件系统层，以write(2)为例，内核拷贝了write(2)参数指定的用户态数据到Page Cache中，并适时向下层同步 块层，管理块设备的IO队列，对IO请求进行合并、排序（IO调度算法和blk-mq都在这一层） 设备层，通过DMA（一种磁盘、网卡等直接写内存的快速通道，不需要CPU参与）与内存直接交互，完成数据和具体设备之间的交互 传统的Buffered IO使用read(2)读取文件的过程什么样的？假设要去读一个冷文件（Cache中不存在） open(2)打开文件内核后建立了一系列的数据结构 接下来调用read(2)，到达文件系统这一层，发现Page Cache中不存在该位置的磁盘映射，然后创建相应的Page Cache并和相关的扇区关联。 然后请求继续到达块设备层，在IO队列里排队，接受一系列的调度后到达设备驱动层，此时一般使用DMA方式读取相应的磁盘扇区拷贝到Page Cache中 然后read(2)拷贝数据到用户提供的用户态buffer中去（read(2)的参数指出的）。 可以看到，一次read总共进行了三次拷贝。相对地，我们以socket收发一次数据为例，看看需要什么成本： 图中总共进行了4次拷贝（其中两次是DMA拷贝，CPU没参与），4次上下文切换。大量数据的拷贝，用户态和内核态的频繁切换，会消耗大量的 CPU 资源，严重影响数据传输的性能，有数据表明，在Linux内核协议栈中，这个拷贝的耗时甚至占到了数据包整个处理流程的57.1%。这就是I/O加速带给我们的代价。 ","date":"2019-10-31","objectID":"/linux_io/:2:5","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"stdio 上面可以看到，对系统进行和磁盘快大小整数倍的读写时，I/O的效率最高。仅仅是内核的I/O优化还不够，需要对普通文件执行许多轻量级I/O请求的程序通常使用用户缓冲I/O。用户缓冲I/O是在用户空间而不是在内核中完成的，它可以在程序中设定，也可以调用标准库透明地执行。一般程序可选的I/O优化有几种： 直接使用内核提供的write和read系统调用。 使用stdio提供的fgetc fgets fread fputc fputs fwrite等带用户态缓冲区的标准库函数。 自己实现用户态缓冲区，用自己的用户态缓冲区+write和read系统调用。 自己实现用户态缓冲区和内核缓冲区，使用Direct I/O读写磁盘。 用户态缓冲区的基本思想是，如果是写请求，先在缓冲区存一份数据，然后在一个缓冲区满的时候再调用write写进去。最合适的缓冲区大小是和磁盘块对齐的，一般4096或者8192的大小速度就会达到最快。如果是读请求，缓冲区就会成块读取数据，当一个块被读完后再预先读一块。无论读取的时候有没有对齐，缓冲区总会对齐了读。 ","date":"2019-10-31","objectID":"/linux_io/:3:0","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"设置缓冲区 int setvbuf (FILE *stream, char *buf, int mode, size_t size) // 1. 该函数设置流的缓冲类型模式，模式必须是以下的一种： IONBF //无缓冲 每输入一个字符，就刷入内核缓冲区 IOLBF //行缓冲 遇到换行符，就刷入内核缓冲区 IOFBF //块缓冲 默认的文件缓冲。每写满一个磁盘块就刷入一次 // 2. buf可以设置为自定义的缓冲区。如果不需要就设置为空，系统会自动分配。 // 3. 要特别注意buf的生命周期。buf必须在流刚打开时就设置。另外，buf必须在流关闭时依然没被回收。 ","date":"2019-10-31","objectID":"/linux_io/:3:1","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"清洗缓冲区 int fflush(FILE *stream) 会把stream指向的流中的所有未写入的数据会被清洗到内核中。如果stream是NULL，所有进程打开的流会被清洗掉。 fflush只是把用户缓冲的数据直接调用write写入到内核缓冲区。这并不保证数据能够写入物理介质，如果需要的话，请使用fsync这一类函数。 一般可以在调用fflush后，立即调用fsync，这样可以直接刷到磁盘上。主要注意用户态的fwrite一类的函数一定不要和write一类的系统调用同时使用。 ","date":"2019-10-31","objectID":"/linux_io/:3:2","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"零拷贝 之前的章节可以看到，内核中的I/O缓存虽然给我们带来了磁盘读写速度的便利，但是确牺牲了很多的CPU时间。其实有很多拷贝不是必须的，我们也有一些手段去避免无用的反复拷贝和上下文切换。 ","date":"2019-10-31","objectID":"/linux_io/:4:0","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"mmap 我们可以用mmap把数据直接映射到内核的Page Cache，这样就可以少一次用户态到内核的拷贝： tmp_buf = mmap(file, len); write(socket, tmp_buf, len); mmap copy 图中可以看到，DMA引擎将文件内容复制到内核缓冲区中，然后与用户进程共享缓冲区。这不会在内核和用户存储器空间之间执行任何复制。 mmap是有代价的。例如，当你的程序map了一个文件，但是当这个文件被另一个进程截断(truncate)时, write系统调用会因为访问非法地址而被SIGBUS信号终止。SIGBUS信号默认会杀死你的进程并产生一个coredump,如果你的服务器这样被中止了，那会产生一笔损失。 通常我们使用以下解决方案避免这种问题： 处理SIGBUS信号 当遇到SIGBUS信号时，信号处理程序简单地返回，write系统调用在被中断之前会返回已经写入的字节数，并且errno会被设置成success。但是这是一种糟糕的处理办法，因为你并没有解决问题的实质核心。 使用文件租借锁 我们为文件向内核申请一个租借锁，当其它进程想要截断这个文件时，内核会向我们发送一个实时的RT_SIGNAL_LEASE信号，告诉我们内核正在破坏你加持在文件上的读写锁。这样在程序访问非法内存并且被SIGBUS杀死之前，你的write系统调用会被中断。write会返回已经写入的字节数，并且置errno为success。 ","date":"2019-10-31","objectID":"/linux_io/:4:1","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"sendfile 如果是给套接字发数据，sendfile提供了一种从一个fd中读取内容写入到另一个fd的方式。 ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count) 描述符out_fd必须指向一个套接字，而in_fd指向的文件必须是可以mmap的(sendfile只能将数据从文件传递到套接字上) 。 offset标识了从in_fd中读取的位置，count则表明读取的长度。 如果是管道，可以用下面的splice（两个fd至少有一个是管道）： ssize_t splice(int fd_in, loff_t *off_in, int fd_out, loff_t *off_out, size_t len, unsigned int flags) 图中可以看到，sendfile可以直接把文件从内核缓冲区拷贝到socket缓冲区。虽然也是三次复制，但是少了一次陷入用户态的上下文切换。在我们调用sendfile时，如果有其它进程截断了文件会发生什么呢？假设我们没有设置任何信号处理程序，sendfile调用仅仅返回它在被中断之前已经传输的字节数，errno会被置为success。如果我们在调用sendfile之前给文件加了锁，sendfile的行为仍然和之前相同，我们还会收到RT_SIGNAL_LEASE的信号 ","date":"2019-10-31","objectID":"/linux_io/:4:2","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"sendfile with DMA 常规 sendfile 还有一次内核态的拷贝操作，能不能也把这次拷贝给去掉呢？ 答案就是这种 DMA 辅助的 sendfile。 这种方法借助硬件的帮助，在数据从内核缓冲区到 socket 缓冲区这一步操作上，并不是拷贝数据，而是拷贝缓冲区描述符，待完成后，DMA 引擎直接将数据从内核缓冲区拷贝到协议引擎中去，避免了最后一次拷贝。 ","date":"2019-10-31","objectID":"/linux_io/:4:3","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"写时复制（COW），fbuf，netmap 一些其他的零拷贝技术，参见 知乎上的零拷贝 Zero Copy I: User-Mode Perspective ","date":"2019-10-31","objectID":"/linux_io/:4:4","tags":["Linux","文件","AUPE"],"title":"[Linux]文件和零拷贝","uri":"/linux_io/"},{"categories":["Linux"],"content":"socket支持传输层的各种协议，是网络通信的基础组件。本文介绍了socket的创建和关闭、通信、socket地址的结构和获取等内容，并提供了有连接和无连接socket的示例。","date":"2019-10-21","objectID":"/socket/","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"创建和关闭 int socket(int domain, int type, int protocol) 创建一个socket。 domain 指定了通信的特性。AF_UNIX Unix域，AF_INET IPv4域。 AF_INET6 IPv6域。 type 指定了连接的类型。 SOCK_STREAM 有序、可靠、双向、面向连接的字节流 TCP SOCK_DGRAM 不可靠、无连接、固定长度的报文 UDP SOCK_SEQPACKET 固定长度、有序、可靠、双向、面向连接的字节流 protocol 为0时，选择指定域的默认协议。AF_INET域的SOCK_STREAM默认的协议为TCP，SOCK_DGRAM则为UDP。还有IPPROTO_ICMP、IPPROTO_IP、IPPROTO_RAW等。SOCK_STREAM提供字节流服务，所以程序分不出报文的界限。 int shutdown(int socketfd, int how) 关闭一个socket。 套接字函数是双向的。可以用这个函数关闭套接字的某个方向的IO。 how是SHUT_RD表示关闭读端，无法从套接字读取数据。SHUT_WR是关闭写端，无法向套接字写入数据。SHUT_RDWR无法读也无法写。 close()是一个fd的通用释放函数。他和shutdown有何不同？1) close要等所有的活动引用关闭后才释放套接字。这使得dup之后的套接字必须等待所有的引用释放。但是shutdown和引用fd数量无关。2)shutdown可以方便地关闭读写的任何一端。 ","date":"2019-10-21","objectID":"/socket/:1:0","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"网络地址 ","date":"2019-10-21","objectID":"/socket/:2:0","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"地址的结构体 // Linux 套接字 // 这是Linux定义的一个通用结构。所有地址都可以强转为这个结构体，比如IPV4、IPV6等，便于使用。 struct sockaddr { u_short sa_family; /* address family */ char sa_data[14]; /* up to 14 bytes of direct address */ }; // IPv4 地址 // 1. in_port_t 是16位的网络序整数，需要htons转换到网络序再赋值 // 2. sin_addr 有几种常见的常量，INADDR_ANY表示所有网卡 sockaddr_in { sa_family_t sin_family; in_port_t sin_port; /* Port number. (typedef uint16_t in_port_t)*/ struct in_addr sin_addr; /* Internet address. （typedef uint32_t in_addr_t)*/ unsigned char sin_zero[8]; /* sockaddr 里sa_data定义的14(sa_data)-2(sin_port)-4(sin_addr)=8字节*/ } ","date":"2019-10-21","objectID":"/socket/:2:1","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"网络序 下面的函数提供了网络序端口和主机序端口（int类型）转换的方法。 uint32_t htonl(uint32_t hostint32)返回以网络序（大端序）表示的整数。 uint16_t htons(uint16_t hostint32) uint32_t ntohl(uint32_t netint32) 返回以主机序（小端序）表示的整数。 uint16_t ntohs(uint16_t netint32) ","date":"2019-10-21","objectID":"/socket/:2:2","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"地址和字符串的转换 const char *inet_ntop(int af, const void *src, char *dst, socklen_t size)地址到字符串。 int inet_pton(int af, const char *src, void *dst) 字符串到地址。 其中，af有AF_INET和AF_INET6两个值。src是地址，dst是输出的字符串。size是字符串大小。 这两个函数的工作是把二进制和字符串互转，例如将串192.168.33.123 转为 1100 0000 1010 1000 0010 0001 0111 1011。每八位代表IP地址中的一段，比如末尾的0111 1011就是123。 一个例子： struct in_addr addr; if(inet_pton(AF_INET, \"127.0.0.1\", \u0026addr.s_addr) == 1) printf(\"NetIP: %x\\n\", addr.s_addr); //NetIP: 100007f char str[20]; if(inet_ntop(AF_INET, \u0026addr.s_addr, str, sizeof str)) printf(\"StrIP: %s\\n\", str); //StrIP: 127.0.0.1 一些老的函数，只能用于IPV4： in_addr_t inet_addr(const char *cp) 字符串直接初始化为地址。（仅用于IPV4） int inet_aton(const char *cp, struct in_addr *inp) 字符串到地址。（仅用于IPV4） int inet_ntoa(const char *cp, struct in_addr *inp) 地址到字符串。（仅用于IPV4） ","date":"2019-10-21","objectID":"/socket/:2:3","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"地址查询 int getaddrinfo(const char *node, const char *service, const struct addrinfo *hints, struct addrinfo **res); node可以是域名、IP，如 www.qq.com service可以是http或者端口号，其定义在/etc/services文件中。这个文件的作用是使程序可以在其代码中进行getportbyname接字调用，以了解应使用的端口。例如，POP3电子邮件守护程序将执行getportbyname(POP3)，以检索运行POP3的数字110。 hints 是一系列选项。res是返回的地址结果。我们可以用下面的例子使用它： #define _POSIX_SOURCE #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetdb.h\u003e #include \u003carpa/inet.h\u003e #include \u003cnetinet/in.h\u003e int main(int argc, char **argv) { int status; struct addrinfo hints, *res, *this; char ipaddr[INET6_ADDRSTRLEN]; if (argc != 2) { fprintf(stderr, \"usage: showip hostname\\n\"); return 1; } memset(\u0026hints, 0, sizeof hints); hints.ai_family = AF_UNSPEC; /* AF_INET(IPv4) AF_INET6(IPv6) */ hints.ai_socktype = SOCK_STREAM; /* TCP stream sockets */ if ((status = getaddrinfo(argv[1], NULL, \u0026hints, \u0026res))) { fprintf(stderr, \"getaddrinfo: %s\\n\", gai_strerror(status)); return 2; } printf(\"IP addresses for %s:\\n\\n\", argv[1]); for(this = res; this != NULL; this = this-\u003eai_next) { void *addr; char *ipver; if (this-\u003eai_family == AF_INET) { /* IPv4 */ struct sockaddr_in *ipv4; ipv4 = (struct sockaddr_in *)this-\u003eai_addr; addr = \u0026(ipv4-\u003esin_addr); ipver = \"IPv4\"; } else { /* IPv6 */ struct sockaddr_in6 *ipv6; ipv6 = (struct sockaddr_in6 *)this-\u003eai_addr; addr = \u0026(ipv6-\u003esin6_addr); ipver = \"IPv6\"; } /* convert the IP to a string and print it */ inet_ntop(this-\u003eai_family, addr, ipaddr, sizeof(ipaddr)); printf(\"%s:\\t%s\\n\", ipver, ipaddr); } return 0; } ","date":"2019-10-21","objectID":"/socket/:2:4","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"绑定端口 int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen) 服务端给自己绑定一个众所周知的地址。 一个端口一般只能绑定一个socket。 端口号必须大于1024，除非是root用户。 如果没有bind，在connect或者listen时系统会自动bind。这时候可以用其他函数来查询socket的地址。下面两个函数，一个查本地的地址，一个查远端的地址。 int getsockname(int sockfd, struct sockaddr *addr, socklen_t *addrlen) 查找一个本地的fd绑定的socket。 int getpeername(int sockfd, struct sockaddr *addr, socklen_t *addrlen) 查找一个本地的fd连接的远程socket。 下面这段代码给了一个获取远端socket地址的简短例子。 // client int rc; int sockfd; struct sockaddr_in addr; addr.sin_addr.s_addr = inet_addr(\"127.0.0.1\"); addr.sin_family = AF_INET; addr.sin_port = htons(8888); printf(\"Server ip=%s port=%d\\n\", inet_ntoa(addr.sin_addr), ntohs(addr.sin_port)); sockfd = socket(AF_INET, SOCK_STREAM, 0); rc = connect(sockfd, (const struct sockaddr *)\u0026addr, sizeof(struct sockaddr_in)); struct sockaddr_in svraddr; socklen_t len = sizeof(struct sockaddr_in); getsockname(sockfd,(struct sockaddr *)\u0026svraddr, \u0026len); printf(\"Local #%d ip=%s port=%d\\n\", sockfd, inet_ntoa(svraddr.sin_addr), ntohs(svraddr.sin_port)); close(sockfd); ","date":"2019-10-21","objectID":"/socket/:3:0","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"有连接的socket的准备工作 ","date":"2019-10-21","objectID":"/socket/:4:0","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"客户端 (socket-connect-write-read-close) 客户端的write-read这三步都是默认阻塞的。socket-connect-close会立即返回。 int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen) 连接一个指定的服务器。 如果socket是STREAM或者SEQPACKET，那么通信前就要建立连接。当然，也可用于DGRAM，虽然没连接，但是这样不用每次都指定一个服务端地址。 connect会为sockfd指定的socket自动绑定一个端口。 connect遇到对方服务器忙时，会立即返回-1。如果此时socket是非阻塞模式，会把errno设为EINPROGRESS。 如果connect失败，该socket可能变成未定义的。所以每次失败都必须关闭socket。 addrlen是前面地址的长度。比如普通的IPv4地址可能是一个sockaddr_in的大小。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e int main(int argc , char *argv[]) { // socket int sockfd = 0; sockfd = socket(AF_INET , SOCK_STREAM , 0); if (sockfd == -1){ printf(\"Fail to create a socket.\"); } // 服务端的地址 struct sockaddr_in info; bzero(\u0026info,sizeof(info)); info.sin_family = PF_INET; info.sin_addr.s_addr = inet_addr(\"127.0.0.1\"); info.sin_port = htons(8700); // connect int err = connect(sockfd,(struct sockaddr *)\u0026info,sizeof(info)); if(err==-1){ printf(\"Connection error\"); } // 发送消息 char message[] = {\"Hi there\"}; char receiveMessage[100] = {}; send(sockfd,message,sizeof(message),0); recv(sockfd,receiveMessage,sizeof(receiveMessage),0); printf(\"%s\",receiveMessage); printf(\"close Socket\\n\"); close(sockfd); return 0; } ","date":"2019-10-21","objectID":"/socket/:4:1","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"服务端（socket-bind-listen-accept-read-write-close） 服务端的accept-read-write这三步都是默认阻塞的。socket-bind-listen-close会立即返回。 int listen(int sockfd, int backlog) 使得socket处于可以接收连接的状态。 sockfd 指明谁在listen。 backlog提示系统本线程还有多少连接需要建立。系统指定了等待连接的最大数量。如果队列满了，其他连接都会被丢弃。系统默认的net.core.somaxconn为128。 int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen) 接受一个连接。 sockfd 指明谁在accept。 sockaddr和addrlen会填充为接受到的连接地址和长度。（对端的） 如果没有请求过来，会一直阻塞到有请求为止。如果此时socket是非阻塞模式，会立即返回-1，并把errno设为EWOULDBLOCK。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e int main(int argc , char *argv[]) { //socket char inputBuffer[256] = {}; char message[] = {\"Hi,this is server.\\n\"}; int sockfd = 0,forClientSockfd = 0; sockfd = socket(AF_INET , SOCK_STREAM , 0); if (sockfd == -1){ printf(\"Fail to create a socket.\"); } // bind \u0026 listen struct sockaddr_in serverInfo,clientInfo; int addrlen = sizeof(clientInfo); bzero(\u0026serverInfo,sizeof(serverInfo)); serverInfo.sin_family = PF_INET; serverInfo.sin_addr.s_addr = INADDR_ANY; serverInfo.sin_port = htons(8700); bind(sockfd,(struct sockaddr *)\u0026serverInfo,sizeof(serverInfo)); listen(sockfd,5); // 收发消息 while(1){ forClientSockfd = accept(sockfd,(struct sockaddr*) \u0026clientInfo, \u0026addrlen); recv(forClientSockfd,inputBuffer,sizeof(inputBuffer),0); send(forClientSockfd,message,sizeof(message),0); printf(\"sended: %s\\n\", message); } return 0; } ","date":"2019-10-21","objectID":"/socket/:4:2","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["Linux"],"content":"收发数据 ssize_t send(int sockfd, const void *buf, size_t len, int flags) 发送数据 尽管可以使用write和read操作socket，但是send提供了更多的选项。 buf和len提供了发送的数据包。 flags提供了发送的选项。比如MSG_DONTROUTE不路由出本地，MSG_DONTWAIT允许非阻塞操作, MSG_EOF 写完后关闭服务端。 send会返回发送成功的字节数。如果send成功返回，则表示已经成功发送到了网络驱动程序上。如果失败，返回-1。 对于字节流（TCP）协议，send会阻塞到报文传输完成。对于有报文最大长度限制的协议，send到达限制后会返回-1，设置错误码为EMSGSIZE。 ssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen) 和send功能一样，但是可以指定地址。 ssize_t recv(int sockfd, void *buf, size_t len, int flags) 接受数据 buf和len提供了发送的数据包。 flags提供了发送的选项。比如MSG_PEEK只会读取数据，但是不会改动，MSG_DONTWAIT允许非阻塞操作, MSG_EOF 写完后关闭服务端。 recv会返回接受到的字节数。如果对端已经调用shutdown或者协议已经自动关闭，recv会返回0。 ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen) 可以额外获取发送者的地址。地址会被写入src_addr对应的内存中。 ","date":"2019-10-21","objectID":"/socket/:5:0","tags":["Linux","socket","AUPE"],"title":"[Linux]Linux socket API","uri":"/socket/"},{"categories":["后台"],"content":"描述RocketMQ的多个关键特性的实现原理，并对消息中间件实现遇到的各种问题进行总结，阐述RocketMQ 如何解决这些问题。","date":"2019-09-04","objectID":"/rocketmq/","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"主要整理文献： RocketMQ部署架构和技术架构 - Github RocketMQ关键机制的设计原理 - Github RocketMQ 原理简介 - 淘宝消息中间件项目组 设计理念和部署 ","date":"2019-09-04","objectID":"/rocketmq/:0:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"消息队列需要解决的问题 发布/订阅 最基础的需求，可以做解耦\u0026聚合，如果用Redis做，不够可靠 支持优先级队列、延时队列 顺序消费，rockmq严格有序 支持消息过滤，Producer和consumer共同过滤 持久化 内存缓存+文件 异常恢复 broker crash，os crash，掉电 —保证消息不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步） 磁盘损坏，机器永久损坏 —通过异步复制，可保证99%的消息不丢 实时性 RocketMQ使用长轮询Pull方式，可保证消息非常实时，消息实时性不低于Push。 At least Once 和 Exactly Only Once， 至少消费一次且只消费一次 broker的buffer容量问题。RocketMQ 的内存Buffer持久化在硬盘，抽象成一个无限长度的队列，不管有多少数据进来都能装得下，当然也会定时清理。 回溯消费 一般是按照时间维度，例如由于 Consumer 系统故障，恢复后需要重新消费 1 小时前的数据，那么 Broker 要提供一种机制，可以按照时间维度来回退消费进度。 RocketMQ 支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。 消息堆积 消息堆积在内存Buffer，一旦超过内存Buffer，可以根据一定的丢弃策略来丢弃消息，对性能影响不大，但是不能堆积太多 消息堆积到持久化存储系统中，例如DB，KV存储，文件记录形式。 当消息不能在内存Cache命中时，要不可避免的访问磁盘，会产生大量读IO，读IO的吞吐量直接决定了消息堆积后的访问能力。 消息重试 消息重试有两种原因，一种是消息本身处理失败，如编码有问题等，重试永远不会成功。另一部分是处理消息依赖的下游服务暂时不可用，一段时间重试后可以成功。所以可以消极重试，逐步重试增大等待重试间隔。 ","date":"2019-09-04","objectID":"/rocketmq/:1:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"RockMQ 模块 Name Server ：NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。 (1) 路由管理 Broker管理：NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活； 路由信息管理：每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，找到对应topic的路由信息，从而进行消息的投递和消费。 (2) 无状态：NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。它是一个几乎无状态的结点，他们之间互不通信。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer,Consumer仍然可以动态感知Broker的路由的信息。 (3) 随机选择：客户端连接时，会随机选择。 (4) 长连接：Broker向所有的NameServer结点建立长连接，注册Topic信息。Producer和Consumer也是长连接。 Broker：处理消息存储，转发等处理的服务器。 (0) 分Group：Broker以group分开，每个group只允许一个master，若干个slave。 (1) 读写分离：只有master才能进行写入操作，slave不允许。 (2) 主从同步：slave从master中同步数据。同步策略取决于master的配置，可以采用同步双写，异步复制两种。 (3) 默认消费：在默认情况下，消费者都从master消费，只有master挂掉或者产生消息堆积了才从slave消费。 Broker有下面几个重要的子模块： (1) Remoting Module：整个Broker的实体，负责处理来自clients端的请求。 (2) Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息 (3) Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。 (4) HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。 (5) Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。 Producer：消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。和NameServer、master都建立长连接，从NameServer拉取topic信息，给master发送心跳。完全无状态 Consumer：消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。和NameServer、master、slave都建立长连接，从NameServer拉取topic信息，给master、slave发送心跳。主备都可以订阅消息，订阅的对象由broker决定。 ","date":"2019-09-04","objectID":"/rocketmq/:2:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"网络部署特点 NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 注意：当前RocketMQ版本在部署架构上支持一Master多Slave，但只有BrokerId=1的从服务器才会参与消息的读负载。 Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。 ","date":"2019-09-04","objectID":"/rocketmq/:3:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"网络模块的工作流程 启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。 Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。 Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。 Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。 ","date":"2019-09-04","objectID":"/rocketmq/:4:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"模块的通信机制 RocketMQ消息队列集群主要包括NameServe、Broker(Master/Slave)、Producer、Consumer4个角色，基本通讯流程如下： (1) Broker启动后需要完成一次将自己注册至NameServer的操作；随后每隔30s时间定时向NameServer上报Topic路由信息。 (2) 消息生产者Producer作为客户端发送消息时候，需要根据消息的Topic从本地缓存的TopicPublishInfoTable获取路由信息。如果没有则更新路由信息会从NameServer上重新拉取，同时Producer会默认每隔30s向NameServer拉取一次路由信息。 (3) 消息生产者Producer根据2）中获取的路由信息选择一个队列（MessageQueue）进行消息发送；Broker作为消息的接收者接收消息并落盘存储。 (4) 消息消费者Consumer根据2）中获取的路由信息，并再完成客户端的负载均衡后，选择其中的某一个或者某几个消息队列来拉取消息并进行消费。 从上面1）~3）中可以看出在消息生产者, Broker和NameServer之间都会发生通信（这里只说了MQ的部分通信），因此如何设计一个良好的网络通信模块在MQ中至关重要，它将决定RocketMQ集群整体的消息传输能力与最终的性能。 消息存储 ","date":"2019-09-04","objectID":"/rocketmq/:5:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"消息存储结构(磁盘) (1) CommitLog：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件； (2) ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件，故consumequeue文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：`$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M； (3) IndexFile：索引文件提供了一种可以通过key或时间区间来查询消息的方法。Index文件的存储位置是：$HOME/store/index/{fileName}，文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。（具体的文件设计见下面的消息查询） 在上面的RocketMQ的消息存储整体架构图中可以看出，RocketMQ采用的是混合型的存储结构，即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。RocketMQ的混合型存储结构(多个Topic的消息实体内容都存储于一个CommitLog中)针对Producer和Consumer分别采用了数据和索引部分相分离的存储结构，Producer发送消息至Broker端，然后Broker端使用同步或者异步的方式对消息刷盘持久化，保存至CommitLog中。只要消息被刷盘持久化至磁盘文件CommitLog中，那么Producer发送的消息就不会丢失。正因为如此，Consumer也就肯定有机会去消费这条消息。当无法拉取到消息后，可以等下一次消息拉取，同时服务端也支持长轮询模式，如果一个消息拉取请求未拉取到消息，Broker允许等待30s的时间，只要这段时间内有新消息到达，将直接返回给消费端。这里，RocketMQ的具体做法是，使用Broker端的后台服务线程—ReputMessageService不停地分发请求并异步构建ConsumeQueue（逻辑消费队列）和IndexFile（索引文件）数据。 ","date":"2019-09-04","objectID":"/rocketmq/:6:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"内存缓存 PageCache 页缓存（PageCache)是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度，主要原因就是由于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。对于数据的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于数据的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取。 在RocketMQ中，ConsumeQueue逻辑消费队列存储的数据较少，并且是顺序读取，在page cache机制的预读取作用下，Consume Queue文件的读性能几乎接近读内存，即使在有消息堆积情况下也不会影响性能。而对于CommitLog消息存储的日志数据文件来说，读取消息内容时候会产生较多的随机访问读取，严重影响性能。如果选择合适的系统IO调度算法，比如设置调度算法为“Deadline”（此时块存储采用SSD的话），随机读的性能也会有所提升。 另外，RocketMQ主要通过MappedByteBuffer对文件进行读写操作。其中，利用了NIO中的FileChannel模型将磁盘上的物理文件直接映射到用户态的内存地址中（这种Mmap的方式减少了传统IO将磁盘文件数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销），将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率（正因为需要使用内存映射机制，故RocketMQ的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存）。 ","date":"2019-09-04","objectID":"/rocketmq/:7:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"刷盘策略 异步刷盘：能够充分利用OS的PageCache的优势，只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了MQ的性能和吞吐量。 同步刷盘：与异步刷盘的唯一区别是异步刷盘写完 PAGECACHE 直接返回，而同步刷盘需要等待刷盘完成才返回，同步刷盘流程如下： (1) 写入PAGECACHE后，线程等待，通知刷盘线程刷盘。 (2) 刷盘线程刷盘后，唤醒前端等待线程，可能是一批线程。 (3) 前端等待线程向用户返回成功。 同步刷盘对MQ消息可靠性来说是一种不错的保障，但是性能上会有较大影响，一般适用于金融业务应用该模式较多。 异步刷盘的思考： 在有 RAID 卡，SAS 15000 转磁盘测试顺序写文件，速度可以达到 300M 每秒左右，而线上的网卡一般都为千兆网卡，写磁盘速度明显快于数据网络入口速度，那么是否可以做到写完内存就向用户返回，由后台线程刷盘呢？ (1) 由于磁盘速度大于网卡速度，那么刷盘的进度肯定可以跟上消息的写入速度。 (2) 万一由于此时系统压力过大，可能堆积消息，除了写入 IO，还有读取 IO，万一出现磁盘读取落后情况，会不会导致系统内存溢出，答案是否定的，原因如下： a) 写入消息到 PAGECACHE 时，如果内存不足，则尝试丢弃干净的 PAGE，腾出内存供新消息使用，策略是 LRU 方式。 b) 如果干净页不足，此时写入 PAGECACHE 会被阻塞，系统尝试刷盘部分数据，大约每次尝试 32 个 PAGE。 ","date":"2019-09-04","objectID":"/rocketmq/:8:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"高并发的队列 基本的刷盘流程： (1) 所有数据单独存储到一个 Commit Log，完全顺序写，随机读。 (2) 对最终用户展现的队列实际只存储消息在 Commit Log 的位置信息，并且串行方式刷盘。 这样做的好处如下： (1) 队列轻量化，单个队列数据量非常少。 (2) 对磁盘的访问串行化，避免磁盘竟争，不会因为队列增加导致 IOWAIT 增高。 每个方案都有缺点，它的缺点如下： (1) 乱序。写虽然完全是顺序写，但是读却变成了完全的随机读。 (2) 增大开销。读一条消息，会先读 Consume Queue，再读 Commit Log，增加了开销。 (3) 编码复杂。要保证Commit Log 与 Consume Queue 完全的一致，增加了编程的复杂度。 以上缺点如何克服： (1) 随机读，尽可能让读命中 PAGECACHE，减少 IO 读操作，所以内存越大越好。如果系统中堆积的消息过多， 读数据要访问磁盘会不会由于随机读导致系统性能急剧下降，答案是否定的。 a) 访问 PAGECACHE 时，即使只访问 1k 的消息，系统也会提前预读出更多数据，在下次读时，就可能命中内存。 b) 随机访问 Commit Log 磁盘数据，系统 IO 调度算法设置为 NOOP 方式，会在一定程度上将完全的随机读变成顺序跳跃方式，而顺序跳跃方式读较完全的随机读性能会高 5 倍以上。（Noop调度算法也叫作电梯调度算法，它将IO请求放入到一个FIFO队列中，然后逐个执行这些IO请求，当然对于一些在磁盘上连续的IO请求，Noop算法会适当做一些合并。这个调度算法特别适合那些不希望调度器重新组织IO请求顺序的应用。） 另外 4k 的消息在完全随机访问情况下，仍然可以达到 8K 次每秒以上的读性能。 (2) 由于 Consume Queue 存储数据量极少，而且是顺序读，在 PAGECACHE 预读作用下，Consume Queue 的读性能几乎与内存一致，即使堆积情况下。所以可认为 Consume Queue 完全不会阻碍读性能。 (3) Commit Log 中存储了所有的元信息，包含消息体，类似于 Mysql、Oracle 的 redolog，所以只要有 Commit Log 在，Consume Queue 即使数据丢失，仍然可以恢复出来。 ","date":"2019-09-04","objectID":"/rocketmq/:9:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"关于随机读写 全随机写无疑是最慢的写入方式，在logic dump测试中很惊讶的发现，将200M的内存数据随机的写入到100G的磁盘数据里面，竟然要2个小时之多。原因就是虽然只有200M的数据，但实际上却是200万次随机写，根据测试，在2850机器上，这样完全的随机写，r/s 大约在150～350之间，在180机器上，r/s难以达到250，这样计算，难怪需要2～3个小时之久。 如何改进这种单线程随机写慢的问题呢？ 一种方法就是尽量将完全随机写变成有序的跳跃随机写。实现方式，可以是简单的在内存中缓存一段时间，然后排序，使得在写盘的时候，不是完全随机的，而是使得磁盘磁头的移动只向一个方向。根据测试，简单的先在内存中排序，竟然直接使得写盘时间缩短到1645秒，磁盘的r/s也因此提升到1000以上。写盘的速度，一下子提高了5倍 ","date":"2019-09-04","objectID":"/rocketmq/:10:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"消息周转的过程 (1)Producer 发送消息，消息从 socket 进入 java 堆。 (2)Producer 发送消息，消息从 java 堆转入 PAGACACHE，物理内存。 (3)Producer 发送消息，由异步线程刷盘，消息从 PAGECACHE 刷入磁盘。 (4)Consumer 拉消息（多数情况），消息直接从 PAGECACHE（数据在物理内存）转入 socket，到达 consumer，不经过 java 堆。这种消费场景最多，线上 96G 物理内存，按照 1K 消息算，可以在物理内存缓存 1 亿条消息。 (5)Consumer 拉消息（少数情况），消息直接从 PAGECACHE（数据在虚拟内存）转入 socket。 (6)Consumer 拉消息（少数情况），由于 Socket 访问了虚拟内存，产生缺页中断，此时会产生磁盘 IO，从磁盘 Load 消息到 PAGECACHE，然后直接从 socket 发出去。 RockMQ高级特性 ","date":"2019-09-04","objectID":"/rocketmq/:11:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"At least Once 和 Exactly Only Once At least Once 是指每个消息必须投递一次 RocketMQ Consumer 先 pull 消息到本地，消费完成后，才向服务器返回 ack，如果没有消费一定不会 ack 消息，所以 RocketMQ 可以很好的支持此特性。 Exactly Only Once 是指只消费一次，即生产和消费都只能进行一次 在分布式系统环境下，不可避免要产生巨大的开销。所以 RocketMQ 为了追求高性能，并不保证此特性，要求在业务上进行去重，也就是说消费消息要做到幂等性。RocketMQ 虽然不能严格保证不重复，但是正常情况下很少会出现重复发送、消费情况，只有网络异常，Consumer 启停等异常情况下会出现消息重复。 ","date":"2019-09-04","objectID":"/rocketmq/:12:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"顺序消息 一个订单产生了 3 条消息，分别是订单创建，订单付款，订单完成。消费时，要按照这个顺序消费才能有意义。但是同时订单之间是可以并行消费的。所以我们只要保证同一个订单的消息在同一个队列里处理，就可以保证顺序性。 顺序消息 消费消息的顺序要同发送消息的顺序一致，在 RocketMQ 中，主要指的是局部顺序，即一类消息为满足顺序性，必须 Producer 单线程顺序发送，且发送到同一个队列，这样 Consumer 就可以按照 Producer 发送的顺序去消费消息。 普通顺序消息 顺序消息的一种，正常情况下可以保证完全的顺序消息。这种消息需要保证三点： 消息被发送时保持顺序 消息被存储时保持和发送的顺序一致 消息被消费时保持和存储的顺序一致 第一，发送的时候要保持有序，这里rockmq把需要保持顺序的消息哈希到同一个队列（不一定同分区，如图） 第二，落盘的时候有序，msg queue本来就是顺序写 第三，消费的时候有序，如果queue被多个consumer协程消费就会乱序。这里有两种消费模式，一种是consumer msg orderly，在消费队列时会加锁，确保一对一消费。还有一种是consumer msg concurrently，多协程广播消费，就会有问题，所以只能指定单协程。 但是一旦发生通信异常，Broker 重启，由于队列总数发生变化，哈希取模后定位的队列会变化，产生短暂的消息顺序不一致。如果业务能容忍在集群异常情况（如某个 Broker 宕机或者重启）下，消息短暂的乱序，使用普通顺序方式比较合适。 严格顺序消息 顺序消息的一种，无论正常异常情况都能保证顺序，但是牺牲了分布式 Failover 特性，即 Broker 集群中只要有一台机器不可用，则整个集群都不可用，服务可用性大大降低。如果服务器部署为同步双写模式，此缺陷可通过备机自动切换为主避免，不过仍然会存在几分钟的服务不可用。（依赖同步双写，主备自动切换，自动切换功能目前还未实现） 目前已知的应用只有数据库 binlog 同步强依赖严格顺序消息，其他应用绝大部分都可以容忍短暂乱序，推荐使用普通的顺序消息。 ","date":"2019-09-04","objectID":"/rocketmq/:13:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"优先级消息 优先级是指在一个消息队列中，每条消息都有不同的优先级，一般用整数来描述，优先级高的消息先投递。如果要用严格的优先级，则需要按照优先级排序确认消费次序，代价很大。 rocketmq实现的不是严格意义上的优先级，通常将优先级划分为高、中、低，或者再多几个级别。每个优先级可以用不同的 topic 表示，发消息时，指定不同的 topic 来表示优先级，随后优先消费某些topic。这种方式可以解决绝大部分的优先级问题，但是对业务的优先级精确性做了妥协。 ","date":"2019-09-04","objectID":"/rocketmq/:14:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"延迟消息 RocketMQ源码-RocketMQ延时消息 因为按照时间排序的复杂度太高，所以采用了折中的办法，降低延迟消息准确性，分为18个延迟队列（1s, 2s, …, 30min, 1h, 2h）写入 延迟消息正常提交给CommitLog保存 因为是延迟消息，单独写到延时队列专用的topic，这样就不会被马上消费 每一个延时等级对应一个queue，queueId = delayLevel - 1 延时队列调度器轮询查看相应的队列中消息，是否到了要执行的时间 到了执行时间的消息，恢复原来消息的topic和queueId，发给写入普通的消费broker。这样就能正常消费了 ","date":"2019-09-04","objectID":"/rocketmq/:15:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"负载均衡 ","date":"2019-09-04","objectID":"/rocketmq/:16:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"发送消息负载均衡 发送策略：采取轮询的方式，给每个队列依次发送消息。比如有5个队列，可以部署在一台机器或者分别部署在5台机器上，发送消息通过轮询队列的方式发送，每个队列接收平均的消息量。通过增加机器，可以水平扩展队列容量。 退避策略（latencyFaultTolerance）：是指对之前失败的，按一定的时间做退避。例如，如果上次请求的latency超过550Lms，就退避3000Lms；超过1000L，就退避60000L； ","date":"2019-09-04","objectID":"/rocketmq/:16:1","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"订阅消息负载均衡 如果有 5 个队列，2 个 consumer，那么第一个 Consumer 消费 3 个队列，第二 consumer 消费 2 个队列。 这样即可达到平均消费的目的，可以水平扩展 Consumer 来提高消费能力。但是 Consumer 数量要小于等于队列数 量，如果 Consumer 超过队列数量，那么多余的 Consumer 将不能消费消息。 如果有 10 个队列，20 个 consumer, 11-20号消费者则不能订阅到消息。 核心设计理念是在一个消息消费队列在同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。一个负载均衡的流程如下： 上报自己：在Consumer启动后，它就会通过定时任务不断地向RocketMQ集群中的所有Broker实例发送心跳包（其中包含了消息消费分组名称、订阅关系集合等信息）。Broker端在收到Consumer的心跳消息后，会将它们都维护在本地缓存变量consumerTable备用。 定时均衡：Consumer中有一个RebalanceService线程，每隔20s执行一次策略。 (A) 拉取所有queue：获取这个topic的consumer queue集合mqset (B) 拉取所有消费者：Consumer使用topic和consumerGroup为参数对broker发起RPC请求，获取broker的consumerTable (C) 平均分配：拿到Topic下所有的consumer queue、Consumer Id排序，把queue平均分配给所有的Consumer 。几乎每个consumer都会分到相同数量的queue。 (D) 改变消费连接：根据新建立的映射关系调整消费者和queue的连接。把分配到的consumer queue集合和正在处理的consumer queue做比对。对于正在处理的但是没有分配到的，移除这些连接；对于分配到没有处理的，连接到这些queue开始消费。其余的不处理。 ","date":"2019-09-04","objectID":"/rocketmq/:16:2","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"并行消费 单队列并行消费： 单队列并行消费采用滑动窗口方式并行消费，如图所示，3~7 的消息在一个滑动窗口区间，可以有多个线程并行消 费，但是每次提交的 Offset 都是最小 Offset，例如 3 。 ","date":"2019-09-04","objectID":"/rocketmq/:17:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"消息过滤 在 Broker 端进行 Message Tag 比对，先遍历 Consume Queue，如果存储的 Message Tag 与订阅的 Message Tag 不符合，则跳过，继续比对下一个，符合则传输给 Consumer。注意：Message Tag 是字符串形式，Consume Queue 中存储的是其对应的 hashcode，比对时也是比对 hashcode。 Consumer 收到过滤后的消息后，同样也要执行在 Broker 端的操作，但是比对的是真实的 Message Tag 字 符串，而不是 Hashcode。 为什么过滤要这样做？ Hashcode更短。Message Tag 存储 Hashcode，是为了在 Consume Queue 定长方式存储，节约空间。 和Commit Log解耦。过滤过程中不会访问Commit Log数据，可以保证堆积情况下也能高效过滤。 双重保证。即使存在 Hash 冲突，也可以在 Consumer 端进行修正，保证万无一失。 ","date":"2019-09-04","objectID":"/rocketmq/:18:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"消息查询 ","date":"2019-09-04","objectID":"/rocketmq/:19:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"A. 按照MessageId查询消息 MessageId的长度总共有16字节，其中包含了消息存储主机地址（IP地址和端口），消息Commit Log offset。 Client端从MessageId中解析出Broker的地址（IP地址和端口）和Commit Log的偏移地址后封装成一个RPC请求后通过Remoting通信层发送（业务请求码：VIEW_MESSAGE_BY_ID）。Broker端走的是QueryMessageProcessor，读取消息的过程用其中的 commitLog offset 和 size 去 commitLog 中找到真正的记录并解析成一个完整的消息返回。 ","date":"2019-09-04","objectID":"/rocketmq/:19:1","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"B. 按照Message Key查询消息 Index File由下面几个部分组成： 索引文件头 存了已用slot个数、已用索引个数、第一个和最后一个消息的落盘时间和在CommitLog的offset Slot Table 一个存放指针的哈希表，里面存着指向indexs的地址 Indexs 索引主体，存放着下面的内容： key hash value: message key的hash值 phyOffset: message在CommitLog的物理文件地址, 可以直接查询到该消息(索引的核心机制) timeDiff: message的落盘时间与header里的beginTimestamp的差值(为了节省存储空间，如果直接存message的落盘时间就得8bytes) prevIndex: hash冲突处理的关键之处, 相同hash值上一个消息索引的index Note: 这个prevIndex是用来解决hash冲突的。如果没有冲突，prevIndex就是0。如果有冲突，slot table的指针会指向比较新的那个indexs的地址，然后把新的indexs的prevIndex写上旧的indexs地址。这样，在遍历的时候，从slot table开始查找，经过一个key hash slot -\u003e slot value -\u003e curIndex -\u003e prevIndex -\u003e ... -\u003e prevIndex -\u003e 相同的hash value的链路，最后总会找到相同hash值的key。 Note: 如果在插入Indexs的时候采用append的形式，插入的偏移量： 文件偏移量=索引文件头长度+Slot Table长度+Indexs个数*单个Indexs大小 我们看一个通常的插入key的流程： 根据查询的 key 的 hashcode % slotNum 得到具体的槽的位置（slotNum 索引文件slots上限的数目，一般像图中 slotNum=5000000）。 根据 slotValue（slot 位置对应的值）查找到索引项列表的最后一项（slotValue总是指向最新的一个）。 顺着prevIndex遍历所有索引项列表，匹配key hash value相同的索引项，返回查询时间范围内的结果集（默认一次最大返回的 32 条记录）。 Note: 如果值的key hash value值相等但 key 不等，其实这里是检查不出来的。出于性能的考虑冲突的检测放到客户端处理（key 的原始值是存储在消息文件中的，避免对数据文件的解析），客户端比较一次消息体的 key 是否相同。 5. 存储：为了节省空间索引项中存储的时间是时间差值（存储时间-开始时间，开始时间存储在索引文件头中），整个索引文件是定长的，结构也是固定的。索引文件存储结构如上图。 ","date":"2019-09-04","objectID":"/rocketmq/:19:2","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"Pull 和 Push RocketMQ消息订阅有两种模式，一种是Push模式（MQPushConsumer），即MQServer主动向消费端推送；另外一种是Pull模式（MQPullConsumer），即消费端在需要时，主动到MQServer拉取。但在具体实现时，Push和Pull模式都是采用消费端主动拉取的方式，即consumer轮询从broker拉取消息。区别是： Push方式里，consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送过来的。 Pull方式里，取消息的过程需要用户自己写，首先通过打算消费的Topic拿到MessageQueue的集合，遍历MessageQueue集合，然后针对每个MessageQueue批量取消息，一次取完后，记录该队列下一次要取的开始offset，直到取完了，再换另一个MessageQueue。 Push的问题：慢消费。如果消费者的速度比发送者的速度慢很多，势必造成消息在broker的堆积。对于消息量有限且到来的速度不均匀的情况，pull模式比较合适。 Pull的问题：消息延迟和忙等。pull需要轮询，就需要设置一个间隔时间，这个间隔太短就会引起无效的忙等，间隔太长会导致消息延迟。 在RocketMQ里，有一种优化的做法——长轮询 Pull ，来平衡推拉模型各自的缺点。基本思路是： consumer尝试拉取，发现broker上没有消息（有消息就直接返回了） broker不直接返回, 而是把连接挂在那里wait producer如果有新的消息到来，把连接notify起来，返回给consumer 如果没有消息到来，超时后释放链接（比如30s） 缺点：但海量的长连接block对系统的开销还是不容小觑 ","date":"2019-09-04","objectID":"/rocketmq/:20:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"事务消息 ","date":"2019-09-04","objectID":"/rocketmq/:21:0","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"事务的流程 MQ也提供了对事务的支持，比如操作A可以放在生产者的本地事务里，操作B可以放在消费者里 发送方向 MQ 服务端发送消息 broker将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功，此时消息为prepared状态。 发送方开始执行本地事务逻辑。 发送方根据本地事务执行结果向 broker 提交二次确认（Commit 或是 Rollback） broker 收到 Commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；broker 收到 Rollback 状态则删除prepared的消息，订阅方将不会接受该消息。 补充逻辑 5. 在断网或者是应用重启的特殊情况下，上述步骤4提交的二次确认最终未到达 broker，经过固定时间后 broker 将对该消息发起消息回查。 6. 发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。 发送方根据检查得到的本地事务的最终状态再次提交二次确认，broker 仍按照步骤4对prepare的消息进行操作。 ","date":"2019-09-04","objectID":"/rocketmq/:21:1","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["后台"],"content":"事务的实现 看一下mq具体处理事务消息的办法，如果一个事务消息被写入： 写入的如果是事务消息，对消息的Topic和Queue等属性进行替换写入half topic，同时将原来的Topic和Queue信息存储到消息的属性中 （正因为消息主题被替换，故消息并不会转发到该原主题的消息消费队列，消费者无法感知消息的存在，不会消费，和延时消息一样的套路） 消息commit或者rollback时，会在op topic中存储一份，表示消息的状态，op topic的消息体是到half topic的索引，便于后面回查 如果是rollback，消息直接设置为回滚，就不会再处理了 Commit之后，读取出Half消息，并将Topic和Queue替换成真正的目标的Topic和Queue，然后走普通消息的写入流程 Note：如果commit因为网络等原因失败，Broker端对未确定状态的消息（在half topic不在op topic里的） 发起定时回查，将消息发送到对应的Producer，由Producer根据消息来检查本地事务的状态，进而执行Commit或者Rollback。 ","date":"2019-09-04","objectID":"/rocketmq/:21:2","tags":["后台","消息队列"],"title":"[后台]RocketMQ的架构和设计","uri":"/rocketmq/"},{"categories":["Linux"],"content":"使用进程间通信来完成信息互换是很常见的场景。本文介绍了指令形式的通信（信号、信号量），文本形式的通信（共享内存，管道，FIFO，Unix域套接字）来完成这一基本的任务。","date":"2019-08-01","objectID":"/ipc/","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"管道 管道是进程间通信的最古老方式。它通过共享文件来完成进程间的通信。它有两个局限性： 它是半双工的。数据只能从一个进程流向另一个进程。 通信的进程之间必须另一个进程是fork出来的。通常，一个进程会创建一个管道，然后执行fork，这样管道就会在两个进程之间共享。 FIFO解决了第一种局限性，Unix域套接字解决了第二种。我们先来看管道。 int pipe(int pipefd[2]);管道由pipe函数创建。 参数pipefd是一个两个元素的数组。pipefd[0]用来读，pipefd[1]用来写。 成功返回0 。失败返回-1并设置errno。 单进程的管道没有任何用处。在这个函数之后一般会fork，然后一个进程来写pipefd[1]，一个进程来读pipefd[0]。他们的另一个fd元素将会被关闭。 下面是一段实例, 父进程通过管道向子进程传递了信息，子进程接收并把他们输出： #include \"apue.h\" int main(void) { int n; int fd[2]; pid_t pid; char line[MAXLINE]; if (pipe(fd) \u003c 0) err_sys(\"pipe error\"); if ((pid = fork()) \u003c 0) { err_sys(\"fork error\"); } else if (pid \u003e 0) { /* parent */ close(fd[0]); write(fd[1], \"hello world\\n\", 12); } else { /* child */ close(fd[1]); n = read(fd[0], line, MAXLINE); write(STDOUT_FILENO, line, n); } exit(0); } FILE *popen(const char *command, const char *type) 函数popen执行一个命令，然后返回这个命令的文件指针。 type参数为’r’，表示这个文件可读，如果是’w’，表示可写。 command参数是要执行的命令 使用完用int pclose(FILE *stream)关闭管道。 这个函数是管道实现的一个例子。它先创建一个管道，然后fork一个子进程，关闭未使用的管道端（读或写），然后在子进程执行命令，最后等待执行完毕。 FIFO int mkfifo(const char *pathname, mode_t mode)提供了任意进程间通过文件通信的方式。 参数path表示管道的路径。 参数mode和open函数的模式一样。 int mkfifoat(int dirfd, const char *pathname, mode_t mode)提供了更多选择的路径控制。 ","date":"2019-08-01","objectID":"/ipc/:0:0","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"FIFO用于复制输出流 下面的命令展示了复制输出流的方法。输入文件先到达prog1，然后通过tee命令复制给fifo和prog2。fifo中的数据会流到prog3。 mkfifo fifo1 prog3 \u003c fifo1 \u0026 prog1 \u003c infile | tee fifo1 |prog2 ","date":"2019-08-01","objectID":"/ipc/:1:0","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"FIFO用于服务端和客户端通信 使用FIFO可以用来做服务端-客户端通信。服务端提供一个FIFO让客户端写入，这样就可以接收到客户端的请求。那么如何响应客户端？可以让客户端在请求中携带进程ID，然后服务端为每个客户端都创建一个FIFO（和客户端约定好路径），然后让客户端从中读取。 这种方法有些问题： 客户端可能随时进程消失，FIFO没有被回收 客户端发起单向调用就终止时，FIFO没有被回收（监听SIGPIPE可以解决） 客户进程从1变成0时，服务端需要处理EOF（请求FIFO可以设为读-写模式解决） XSI IPC ","date":"2019-08-01","objectID":"/ipc/:2:0","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"IPC标识符 进行进程间通信，必须要有一个编号来表明所用的资源（IPC对象）是哪个。在Linux中，IPC标识符是一个key_t类型（一般实现为长整型，从0开始分配，每有一个IPC对象就加一，直到最大值后又从0开始）。使用IPC操作必须提供这个IPC标识符，那么不同进程如何共享这个标识符呢？ ","date":"2019-08-01","objectID":"/ipc/:3:0","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"ftok key_t ftok(const char *pathname, int proj_id) 通过ftok函数，不同进程可以产生相同的key。 参数 pathname 是进程间约定的已经存在的文件路径。 参数 proj_id 是约定的0-255的值，也是一个约定的项目id。 事实上，ftok取了pathname中文件的设备编号st_dev的低8bit、文件iNodest_ino的低16bit，和proj_id的低8bit合并成了返回的key_t值。 这意味着如果文件在使用中被删除并重建，key会发生变化。如果proj_id一致，也有可能造成冲突。 ","date":"2019-08-01","objectID":"/ipc/:3:1","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"IPC_PRIVATE IPC_PRIVATE 实际上是定义的值是0 。用这个做key时，系统将会产生一个新的IPC对象。一般用于不同进程间不需要约定key的时候，比如父进程在获得对象后传承给子进程。 ","date":"2019-08-01","objectID":"/ipc/:3:2","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"IPC 权限 所有的IPC对象都有一个权限字段来标识所属的线程。一般IPC对象只能由创建的进程或者超级权限进程来删除。这个权限信息里记录了一些创建者的信息。uid、gid、mode三个字段可以由用户通过msgctl、shmctl、semctl等函数来修改。修改者必须是创建进程或者超级权限进程。 mode 字段有一些特定的值表示权限，类似文件的chmod。下面给出了该字段每一位的含义。 struct ipc_perm { key_t __key; /* Key supplied to shmget(2) */ uid_t uid; /* Effective UID of owner */ gid_t gid; /* Effective GID of owner */ uid_t cuid; /* Effective UID of creator */ gid_t cgid; /* Effective GID of creator */ unsigned short mode; /* Permissions + SHM_DEST and SHM_LOCKED flags */ unsigned short __seq; /* Sequence number */ }; // mode字段 0400 用户读 0200 用户写 0040 组读 0020 组写 0004 其他读 0002 其他写 ","date":"2019-08-01","objectID":"/ipc/:3:3","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"IPC的缺点 IPC不会主动回收资源。IPC是系统来维护的，没有引用计数。如果一个进程在一个消息队列中添加了消息然后终止，系统不会删除这些消息，直到下个进程显示地使用或删除他们。 PIPE会在最后一个使用的进程终止后自动销毁。FIFO虽然在最后一个使用的进程结束后会保留名字，但是其中的数据会删除。 IPC在文件系统中没有名字。Linux是一切皆文件的，没有文件描述符有几个麻烦：a)无法ls，rm，chmod，无法像操作文件一样操作IPC对象，只能用其特定的函数。b)没办法使用select，poll这样的多路复用技术，这将导致进程无法同时监听两个消息队列。 ","date":"2019-08-01","objectID":"/ipc/:3:4","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"消息队列 int msgget(key_t key, int msgflg)创建一个msg对象。 key可以是IPC_PRIVATE或者一个存在的IPC的key。 msgflg提供了创建消息队列的选项。a)为0时返回key的消息队列的标识符，不存在会报错 b) PC_CREAT：当msgflg\u0026IPC_CREAT为真时，则新建一个消息队列；如果存在这样的消息队列，返回此消息队列的标识符 c) IPC_CREAT|IPC_EXCL 不存在则创建一个key的消息队列，存在则返回错误。 成功返回消息队列的标识符，失败返回-1，并写errno。 int msgctl(int msqid, int cmd, struct msqid_ds *buf) 读写msg对象的属性 msqid是一个消息队列的标识符。 cmd 提供了读写的选项。a) IPC_STAT 读取属性到buf中。 b) IPC_SET 写入属性到buf中 c) IPC_RMID 删除消息队列和队列中的所有消息。删除前会用msg_perm校验归属。 buf 是设置的详情，见下表。 struct msqid_ds { struct ipc_perm msg_perm; // Ownership and permissions 权限，初始化时填0 time_t msg_stime; // Time of last msgsnd(2) 初始化时填0 time_t msg_rtime; // Time of last msgrcv(2) 初始化时填0 time_t msg_ctime; // Time of last change 初始化时设置为当前时间 unsigned long __msg_cbytes; // Current number of bytes in queue (non-standard) msgqnum_t msg_qnum; // Current number of messages in queue 初始化时填0 msglen_t msg_qbytes; // Maximum number of bytes allowed in queue 初始化时填系统值MSGMNB pid_t msg_lspid; // PID of last msgsnd(2) 初始化时填0 pid_t msg_lrpid; // PID of last msgrcv(2) 初始化时填0 }; int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg) 发送消息。如果消息队列已满，会阻塞等待。 参数msqid 是发送消息的消息队列 参数msgp 发送给队列的消息。msgp可以是任何类型的结构体，但第一个字段必须为long类型，即表明此发送消息的类型。msgp定义的参照格式如下： struct s_msg{ /*msgp定义的参照格式*/ long type; /* 必须大于0,消息类型 */ char mtext[256]; /*消息正文，可以是其他任何类型*/ } msgp; 参数msgsz 要发送消息的大小, 其中不含消息类型的4个字节。 参数msgflg 设置发送的模式。IPC_NOWAIT类似一个非阻塞IO，写不进消息队列也会立即返回IPC_NOERROR 如果消息超过长度限制msgsz，会截断消息。 成功返回0，失败返回-1，设置errno。EAGAIN 消息队列已满，EIDRM 消息队列已删除，EACCESS 无权限写入， EINVAL 参数错误。 msgsnd会一直阻塞等待，直到 a) 消息队列有空余 b) 消息队列被删除 c) msgsnd函数被信号中断。 size_t msgrcv(int msqid, void *msgp, size_t msgsz, long msgtyp, int msgflg) 会读取消息存入msgp指针，然后把消息从队列中删除。在此之前，此函数会一直阻塞。 参数msqid 是接收消息的消息队列 参数msgp 存放读出来的消息。结构体必须和上面的发送结构体相同。 参数msgsz 读出来消息的大小, 其中不含消息类型的4个字节。 参数msgtyp a) 为0表示读第一个消息 b) 大于0表示读消息类型等于本参数的第一个消息 c) 小于0表示读消息类型小于等于本参数绝对值的第一个消息 参数msgflg 设置读的模式。IPC_NOWAIT类似一个非阻塞IO，没有消息可读也会立即返回，此时错误为 ENOMSG。IPC_NOERROR 如果消息超过长度限制msgsz，会截断消息。 成功返回消息长度，失败返回-1，设置errno。E2BIG 消息数据长度大于msgsz而msgflag没有设置IPC_NOERROR 。 下面给出了一个两个进程间通过消息队列通信的样例。由于消息队列创建后不会自动删除，需要运行ipcrm -q msqid来手动删除队列。 #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/msg.h\u003e #include \u003ctime.h\u003e #define TEXT_SIZE 512 struct msgbuf { long mtype; int status; char time[20]; char mtext[TEXT_SIZE]; } ; char *getxtsj() { time_t tv; struct tm *tmp; static char buf[20]; tv = time( 0 ); tmp = localtime( \u0026tv ); sprintf( buf, \"%02d:%02d:%02d\", tmp-\u003etm_hour, tmp-\u003etm_min, tmp-\u003etm_sec ); return buf; } int main( int argc, char **argv ) { int msqid; struct msqid_ds info; struct msgbuf buf; struct msgbuf buf1; int flag; int sendlength, recvlength; int key; key = ftok( \"msg.tmp\", 0x01 ); if ( key \u003c 0 ) { perror( \"ftok key error\" ); return(-1); } msqid = msgget( key, 0600 | IPC_CREAT ); if ( msqid \u003c 0 ) { perror( \"create message queue error\" ); return(-1); } buf.mtype = 1; buf.status = 9; strcpy( buf.time, getxtsj() ); strcpy( buf.mtext, \"happy new year!\" ); sendlength = sizeof(struct msgbuf) - sizeof(long); flag = msgsnd( msqid, \u0026buf, sendlength, 0 ); if ( flag \u003c 0 ) { perror( \"send message error\" ); return(-1); } buf.mtype = 3; buf.status = 9; strcpy( buf.time, getxtsj() ); strcpy( buf.mtext, \"good bye!\" ); sendlength = sizeof(struct msgbuf) - sizeof(long); flag = msgsnd( msqid, \u0026buf, sendlength, 0 ); if ( flag \u003c 0 ) { perror( \"send message error\" ); return - 1; } system( \"ipcs -q\" ); return(0); } 接受消息： #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/msg.h\u003e #define TEXT_SIZE 512 struct msgbuf { long mtype ; int status ; char time[20] ; char mtext[TEXT_SIZE] ; } ; int main(int argc, char **argv) { int msqid ; struct msqid_ds info ; struct msgbuf buf1 ; int flag ; int recvlength ; int key ; int mtype ; key = ftok(\"msg.tmp\", 0x01 ) ; if ( key \u003c 0 ) { perror(\"ftok key error\") ; return -1 ; } msqid = msgget( key, 0 ) ; if ( msqid \u003c 0 ) { perror(\"get ipc_id error\") ; return -1 ; } recvlength = sizeof(struct msgbuf) - sizeof(long) ; ","date":"2019-08-01","objectID":"/ipc/:4:0","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"信号量 信号量是一个计数器，用于控制多个进程对资源的访问。当一个进程访问信号量控制的资源时，以以下步骤执行： 取信号量的值。如果值是正，则进程可以继续执行。进程访问资源，并把信号量的值减一，表示他占用了一个资源。 如果值是0，进程会休眠，直到信号量的值大于0，进程被唤醒，再执行1。 当进程释放资源时，信号量值加一，并唤醒正在等待的进程。 实际上，XSI中的信号量要复杂一些，他有几个缺点： 信号量并非是一个数值，而是一个多个值的集合。创建时要指定值的数量。 信号量的创建和初始化是分开的，并非一个原子操作。这样就没法原子地创建一个信号量。 即使已经没有进程再使用信号量，他们依然不会销毁。 关于信号量不再展开描述，参见 Linux进程间通信——使用信号量 ","date":"2019-08-01","objectID":"/ipc/:5:0","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"共享内存 进程间通信最方便的方法，就是一起读写内存。由于进程不需要把这块内存复制到自己的进程空间内，所以共享内存的方法非常快。需要注意的是，在一个进程写内存的时候，其他进程不能操作这块内存。这里可以用记录锁、信号量或者互斥量来同步。 通过mmap把文件映射到内存中也是一种共享内存的实现。于这种方式不同的是，XSI中的共享内存没有文件映射，是一个内存的匿名段。 int shmget(key_t key, size_t size, int shmflg) 用于创建一个共享内存。 key可以是IPC_PRIVATE或者一个存在的共享内存的key（可能是ftok生成）。 size 表示要创建的共享内存的大小，必须为内存页大小的整数倍。如果是读取线程获取已经存在的共享内存，填0。 shmflg提供了创建消息队列的选项。a)为0时返回key的共享内存的标识符，不存在会报错 b) IPC_CREAT：当shmflg\u0026IPC_CREAT为真时，则新建一个共享内存；如果存在这样的共享内存，返回此共享内存的标识符 c) IPC_CREAT|IPC_EXCL 不存在则创建一个key的共享内存，存在则返回错误。 成功返回0，失败返回-1。EINVAL 参数size小于SHMMIN或大于SHMMAX。EEXIST 预建立key所指的共享内存，但已经存在。 EIDRM参数key所指的共享内存已经删除。 ENOSPC超过了系统允许建立的共享内存的最大值(SHMALL)。 ENOENT参数key所指的共享内存不存在，而参数shmflg未设IPC_CREAT位。EACCES没有权限 ENOMEM 核心内存不足。 int shmctl(int shmid, int cmd, struct shmid_ds *buf) 设置共享内存。 参数 shmid是共享内存的id 。 参数 cmd 指定了本次操作的行为。IPC_STAT 得到共享内存的状态，把共享内存的shmid_ds结构复制到buf中。IPC_SET改变共享内存的状态，把buf所指的shmid_ds结构中的uid、gid、mode复制到共享内存的shmid_ds结构内IPC_RMID删除这片共享内存。 参数 shmid_ds是一些共享内存的设置。创建新字段时，应按照下面的初始化设置进行初始化。 struct shmid_ds { struct ipc_perm shm_perm; // Ownership and permissions 权限初始化 size_t shm_segsz; // Size of segment (bytes) 初始化设置为请求的size time_t shm_atime; // Last attach time 初始化设置为0 time_t shm_dtime; // Last detach time 初始化设置为0 time_t shm_ctime; // Last change time 初始化设置为当前时间 pid_t shm_cpid; // PID of creator pid_t shm_lpid; // PID of last shmat(2)/shmdt(2) 初始化设置为0 shmatt_t shm_nattch; // No. of current attaches 初始化设置为0 ... }; void *shmat(int shmid, const void *shmaddr, int shmflg) 连接指定id的共享内存。连接后，这片共享内存就可以在进程空间内访问。 参数shmid是共享内存的id。 参数shmaddr指定本进程内内存的地址，之后这片地址会映射到共享内存。如果设为NULL，由系统决定地址（没有特殊需要就设为NULL）。 参数shmflg 提供了一些选项。SHM_RDONLY 为只读模式，其他为读写模式。 成功返回连接的本进程内存地址，失败返回-1。 函数fork后，子进程会继承已连接的这片地址。exec后，子进程会和这片共享内存结束连接。 int shmdt(const void *shmaddr) 结束这片共享内存的映射。 参数shmaddr指定本进程内内存的地址，是上面的shmat返回的。 成功返回0，失败返回-1。 shmdt执行后，shm_nattch会减一。 ","date":"2019-08-01","objectID":"/ipc/:6:0","tags":["Linux","AUPE"],"title":"[Linux]进程间通信","uri":"/ipc/"},{"categories":["Linux"],"content":"当处理多个IO时，阻塞往往不是可行的方案。本文介绍了select、poll、epoll的用法和注意点。","date":"2019-07-31","objectID":"/linux_epoll/","tags":["Linux","AUPE"],"title":"[Linux]高级IO","uri":"/linux_epoll/"},{"categories":["Linux"],"content":"如果有多个IO需要处理 当一个描述符读，然后又写到另一个描述符时，可以用循环的方式访问阻塞io： #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #define BUF_SIZE 128 int main(){ char buf[BUF_SIZE]; int n; while ( n = read(STDIN_FILENO, buf, BUF_SIZE) \u003e 0) { if (write(STDOUT_FILENO, buf, n) != n){ fprintf(stderr, \"%s\\n\", \"write error!\"); break; } } return 0; } 但是如果要从两个fd读的时候，就不能用阻塞io去读了。因为进程阻塞在某个fd的时候，另一个fd即使输入了数据也无法处理。 比如一个telnet程序的输出有两个来源，用户输入回显和远端回包。如果阻塞在等待远端回包，用户输入就不会有回显了。解决这个问题就几种思路： 再fork一个进程，每个进程处理一个fd。这看起来很好，但是处理EOF却成了问题。如果子进程先读到EOF，那么子进程终止，返回SIGCHLD给父进程，然后父进程终止。如果父进程读到EOF，父进程就需要通知子进程结束，此时需要额外的信号（如SIGUSER1）. 用两个线程来处理，每个线程一个fd。同样的，处理线程之间的同步也会变的比较复杂。 用非阻塞的io来轮询。先read一个fd，如果没数据立即返回，然后等待若干时间，然后再read下一个fd，直到某个fd有数据读为止。这个方法有两个缺点，一是频繁的read调用浪费了cpu时间，但是大部分时间是没数据读的。二是每次read返回后等待的时间不好确定，太久会读取不及时，太短会使得cpu更加繁忙。 使用异步IO。当fd归属的设备准备好的时候，用信号通知处理进程。这个方法有两个缺点，一是信号在不同的系统上实现不同，移植性较差。二是进程收到的信号只有一种（SIGPOLL或者SIGIO），进程无法分辨是哪个fd。 有没有比较完善的方案？io多路复用来了。这种方案会记录一个我们需要的fd的列表，然后我们去查询，当这个列表中有fd有数据时，查询就会返回这个fd。 IO多路复用：select int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数提供了查询fd状态的能力。我们传入希望监听的fd，内核告诉我们哪些fd已经有事件发生并返回。 参数 timeout 控制愿意等待的时间。timeval为NULL时，select会一直阻塞等待某个fd准备好。（如果接收到信号，select也会提前返回-1，并把errno设为INTR） 参数 readfds, writefds, exceptfds 是我们告诉内核希望监听的fd的指针。如果希望监听某fd的读事件，就加入到readfds中。后面两个用于监听写事件和异常事件。 返回时，readfds, writefds, exceptfds 中会留下对应事件已经就绪的fd。此时这些fd是可读的、可写的或发生异常的。 参数 nfds 是三个fd集合中的最大值加一，它制定了fd的遍历范围。也可以把它设为FD_SETSIZE，一般为1024，但是这样会导致select遍历系统中所有的fd。 返回值：a)如果没有就绪的fd，函数返回0。b)如果有就绪的fd，函数返回就绪的fd数量。c)如果收到信号，返回-1，并把errno设为INTR d)特别地，如果fd到达EOF，函数调用read，然后返回0 函数pselect采用了timespec类型的超时设置。此外，还可以设置sigmask用来屏蔽一些信号，防止自己被终止。 fd_set 是一个fd的集合。在实现上是一个大bit数组，它只支持赋值操作和下面宏定义的操作： // 如果fd在fd_set中返回0 int FD_ISSET(int fd, fd_set *set); // 初始化fd_set void FD_ZERO(fd_set *set); // 设置某个fd void FD_SET(int fd, fd_set *set); // 清除某个fd void FD_CLR(int fd, fd_set *set); 下面给了一个select的例子。他会等待输入五秒钟，如果有输入会立马回显。如果超时，则会直接退出。 #include \u003cstdio.h\u003e #include \u003csys/time.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e #define TIMEOUT 5 /* select timeout in seconds */ #define BUF_LEN 1024 /* read buffer in bytes */ int main( void ) { struct timeval tv; fd_set readfds; int ret; /* Wait on stdin for input. */ FD_ZERO( \u0026readfds ); FD_SET( STDIN_FILENO, \u0026readfds ); /* Wait up to five seconds. */ tv.tv_sec = TIMEOUT; tv.tv_usec = 0; /* All right, now block! */ ret = select( STDIN_FILENO + 1, \u0026readfds, NULL, NULL, \u0026tv ); if ( ret == -1 ) { perror(\"select\"); return(1); } else if ( !ret ) { printf(\"%d seconds elapsed.\\n\", TIMEOUT ); return(0); } /* * * Is our file descriptor ready to read? * * (It must be, as it was the only fd that * * we provided and the call returned * * nonzero, but we will humor ourselves.) * */ if ( FD_ISSET( STDIN_FILENO, \u0026readfds ) ) { char buf[BUF_LEN + 1]; int len; /* guaranteed to not block */ len = read( STDIN_FILENO, buf, BUF_LEN ); if ( len == -1 ) { perror(\"read\"); return(1); } if ( len ) { buf[len] ='\\0'; printf(\"read: %s \\n\", buf ); } return(0); } fprintf( stderr,\"This should not happen !\\n\"); return(1); } IO多路复用：poll select有一些缺点。由于传入的fd的集合是一个bit数组，所以select必须得从0开始一直扫描到nfds指定的最大值，效率很低。poll优化了select的一些易用性的问题。 int poll(struct pollfd *fds, nfds_t nfds, int timeout); struct pollfd { int fd; /* file descriptor */ short events; /* requested events */ short revents; /* returned events */ }; // short events 定义 POLLIN 有数据可读。（和POLLRDNORM | POLLRDBAND 等价） POLLRDNORM 有正常数据可读。 POLLRDBAND 有优先数据可读。 POLLPRI 有高优先数据可读。 POLLOUT 写操作不会阻塞。（和POLLWRNORM | POLLBAND 等价） POLLWRNORM 写正常数据不会阻塞。 POLLBAND 写优先数据不会阻塞。 POLLMSG 有一个SIGPOLL消息可用。 POLLER 输入的fd有错误。 POLLHUP fd被挂起。（请注意，文件到达EOF，会返回POLLIN，然后read返回0） POLLNVAL 输入的fd无效。 POLLIN | POLLPRI 对应select的读事件 POLLOUT | POLLWRBAND 对应select的写事件 poll 函数提供了一个select的改进版本。 参数 fds 是一个poolfd的指针，或者一个数组（同时监听多个fd）。poolfd这个结构体包含三个参数，监视的文件描述符fd，关注的event事件类型events，和内核返回的fd的事件类型revents 。 参数 nfds 告诉我们需要监听的fd数量，即参数 fds 的长度。 参数 timeout 告诉我们等待多久超时，单位为ms。为-1时，poll永远不超时。为0时，poll立即返回。为正数时，poll等待对应的毫秒数。 那么到底poll有哪些改进？ poll优化了参数。a)无需调用者知道fd最大值加一是什么。b)而且不用每次调用前都初始化select的fdset（se","date":"2019-07-31","objectID":"/linux_epoll/:0:0","tags":["Linux","AUPE"],"title":"[Linux]高级IO","uri":"/linux_epoll/"},{"categories":["Linux"],"content":"初始化和注册事件：epoll_create / epoll_ctl int epoll_create(int size) 创建一个epoll实例，返回该实例的fd。 参数size为估计的处理fd数量，越精确性能越高。Linux 2.6后不在使用该参数 成功时，返回fd。失败时，返回-1，并设置errno。 返回的fd和要处理的fd没有关联，只是用来调用epoll。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event) 在一个epoll中添加监听的fd和对应的时间类型 参数epfd为上面create返回的epollfd 参数op有几个值：EPOLL_CTL_ADD 添加fd，EPOLL_CTL_DEL 删除fd，EPOLL_CTL_MOD 改变fd监听类型。 参数fd是监听的fd对象。 参数event见下面的代码块。 成功后，epoll_ctl返回0 。失败时，返回-1，并设置errno。 typedef union epoll_data { void *ptr; int fd; __uint32_t u32; __uint64_t u64; } epoll_data_t; struct epoll_event { __uint32_t events; /* Epoll 事件类型，见下面 */ epoll_data_t data; /* 用户存储数据，稍后会返回 */ }; // Epoll 事件类型 EPOLLIN 文件可读 EPOLLOUT 文件可写 EPOLLPRI 高优先级文件可读 EPOLLET 设置为边沿触发，默认为水平触发。 EPOLLHUP 文件挂起。默认会监听 EPOLLERR 文件出错。默认会监听 EPOLLONESHOT 一次性监听，有事件发生并处理后不再监听该文件。 // 下面是一个关联事件类型的样例 struct epoll_event event; event.data.fd = fd; event.events = EPOLLIN | EPOLLOUT; int ret = epoll_ctl(epfd, EPOLL_CTL_ADD, fd, \u0026event); if(ret != 0) perror(\"epoll_ctl\") ","date":"2019-07-31","objectID":"/linux_epoll/:1:0","tags":["Linux","AUPE"],"title":"[Linux]高级IO","uri":"/linux_epoll/"},{"categories":["Linux"],"content":"监听事件：epoll_wait int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout) 等待某个epoll上的fd发生事件，时限为timeout毫秒。 参数epfd为需要等待的epollfd 参数events为返回的事件的地址。也可以是一个数组。 参数 maxevents 表明返回的事件数量不能超过该值，一般时数组的长度。 参数 timeout 告诉我们等待多久超时，单位为ms。为-1时，poll永远不超时。为0时，poll立即返回。为正数时，poll等待对应的毫秒数。 下面时一个完整的wait样例。 #define MAX_EVENTS 64 struct epoll_event *events; int nr_events, i, epfd; events = malloc( sizeof(struct epoll_event) * MAX_EVENTS ); if ( !events ) { perror( \"malloc\" ); return(1); } nr_events = epoll_wait( epfd, events, MAX_EVENTS, −1 ); if ( nr_events \u003c 0 ) { perror( \"epoll_wait\" ); free( events ); return(1); } for ( i = 0; i \u003c nr_events; i++ ) { printf( \"event=%ld on fd=%d\\n\", events[i].events, events[i].data.fd ); /* * We now can, per events[i].events, operate on * events[i].data.fd without blocking. */ } free( events ) ","date":"2019-07-31","objectID":"/linux_epoll/:2:0","tags":["Linux","AUPE"],"title":"[Linux]高级IO","uri":"/linux_epoll/"},{"categories":["Linux"],"content":"边沿触发和水平触发 ","date":"2019-07-31","objectID":"/linux_epoll/:3:0","tags":["Linux","AUPE"],"title":"[Linux]高级IO","uri":"/linux_epoll/"},{"categories":["Linux"],"content":"两种触发的区别 epoll默认的工作方式是水平触发。在水平触发模式下，只要满足fd可读/写，每次调用epoll_wait都会返回这个fd。在边沿触发模式下，只有fd从不可读(写)变为可读(写)时，才会返回这个fd。（读缓冲区有数据就是可读，写缓冲区不满就是可写） 考虑下面的情况，两种触发模式的epoll都监听了读缓冲区： 读缓冲区刚开始是空的 读缓冲区写入2KB数据 水平触发和边缘触发模式此时都会发出可读信号 收到信号通知后，读取了1kb的数据，读缓冲区还剩余1KB数据 水平触发会再次进行通知，而边缘触发不会再进行通知 所以，边缘触发需要一次性的把缓冲区的数据读完为止，也就是一直读，直到读到EGAIN为止，EGAIN说明缓冲区已经空了，因为这一点，边缘触发需要设置文件句柄为非阻塞。 //水平触发LT ret = read(fd, buf, sizeof(buf)); //边缘触发ET while(true) { ret = read(fd, buf, sizeof(buf); if (ret == EAGAIN) break; } ","date":"2019-07-31","objectID":"/linux_epoll/:3:1","tags":["Linux","AUPE"],"title":"[Linux]高级IO","uri":"/linux_epoll/"},{"categories":["Linux"],"content":"两种触发的使用方法 参考 dongyue-epoll LT/ET 深入剖析 LT的处理过程： . accept一个连接，添加到epoll中监听EPOLLIN事件 . 当EPOLLIN事件到达时，read fd中的数据并处理 . 当需要写出数据时，把数据write到fd中；如果数据较大，无法一次性写出，那么在epoll中监听EPOLLOUT事件 . 当EPOLLOUT事件到达时，继续把数据write到fd中；如果数据写出完毕，那么在epoll中关闭EPOLLOUT事件 ET的处理过程： . accept一个一个连接，添加到epoll中监听EPOLLIN|EPOLLOUT事件 . 当EPOLLIN事件到达时，read fd中的数据并处理，read需要一直读，直到返回EAGAIN为止 . 当需要写出数据时，把数据write到fd中，直到数据全部写完，或者write返回EAGAIN . 当EPOLLOUT事件到达时，继续把数据write到fd中，直到数据全部写完，或者write返回EAGAIN 使用ET模式，特定场景下会比LT更快，因为它可以便捷的处理EPOLLOUT事件，省去打开与关闭EPOLLOUT的epoll_ctl(EPOLL_CTL_MOD)调用。从而有可能让你的性能得到一定的提升。 例如你需要写出1M的数据，写出到socket 256k时，返回了EAGAIN, 然后： ET模式下，当再次epoll返回EPOLLOUT事件时，继续写出待写出的数据，当没有数据需要写出时，不处理直接略过即可。 LT模式则需要先打开EPOLLOUT，当没有数据需要写出时，再关闭EPOLLOUT（否则会一直返回EPOLLOUT事件） 总体来说，ET处理EPOLLOUT方便高效些，LT不容易遗漏事件、不易产生bug如果server的响应通常较小，不会触发EPOLLOUT，那么适合使用LT，例如redis等。而nginx作为高性能的通用服务器，网络流量可以跑满达到1G，这种情况下很容易触发EPOLLOUT，则使用ET。 ","date":"2019-07-31","objectID":"/linux_epoll/:3:2","tags":["Linux","AUPE"],"title":"[Linux]高级IO","uri":"/linux_epoll/"},{"categories":["Linux"],"content":"和select/poll 相比 各种IO复用模型的比较-云社区 epoll和kqueue （FreeBSD上和epoll类似的组件）是更先进的IO复用模型。比起select和poll来说： 没有最大连接数的限制。1G内存，可以打开约10万左右的连接。而且仅仅使用一个文件描述符，就可以管理多个文件描述符。 内核拷贝只在初始化后发生一次。将用户关系的文件描述符的事件存放到内核的一个事件表中（底层采用的是mmap的方式），这样在用户空间和内核空间的copy只需一次。 复杂度O(1)。这种模型里面，采用了类似事件驱动的回调机制或者叫通知机制，在注册fd时加入特定的状态，一旦fd就绪就会主动通知内核。这样以来就避免了select的无脑遍历socket的方法，这种模式下仅仅是活跃的socket连接才会主动通知内核，所以直接将时间复杂度降为O(1)。 ","date":"2019-07-31","objectID":"/linux_epoll/:4:0","tags":["Linux","AUPE"],"title":"[Linux]高级IO","uri":"/linux_epoll/"},{"categories":["后台"],"content":"多线程计数依然是处理多线程问题中最基础的操作之一。本文讨论了简单的并行计数、最终一致的并行计数、有上限的并行计数等，视图从这个最简单的问题中学习并行设计的思维。","date":"2019-07-26","objectID":"/counting/","tags":["Linux","perfbook"],"title":"[Linux]谈一谈并行Counting","uri":"/counting/"},{"categories":["后台"],"content":"简单的并行计数 在一个简单的多线程计数程序中，我们假设要每个线程去把sum的值多加100m，同时进行。代码如下： #include \u003cpthread.h\u003e #include \u003cstdio.h\u003e #if 0 #define ADD_P(x) __sync_fetch_and_add((x), 1) #else #define ADD_P(x) (++(*x)) #endif #define TC 8 void *thgo(void *arg){ long i = 1000*1000*100; while(i-- \u003e 0){ADD_P((long *)arg);}; pthread_t me = pthread_self(); printf(\"thread sum: %ld tid: %lu \\n\", *(long *)arg, (unsigned long)me); } int main (){ long sum = 0; pthread_t ths[TC]; // threads for (int i = 0; i \u003c TC; ++i){ pthread_create(\u0026ths[i], NULL, thgo, \u0026sum); } // main thread thgo(\u0026sum); // join for (int i = 0; i \u003c TC; ++i){ pthread_join(ths[i], NULL); } printf(\"all final sum : %ld\\n\", sum); return 0; } 如果使用一般的计数，会出现严重的数据踩踏问题，导致结果只能取得一定近似的值： $ time ./t thread sum_added : 96683538 tid: 139864218973952 thread sum_added : 97597912 tid: 139864210581248 thread sum_added : 98631229 tid: 139864202188544 thread sum_added : 106625687 tid: 139864228308800 all final sum : 106628420 real 0m1.079s user 0m4.240s sys 0m0.000s 如果切换原子原语，性能会下降大约八倍（4个线程，在一亿的计数时）。原因是一个变量被4个线程同时竞争，等待的时间大大加长。 thread sum_added : 297410188 tid: 140249129400064 thread sum_added : 323862913 tid: 140249121007360 thread sum_added : 325497470 tid: 140249137792768 thread sum_added : 399999202 tid: 140249147127616 all final sum : 400000000 real 0m8.323s user 0m31.044s sys 0m0.000s 上面是一个使用原子原语时，线程个数和花费时间的关系。随着线程个数的增多，耗时几乎是等比例增长。 经常写计数，偶尔读计数 有一个程序每秒钟处理1亿左右的包，我们需要每五秒查看一下总包长。这是一个典型的经常写计数，偶尔读计数的场景。 ","date":"2019-07-26","objectID":"/counting/:0:0","tags":["Linux","perfbook"],"title":"[Linux]谈一谈并行Counting","uri":"/counting/"},{"categories":["后台"],"content":"利用数组分开计数 一个经典的方法是，取消上一节中进程们共享的变量，改为每个进程独有的变量，然后再做加和。在下面的代码中，用线程id作为key，线程自己的计数作为value建立了map，各个线程分别写入自己的计数器内，避免了冲突。伪代码如下： counts = {} void write_count(){ tid = pthread_self() counts[tid] += 1 } long read_count(){ sum = 0 for tid, c in counts{ sum += c } return sum } 这种方法有两个问题： 读操作时，写操作依然在进行，导致结果不准确。读到的不同线程的计数，介于开始读到读结束的窗口之间。 读操作需要聚合所有线程，对读取端而言比较复杂 ","date":"2019-07-26","objectID":"/counting/:1:0","tags":["Linux","perfbook"],"title":"[Linux]谈一谈并行Counting","uri":"/counting/"},{"categories":["后台"],"content":"定时刷新，最终一致 为了解决上述的两个问题，我们设计了最终一致的版本：每隔1ms把所有线程的计数加和，存入全局变量中。这样有两个优点： 不一致窗口最多为1ms 读取的时候只要直接读变量就可以了，不用加和 counts = {} global_count = 0 void write_count(){ tid = pthread_self() counts[tid] += 1 } long read_count(){ return global_count } // 另起一个线程用来计数 void eventual_count(){ for { sum = 0 for tid, c in counts{ sum += c } global_count = sum sleep 1ms } } Note: 线程数量增多时，eventual_count可能会越来越不准确。解决这个问题的方法是对线程分组，每组线程让一个eventual_count线程来处理计数，这样每个eventual_count线程都不会耗费太多的时间处理。必要的时候，可以采用树状的eventual_count线程，层级处理。 ","date":"2019-07-26","objectID":"/counting/:2:0","tags":["Linux","perfbook"],"title":"[Linux]谈一谈并行Counting","uri":"/counting/"},{"categories":["后台"],"content":"线程私有的__thread __thread gcc提供的关键字，修饰线程私有的变量。修饰后每个线程都有一份该变量实体，且值互不干扰。 counter 是每个线程自己的计数器，long类型。 counterp 是一个用于存放线程私有变量指针的数组。初始化时，把线程私有变量的地址写进数组。读取时，读取所有指针的值加和。 unsigned long __thread counter = 0; unsigned long *counterp[NR_THREADS] = { NULL }; unsigned long finalcount = 0; DEFINE_SPINLOCK(final_mutex); void inc_count(void) { counter++; } unsigned long read_count(void) { int t; unsigned long sum; spin_lock(\u0026final_mutex); sum = finalcount; for_each_thread(t) if (counterp[t] != NULL) sum += *counterp[t]; spin_unlock(\u0026final_mutex); return sum; } void count_register_thread(void) { int idx = smp_thread_id(); spin_lock(\u0026final_mutex); counterp[idx] = \u0026counter; spin_unlock(\u0026final_mutex); } 近似上限的计数 有一些场景需要我们限制计数器的上限，比如限制一个广告曝光的次数。各个线程处理广告的请求，每返回一个广告就给计数器加一，直到总上限到达，就不再返回广告。 比较理想的方案是把任务平均分给每个线程，当他们都达到上限时，认为总上限也已经到达。这样会有几个问题： 每个线程曝光广告的速度不同，可能有点线程很快到达上限了，有的却没有曝光，攒了大量的指标。 这时候如果曝光满了的线程还要继续处理曝光，就要写别的线程的计数器。这会造成昂贵的跨线程通信。 我们可以从上一节的最终一致的方法得到启发，把计数任务分割给各个线程。我们维护一个每个线程的计数器counter和每个线程的计数上限countermax，以及一个全局的计数器globalcount和全局的计数上限globalcountmax。 需要注意的是，我们额外引入了一个globalreserve。它在数值上是countermax的和，用来表示预分配给每个counter的名额，也算在已经用掉的指标里。 这个方法的思想在于，先预分配给每个线程一些指标。如果有一个线程指标都用掉了，那么就收集里面的计数，并给他分配新的指标。直到所有的指标都用尽为止。收集计数的过程，就是globalize_count。分配计数的过程，就是balance_count。流程如下图 这种设计就是一个并行快速路径的例子，这是一种重要的设计模式，适用于下面这种情况：在多数情况没有线程间通信和交互的开销，而偶尔进行的跨进程通信又使用了精心设计的（但是开销仍然很大）全局算法。 在阅读代码之后，还有几点需要思考： 这种计数会有误差。这个方法给每个线程预分配了计数值，但是这些计数值未必有被真实使用。所以最大会有globalreserve大小的误差。 在每个线程刚开始计数时，countermax被设置为总上限除以线程数的值。此时globalreserve和总上限值相等，这意味着最差情况下，如果一直请求某一个特定线程，很快就到达上限了。 我们设置了MAX_COUNTERMAX来缓解第二点的问题。这样globalreserve不会迅速增长的过大。 countermax的值直接决定了误差。当离上限还比较远时，可以给每线程变量countermax赋值一个比较大的数，这样对性能和扩展性比较有好处。当靠近上限时，可以给这些countermax赋值一个较小的数，这样可以降低超过globalcountmax的风险。 在balance操作的时候，我们把counter 设为 countermax/2，这样就可以保证，a)每次计数器把计数交还给总数时，至少有一半的计数被使用了。b)加减计数都能在快速路径中 c)第二点的问题得到缓解 MAX_COUNTERMAX 导致不能进入快速路径的线程增加了，这会导致性能的降低。 unsigned long __thread counter = 0; unsigned long __thread countermax = 0; unsigned long globalcountmax = 10000; unsigned long globalcount = 0; unsigned long globalreserve = 0; unsigned long *counterp[NR_THREADS] = { NULL }; DEFINE_SPINLOCK(gblcnt_mutex); #define MAX_COUNTERMAX 100 static void globalize_count(void) { globalcount += counter; counter = 0; globalreserve -= countermax; countermax = 0; } static void balance_count(void) { countermax = globalcountmax - globalcount - globalreserve; countermax /= num_online_threads(); if (countermax \u003e MAX_COUNTERMAX) countermax = MAX_COUNTERMAX; globalreserve += countermax; counter = countermax / 2; if (counter \u003e globalcount) counter = globalcount; globalcount -= counter; } int add_count(unsigned long delta) { // 减，而不是countermax + delta。防止整形溢出。 if (countermax - counter \u003e= delta) { counter += delta; return 1; } // 所有的全局变量访问都会上锁 spin_lock(\u0026gblcnt_mutex); globalize_count(); if (globalcountmax - globalcount - globalreserve \u003c delta) { spin_unlock(\u0026gblcnt_mutex); return 0; } globalcount += delta; balance_count(); spin_unlock(\u0026gblcnt_mutex); return 1; } unsigned long read_count(void) { int t; unsigned long sum; spin_lock(\u0026gblcnt_mutex); sum = globalcount; for_each_thread(t) if (counterp[t] != NULL) sum += *counterp[t]; spin_unlock(\u0026gblcnt_mutex); return sum; } void count_register_thread(void) { int idx = smp_thread_id(); spin_lock(\u0026gblcnt_mutex); counterp[idx] = \u0026counter; spin_unlock(\u0026gblcnt_mutex); } ","date":"2019-07-26","objectID":"/counting/:3:0","tags":["Linux","perfbook"],"title":"[Linux]谈一谈并行Counting","uri":"/counting/"},{"categories":["Linux"],"content":"如何进行并行编程？本文给了一些pthead库基本的多进程（fork、wait）、多线程（create、join、mutex、rwlock、cond、barrier）API，和详细的样例帮助理解这些API。","date":"2019-07-25","objectID":"/pthread/","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"如何进行并行编程？本文给了一些pthead库基本的多进程、多线程API，和详细的样例帮助理解这些API。 本教程基于AUPE 2013、 perfbook Shell中的并行 ","date":"2019-07-25","objectID":"/pthread/:0:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"后台执行 \u0026 通过\u0026符号指定实例在后台运行，然后统一等待结束。 compute_it 1 \u003e 1.out \u0026 compute_it 2 \u003e 2.out \u0026 wait cat 1.out 2.out ","date":"2019-07-25","objectID":"/pthread/:1:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"管道 | 对于一个足够大的输入文件来说，grep模式匹配将与sed编辑和sort处理并行运行。 grep \"$pattern\" | sed -e \"s/a/b/\" | sort POSIX多进程 下面给出的程序中建立了一个进程，然后修改了x的值并打印，最后父进程等待子进程结束。 ","date":"2019-07-25","objectID":"/pthread/:2:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"fork int fork()马上创建一个当前进程的子进程。子进程会复制(而不是共享)父进程的堆栈、数据空间、fd。 如果是父进程，fork返回子进程的pid。如果是子进程，fork返回0。一般用这个区分不同的分支。 fork返回负数表示失败。失败的原因可能有：系统有了太多的进程；系统中用户进程数超过了CHILD_MAX。此时返回负数。 fork后如果不需要父进程的存储空间会立马调用exec。 使用fork一般有两个目的。父进程希望复制自己，或者想执行另外的程序（调用exec） 为了避免拷贝成本，出现了写时拷贝技术(Copy-On-Write, COW)，子进程创建后分享父进程的数据，并把内存区域设置为只读。当需要写数据时再为这块数据创建副本。 ","date":"2019-07-25","objectID":"/pthread/:3:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"vfork int vfork()创建一个子进程，但分享(不复制)父进程的数据。当执行exec时父进程才退出休眠。专为了避免fork的拷贝成本设计。因为share父进程的数据有很大风险，所以man手册里明确说明vfork()之后，子进程只应该调用_exit()或者exec函数族。 ","date":"2019-07-25","objectID":"/pthread/:4:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"exit void exit(int)退出当前进程。不像return会析构局部变量，弹栈，回到上级函数。如果在子进程的main中调用了return，main会返回两次，导致程序出错。exit不会有这个问题。 ","date":"2019-07-25","objectID":"/pthread/:5:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"wait pid_t wait(int \u0026status) 阻塞等待任意一个子进程结束 a)如果子进程都在运行则阻塞 b)如果一个子进程已经终止，内核向父进程发出了SIGCHLD信号，则获得终止状态并立即返回 c)成功了返回pid，没有子进程，立即出错返回-1 d)子进程状态status可以用四个返回bool的宏 WIFEXITED(int)、WIFEXITSIGNALED(int)、WIFSTOPPED(int)、WIFCONTINUED(int)、来判断属于正常、异常、暂停、暂停后继续的状态。此外还有对应的WEIXTSTATUS(int)返回子进程exit函数的参数、WTERMSIG(int)返回信号编号、WCOREDUMP(int）返回是否生成coredump等。 pid_t waitpid(pid_t pid, int \u0026status, int option)等待指定的pid的子进程结束。 a)当pid=-1，和wait等效。 b)当option=WNOHANG，此函数会立即返回不会阻塞。 c)成功了返回pid，没有子进程，立即出错返回-1 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cerrno.h\u003e #include \u003cpoll.h\u003e #include \u003csys/wait.h\u003e #include \u003cunistd.h\u003e int x = 0; // 等待所有的子进程结束 static __inline__ void waitall(void) { int pid; int status; for (;;) { pid = wait(\u0026status); //sys/wait.h if (pid == -1) { if (errno == ECHILD) //errno.h 子进程不存在 break; perror(\"wait\"); exit(EXIT_FAILURE); } poll(NULL, 0, 1); // 等待1ms } } int main(int argc, char *argv[]) { int pid; pid = fork(); // \u003cunistd.h\u003e if (pid == 0) { /* child */ x = 1; printf(\"Child process set x=1\\n\"); exit(EXIT_SUCCESS); //stdlib } if (pid \u003c 0) { /* parent, upon error */ perror(\"fork\"); //stdio exit(EXIT_FAILURE); //stdlib } /* parent */ waitall(); //父进程一直等待到子进程退出后才调用printf（）。 //通过不同进程并发地访问printf（）的I/O缓冲区并不简单，最好也不要这么做 printf(\"Parent process sees x=%d\\n\", x); return EXIT_SUCCESS; } POSIX多线程 ","date":"2019-07-25","objectID":"/pthread/:6:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"pthread_create int pthread_create(pthread_t tidp, const pthread_attr_t *attr, void *(*start_rtn)(void *), void *arg)创建一个线程去执行参数start_rtn中的函数。该函数参数为arg。tidp参数则会写入线程的线程ID。 这三个指针都是restrict修饰的，代表保证他们不指向同一区域，使得编译器能够优化。 pthread_t标识线程ID，是一个非负整数。为了移植性不能当int处理。pthread_equal(tid1, tid2)可以检测两个id是否相等。pthread_self()可以获取当前的线程ID。 成功返回0，失败返回 EINVAL、EAGAIN、EPERM。 ","date":"2019-07-25","objectID":"/pthread/:7:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"pthread_exit void pthread_exit(void *status)提供了一个线程退出的方法。 线程有三种退出方式： 在线程函数中自然返回。返回值是线程的退出码。 被同进程的其他线程取消。此时线程的返回值是PTHREAD_CANCELED。 调用pthread_exit。返回值会通过参数status传出去。 ","date":"2019-07-25","objectID":"/pthread/:8:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"pthread_join int pthread_join(pthread_t thread, void **retval) 用于在其他线程中等待指定的线程。 该函数会一直卡住，等待ID为参数thread的线程退出。 retval会接收等待的线程返回值。如果不关心返回值直接设为NULL。 成功时返回0，失败时返回EDEADLK、ESRCH、EINVAL。 void pthread_cleanup_push(void (*routine)(void *), void *arg)注册一个线程结束时调用的清理函数。参数routine为调用的函数指针，arg为该函数的参数。下面的情况会触发这个清理函数： a）调用pthread_exit。 b）作为对取消线程请求(pthread_cancel)的响应。 c）以非0参数调用 pthread_cleanup_pop(int)。 pthread_cleanup_pop(int execute)用于删除清理函数，当execute不为0时不会执行清理函数。需要注意此函数和push必须数量相等，不然会报错。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cpthread.h\u003e #include \u003cstring.h\u003e int x = 0; void *mythread(void *arg) { x = 1; printf(\"Child process set x=1\\n\"); return NULL; } int main(int argc, char *argv[]) { int en; pthread_t tid; void *vp; if ((en = pthread_create(\u0026tid, NULL,mythread, NULL)) != 0) { fprintf(stderr, \"pthread_join: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } /* parent */ if ((en = pthread_join(tid, \u0026vp)) != 0) { fprintf(stderr, \"pthread_join: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } printf(\"Parent process sees x=%d\\n\", x); return EXIT_SUCCESS; } POSIX 锁 通常用互斥锁在避免资源间的竞争。当一个资源被锁住时，其他资源如果试图获得锁，他就会等待锁释放再执行。 ","date":"2019-07-25","objectID":"/pthread/:9:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"声明 // 声明 pthread_mutex_t mymutex; // 另一个静态声明+初始化方法，其中INITIALIZER是一个结构体 { { 0, 0, 0, 0, 0, 0, { 0, 0 } } } pthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER; ","date":"2019-07-25","objectID":"/pthread/:10:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"初始化和释放 int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr) 使用前必须初始化。mutex是要初始化的锁。 pthread_mutexattr_t提供了锁的初始化选项。如果不需要设置为NULL。 成功返回0，失败返回错误码 int pthread_mutex_destroy(pthread_mutex_t *mutex)使用后锁必须被摧毁。 成功返回0，失败返回错误码 ","date":"2019-07-25","objectID":"/pthread/:11:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"加锁和释放锁 int pthread_mutex_lock(pthread_mutex_t *mutex) 占用锁，如果锁被占用，会一直等待 int pthread_mutex_unlock(pthread_mutex_t *mutex) 释放锁 成功返回0，失败返回错误码 int pthread_mutex_trylock(pthread_mutex_t *mutex) 试图占用锁 a) 如果锁没有被占用，会占用锁并返回0 b) 如果锁已经被占用，会返回EBUSY int pthread_mutex_timedlock(pthread_mutex_t *restrict mutex, const struct timespec *restrict abs_timeout) 占用锁，如果锁被占用，会一直等待到abs_timeout这个时间点，返回超时 abs_timeout是绝对时间，是未来的一个时间戳 等待超时后返回ETIMEDOUT // 声明、初始化 pthread_mutex_t mymutex; pthread_mutex_init(\u0026mymutex, NULL); // 锁 pthread_mutex_lock(\u0026mymutex); // ... do something pthread_mutex_unlock(\u0026mymutex); // 销毁 pthread_mutex_destroy(\u0026mymutex); // 一个超时锁的例子 struct timespec tout; struct tm *tmp; char buf[64]; pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; pthread_mutex_lock(\u0026lock); printf(\"mutex is locked\\n\"); clock_gettime(CLOCK_REALTIME, \u0026tout); tmp = localtime(\u0026tout.tv_sec); strftime(buf, sizeof(buf), \"%r\", tmp); printf(\"current time is %s\\n\", buf); tout.tv_sec += 10; /* 10 seconds from now */ /* caution: this could lead to deadlock */ err = pthread_mutex_timedlock(\u0026lock, \u0026tout); clock_gettime(CLOCK_REALTIME, \u0026tout); tmp = localtime(\u0026tout.tv_sec); strftime(buf, sizeof(buf), \"%r\", tmp); printf(\"the time is now %s\\n\", buf); 下面的例子有两个线程。 lock_reader 每隔1ms读一次全局变量x的值，用来监测x的变化 lock_writer 每5ms把x的值加一 如果两个线程用了一把锁，reader会等待writer写完，再去读，x只被读到一次。 如果两个线程用了两把锁（等于不加锁），writer每次更改x都会被reader读到。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cpthread.h\u003e #include \u003cerrno.h\u003e #include \u003cpoll.h\u003e #include \u003cstring.h\u003e #define ACCESS_ONCE(x) (*(volatile typeof(x) *)\u0026(x)) #define READ_ONCE(x) \\ ({ typeof(x) ___x = ACCESS_ONCE(x); ___x; }) #define WRITE_ONCE(x, val) ({ ACCESS_ONCE(x) = (val); }) pthread_mutex_t lock_a = PTHREAD_MUTEX_INITIALIZER; pthread_mutex_t lock_b = PTHREAD_MUTEX_INITIALIZER; int x = 0; void *lock_reader(void *arg) { int en; int i; int newx = -1; int oldx = -1; pthread_mutex_t *pmlp = (pthread_mutex_t *)arg; if ((en = pthread_mutex_lock(pmlp)) != 0) { fprintf(stderr, \"lock_reader:pthread_mutex_lock: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } for (i = 0; i \u003c 100; i++){ newx = READ_ONCE(x); if (newx != oldx) { printf(\"lock_reader(): x = %d at %dms\\n\", newx, i); } oldx = newx; poll(NULL, 0, 1); } if ((en = pthread_mutex_unlock(pmlp)) != 0) { fprintf(stderr, \"lock_reader:pthread_mutex_lock: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } return NULL; } void *lock_writer(void *arg) { int en; int i; pthread_mutex_t *pmlp = (pthread_mutex_t *)arg; if ((en = pthread_mutex_lock(pmlp)) != 0) { fprintf(stderr, \"lock_writer:pthread_mutex_lock: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } for (i = 0; i \u003c 3; i++) { WRITE_ONCE(x, READ_ONCE(x) + 1); poll(NULL, 0, 5); } if ((en = pthread_mutex_unlock(pmlp)) != 0) { fprintf(stderr, \"lock_writer:pthread_mutex_lock: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } return NULL; } int main(int argc, char *argv[]) { int en; pthread_t tid1; pthread_t tid2; void *vp; printf(\"Creating two threads using same lock:\\n\"); en = pthread_create(\u0026tid1, NULL, lock_reader, \u0026lock_a); if (en != 0) { fprintf(stderr, \"pthread_create: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } en = pthread_create(\u0026tid2, NULL, lock_writer, \u0026lock_a); if (en != 0) { fprintf(stderr, \"pthread_create: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } if ((en = pthread_join(tid1, \u0026vp)) != 0) { fprintf(stderr, \"pthread_join: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } if ((en = pthread_join(tid2, \u0026vp)) != 0) { fprintf(stderr, \"pthread_join: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } printf(\"Creating two threads w/different locks:\\n\"); x = 0; en = pthread_create(\u0026tid1, NULL, lock_reader, \u0026lock_a); if (en != 0) { fprintf(stderr, \"pthread_create: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } en = pthread_create(\u0026tid2, NULL, lock_writer, \u0026lock_b); if (en != 0) { fprintf(stderr, \"pthread_create: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } if ((en = pthread_join(tid1, \u0026vp)) != 0) { fprintf(stderr, \"pthread_join: %s\\n\", strerror(en)); exit(EXIT_FAILURE); } if ((en = pthread_join(tid2, \u0026vp)) != 0) ","date":"2019-07-25","objectID":"/pthread/:12:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"初始化 // 条件变量使用前也需要初始化，使用完需要释放 pthread_cond_t cond = PTHREAD_COND_INITIALIZER; int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr); int pthread_cond_destroy(pthread_cond_t *cond); ","date":"2019-07-25","objectID":"/pthread/:13:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"等待唤醒 int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex) 在cond接收到唤醒之前，该函数会一直都待。mutex是用来保护该条件变量的锁。 此函数必须用前加锁，用后解锁 了解为什么？ 本函数首先将当前线程加入到唤醒队列，然后旋即解锁mutex，最后等待被唤醒。被唤醒后，又对mutex加锁（可能是看起来没有对用户的行为作任何的改变）。 2的操作保证了线程在陷入wait后至被加入唤醒队列这段时间内是原子的。如果不加锁，可能唤醒时，等待线程尚未被加入到唤醒队列，就会产生唤醒丢失。 这个锁保证了避免唤醒丢失外，还保证了唤醒前后临界区的其他变量不被操作。 int pthread_cond_timedwait(pthread_cond_t *restrict cond, thread_mutex_t *restrict mutex,const struct timespec *restrict abstime); 在上面函数的基础上增加了绝对超时时间。 如果到达绝对时间还没被唤醒，该函数返回 ETIMEDOUT。 ","date":"2019-07-25","objectID":"/pthread/:14:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Linux"],"content":"通知唤醒 int pthread_cond_broadcast(pthread_cond_t *cond) 会唤醒所有该等待cond的线程 成功返回0，失败返回错误 int pthread_cond_signal(pthread_cond_t *cond); 会唤醒一个等待cond的线程 成功返回0，失败返回错误 #include \u003cpthread.h\u003e struct msg { struct msg *m_next; /* ... more stuff here ... */ }; struct msg *workq; // 信号量的语义是queue已经准备好消费 pthread_cond_t qready = PTHREAD_COND_INITIALIZER; pthread_mutex_t qlock = PTHREAD_MUTEX_INITIALIZER; void process_msg(void) { struct msg *mp; for (;;) { pthread_mutex_lock(\u0026qlock); // 这个while可以在queue为空时卡住自己 while (workq == NULL) pthread_cond_wait(\u0026qready, \u0026qlock); mp = workq; workq = mp-\u003em_next; pthread_mutex_unlock(\u0026qlock); /* now process the message mp */ read_map_val_add_process(mp); } } void enqueue_msg(struct msg *mp) { pthread_mutex_lock(\u0026qlock); mp-\u003em_next = workq; workq = mp; pthread_mutex_unlock(\u0026qlock); pthread_cond_signal(\u0026qready); } POSIX 屏障 屏障保证了一组线程同时到达某一点。在其他所有的线程到达wait之前，先到的线程会休眠并等待，直到大家都到达wait，再继续后面的工作。 // 初始化屏障，count为必须到达的线程数量。一旦数量满足，就继续运行 int pthread_barrier_init(pthread_barrier_t *restrict barrier, const pthread_barrierattr_t *restrict attr, unsigned count); // 摧毁屏障 int pthread_barrier_destroy(pthread_barrier_t *barrier); // 到达并等待 int pthread_barrier_wait(pthread_barrier_t *barrier); 下面的代码演示了8个线程共同完成100万个数排序的过程。 #include \"apue.h\" #include \u003cpthread.h\u003e #include \u003climits.h\u003e #include \u003csys/time.h\u003e #define NTHR 8 /* number of threads */ #define NUMNUM 8000000L /* number of numbers to sort */ #define TNUM (NUMNUM/NTHR) /* number to sort per thread */ long nums[NUMNUM]; long snums[NUMNUM]; pthread_barrier_t b; #ifdef SOLARIS #define heapsort qsort #else extern int heapsort(void *, size_t, size_t, int (*)(const void *, const void *)); #endif /* * Compare two long integers (helper function for heapsort) */ int complong(const void *arg1, const void *arg2) { long l1 = *(long *)arg1; long l2 = *(long *)arg2; if (l1 == l2) return 0; else if (l1 \u003c l2) return -1; else return 1; } /* * Worker thread to sort a portion of the set of numbers. */ void * thr_fn(void *arg) { long idx = (long)arg; heapsort(\u0026nums[idx], TNUM, sizeof(long), complong); pthread_barrier_wait(\u0026b); /* * Go off and perform more work ... */ return((void *)0); } /* * Merge the results of the individual sorted ranges. */ void merge() { long idx[NTHR]; long i, minidx, sidx, num; for (i = 0; i \u003c NTHR; i++) idx[i] = i * TNUM; for (sidx = 0; sidx \u003c NUMNUM; sidx++) { num = LONG_MAX; for (i = 0; i \u003c NTHR; i++) { if ((idx[i] \u003c (i+1)*TNUM) \u0026\u0026 (nums[idx[i]] \u003c num)) { num = nums[idx[i]]; minidx = i; } } snums[sidx] = nums[idx[minidx]]; idx[minidx]++; } } int main() { unsigned long i; struct timeval start, end; long long startusec, endusec; double elapsed; int err; pthread_t tid; /* * Create the initial set of numbers to sort. */ srandom(1); for (i = 0; i \u003c NUMNUM; i++) nums[i] = random(); /* * Create 8 threads to sort the numbers. */ gettimeofday(\u0026start, NULL); pthread_barrier_init(\u0026b, NULL, NTHR+1); for (i = 0; i \u003c NTHR; i++) { err = pthread_create(\u0026tid, NULL, thr_fn, (void *)(i * TNUM)); if (err != 0) err_exit(err, \"can't create thread\"); } pthread_barrier_wait(\u0026b); merge(); gettimeofday(\u0026end, NULL); /* * Print the sorted list. */ startusec = start.tv_sec * 1000000 + start.tv_usec; endusec = end.tv_sec * 1000000 + end.tv_usec; elapsed = (double)(endusec - startusec) / 1000000.0; printf(\"sort took %.4f seconds\\n\", elapsed); for (i = 0; i \u003c NUMNUM; i++) printf(\"%ld\\n\", snums[i]); exit(0); } ","date":"2019-07-25","objectID":"/pthread/:15:0","tags":["Linux","perfbook","AUPE"],"title":"[Linux]并行编程：进程、线程和同步","uri":"/pthread/"},{"categories":["Python"],"content":"scrapy是个很简单强大的python爬虫框架，不需要处理网络相关逻辑就可以轻松爬取。本文介绍了一些基本的内容。","date":"2019-03-20","objectID":"/scrapy/","tags":["Python","scrapy","爬虫"],"title":"[Python]Scrapy Scan","uri":"/scrapy/"},{"categories":["Python"],"content":"scrapy是个很简单强大的python爬虫框架，不需要处理网络相关逻辑就可以轻松爬取。本文介绍了一些基本的内容。需要注意的是，本文档中所有的●表示非必须内容。 本教程基于官方文档：官方文档 安装scrapy ","date":"2019-03-20","objectID":"/scrapy/:0:0","tags":["Python","scrapy","爬虫"],"title":"[Python]Scrapy Scan","uri":"/scrapy/"},{"categories":["Python"],"content":"CentOS yum install python34-devel.x86_64 pip3 install scrapy 创建项目 //创建项目hello scrapy startproject hello //创建一个爬虫（在项目根目录运行，不要加http://），名字为baidu，域名为www.baidu.com scrapy genspider baidu \"www.baidu.com\" ● 需要注意的是，如果要无视robots.txt文件，请在下面的settings.py中设置ROBOTSTXT_OBEY = False ● 刚才建好的项目目录文件树如下： tree hello hello |-- hello | |-- __init__.py | |-- items.py // 输出结构体定义 | |-- middlewares.py | |-- pipelines.py | |-- __pycache__ | |-- settings.py // 设置，记得把 ROBOTSTXT_OBEY = False | |-- spiders | |-- __init__.py | |-- baidu.py // 刚创建的爬虫 | |-- __pycache__ |-- scrapy.cfg Shell：测试代码 使用shell可以帮助实现爬虫的代码，查看网页的相关信息。结合浏览器中的审查元素查看会让你构造出需要选择的数据部分。 # 1. 在命令行中执行 scrapy shell 就可以进入shell。 # ● 下面改造了http头的USER_AGENT，一般可以防止请求因为USER_AGENT被拒绝 scrapy shell -s USER_AGENT，=\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36-480\" # 2. 进入shell后可用的对象：request、response、sel（选择器）、settings、spider、crawler # 可用的函数 帮助shelp() 请求fetch(url) fetch(req) 浏览器打开view(rsp) # 3. 接下来可以拉取网页，下面是一些操作的实例: fetch('https://www.baidu.com') # 浏览器中打开爬取的网页 view(response) # 查看req和rsp request.body response.headers # 选择网页中的元素 response.xpath('//div') sel.xpath('//title/text()').extract() # ● get 改为post request = request.replace(method=\"POST\") ","date":"2019-03-20","objectID":"/scrapy/:1:0","tags":["Python","scrapy","爬虫"],"title":"[Python]Scrapy Scan","uri":"/scrapy/"},{"categories":["Python"],"content":"● 调试您的spider 下面代码会在运行spider时，在这里进入shell调试。 from scrapy.shell import inspect_response inspect_response(response, self) 选择器：找到爬取的内容 Scrapy选择器构建于 lxml 库之上，这意味着它们在速度和解析准确性上非常相似。选择器从如下的库中获取： from scrapy.selector import Selector from scrapy.http import HtmlResponse # 可以从rsp中构造，也可以 text=\"\u003ch\u003e\u003c/h\u003e\" 从字符串中构造 response = HtmlResponse(url='http://example.com', body='') Selector(response=response).xpath('//span/text()').extract() # [u'good'] # 幸运的是rsp提供了方法直接构造选择器： response.selector.xpath('//span/text()').extract() # 以及更短的快捷方式： response.xpath('//title/text()').extract() response.css('title::text').extract() ● xpath和css是两种用来选择数据的工具，他们遵循不同的语法。但是他们都都返回一个selector对象。selector有几个成员函数很有用，他们是 extract() 返回里面文字的值 re() 用正则过滤文字值，返回文字值 xpath() css() 返回的selector依然可以用这些工具，这意味着可以嵌套 # 下面是一个从的img标签的text中获取括号内文字的方法 response.xpath('//a[contains(@href, \"image\")]/text()').re(r'Name:\\s*(.*)') # 下面是用xpath的相对路径和选择器嵌套： divs = response.xpath('//div') for p in divs.xpath('.//p'): # 父路径下的所有后代p ... for p in divs.xpath('p'): # 父路径下的所有直接 ... ","date":"2019-03-20","objectID":"/scrapy/:2:0","tags":["Python","scrapy","爬虫"],"title":"[Python]Scrapy Scan","uri":"/scrapy/"},{"categories":["Python"],"content":"● Xpath 语法参考 w3s : Xpath语法参考 Xpath是一种用于操作xml的选择器，可以快速操作想要的html标签。 语法 实例 解释 a bookstore 选取 bookstore 元素的所有子节点。 /a /bookstore 选取根元素 bookstore。 a/b bookstore/book 选取属于 bookstore 的子元素的所有 book 元素。 //a //book 选取所有 book 子元素，而不管它们在文档中的位置。 a//b bookstore//book 选择属于 bookstore 元素的后代的所有 book 元素，而不管它们位于 bookstore 之下的什么位置。 @a //@lang 选取名为 lang 的所有属性。 * /bookstore/* 选取 bookstore 元素的所有子元素。 //* 选取文档中的所有元素。 //title[@*] 选取所有带有属性的 title 元素。 ","date":"2019-03-20","objectID":"/scrapy/:3:0","tags":["Python","scrapy","爬虫"],"title":"[Python]Scrapy Scan","uri":"/scrapy/"},{"categories":["Python"],"content":"● CSS 语法参考 w3s : CSS语法参考 如果要操作一个类或者id而不是标签，CSS是最快的方法。 例子 例子描述 .intro 选择 class=“intro” 的所有元素 #firstname 选择 id=“firstname” 的所有元素 * 选择所有元素 p 选择所有 p 元素 div,p 选择所有 div元素和所有 p 元素 div p 选择 div 元素内部的所有 p 元素 div\u003ep 选择父元素为 元素的所有 元素 div+p 选择紧接在 元素之后的所有 元素 [target] 选择带有 target 属性所有元素 [target=_blank] 选择 target=\"]_blank\" 的所有元素。 [title~=flower] 选择 title 属性包含单词 “flower” 的所有元素 [lang|=en] 选择 lang 属性值以 “en” 开头的所有元素 Item：存储你爬取结果的桶 好了，现在开始写爬虫。不过在这之前需要先定义好你想要爬下来的数据格式是怎么样的，待会把他们装进去。你需要修改hello/items.py，编写一个简单的类。 class HelloItem(scrapy.Item): # 用 scrapy.Field() 作为类型就可以了 id = scrapy.Field() name = scrapy.Field() description = scrapy.Field() ● item和字典的API非常相似。可以使用get()、下标等读写item，甚至可以相互用对方初始化。 Spider：爬虫逻辑 spider是爬取流程的主体。打开hello/spiders/baidu.py，编辑成员函数和成员变量： name 爬虫的名字 allowed_domains 只允许爬取allowed_domains的内容 start_urls 运行时没指定url，就从这里开始爬 start_requests() 可以重写这个来处理第一个request。否则，将会用make_requests_from_url爬url列表里的内容。 make_requests_from_url(url) 可以重写这个来处理请求的发起。默认调用parse来处理rsp。 parse(rsp) 处理rsp。需要返回item或者req的迭代对象作为输出和下一批爬取的内容，或者都返回。 import scrapy from hello.items import HelloItem import scrapy class BaiduSpider(scrapy.Spider): # 创建爬虫时指定的名字 name = 'baidu' # ● 设置中OffsiteMiddleware=True的时候，只允许爬取allowed_domains的内容 allowed_domains = ['baidu.com'] # 爬取的目标链接 start_urls = ['http://www.baidu.com/'] # 用这个函数处理url的rsp def parse(self, response): sel = scrapy.Selector(response) # 选择所有的h3标题返回存储 for h3 in response.xpath('//h3').extract(): yield HelloItem(title=h3) # 返回链接继续爬取 for url in response.xpath('//a/@href').extract(): yield scrapy.Request(url, callback=self.parse) # ● 一个重写start_requests的样例，构造了req，并用logged_in函数处理rsp def start_requests(self): return [scrapy.FormRequest(\"http://www.example.com/login\", formdata={'user': 'john', 'pass': 'secret'}, callback=self.logged_in)] def logged_in(rsp):... 写完后，在项目目录下运行scrapy crawl来运行spider： // 基础的运行 scrapy crawl hello // 传递参数给myspider，并在构造函数中使用 scrapy crawl myspider -a category=electronics class MySpider(Spider): def __init__(self, category=None, *args, **kwargs): super(MySpider, self).__init__(*args, **kwargs) self.start_urls = ['http://www.example.com/categories/%s' % category] // 把爬到的item输出文件 scrapy crawl dmoz -o items.json PipeLine：处理item并输出 Pipeline提供了处理返回的item的几个函数。编辑hello/pipeline.py修改Pipeline的成员函数： process_item(item, spider) 每个item获取后都会用这个处理。这个函数会返回一个处理好的item。 open_spider(spider) 开启spider时被调用 close_spider(spider) 关闭spider时被调用 # 下面是一个用id去重item的样例： class DuplicatesPipeline(object): def __init__(self): self.ids_seen = set() def process_item(self, item, spider): if item['id'] in self.ids_seen: raise DropItem(\"Duplicate item found: %s\" % item) else: self.ids_seen.add(item['id']) return item from scrapy.exporters import CsvItemExporter # 一个用导出器导出的样例： from scrapy.exporters import CsvItemExporter class ExportPipeline(object): def open_spider(self, spider): self.file = open(\"test.csv\", \"wb\") self.exporter = CsvItemExporter(self.file, fields_to_export=[\"id\", \"name\", \"desc\"]) self.exporter.start_exporting() def process_item(self, item, spider): self.exporter.export_item(item) return item def close_spider(self, spider): self.exporter.finish_exporting() self.file.close() 最后，修改settings.py中的ITEM_PIPELINES保证你的Pipeline生效。key表示路径，值表示执行的顺序。 ITEM_PIPELINES = { 'mybot.pipelines.validate.DuplicatesPipeline': 300, 'mybot.pipelines.validate.ExportPipeline': 800, } ","date":"2019-03-20","objectID":"/scrapy/:4:0","tags":["Python","scrapy","爬虫"],"title":"[Python]Scrapy Scan","uri":"/scrapy/"},{"categories":["Python"],"content":"● Feeds Export 序列化你的item结果有很多种方式： FEED_EXPORTERS_BASE = { 'json': 'scrapy.contrib.exporter.JsonItemExporter', 'jsonlines': 'scrapy.contrib.exporter.JsonLinesItemExporter', 'csv': 'scrapy.contrib.exporter.CsvItemExporter', 'xml': 'scrapy.contrib.exporter.XmlItemExporter', 'marshal': 'scrapy.contrib.exporter.MarshalItemExporter', } 高级特性 ","date":"2019-03-20","objectID":"/scrapy/:5:0","tags":["Python","scrapy","爬虫"],"title":"[Python]Scrapy Scan","uri":"/scrapy/"},{"categories":["Python"],"content":"下载器中间件：修改req和rsp的钩子 官方文档：下载器中间件 最佳实践 下面是些处理这些站点的建议(tips): 使用user agent池，轮流选择之一来作为user agent。池中包含常见的浏览器的user agent(google一下一大堆) 禁止cookies(参考 COOKIES_ENABLED)，有些站点会使用cookies来发现爬虫的轨迹。 设置下载延迟(2或更高)。参考 DOWNLOAD_DELAY 设置。 如果可行，使用 Google cache 来爬取数据，而不是直接访问站点。 使用IP池。例如免费的 Tor项目 或付费服务(ProxyMesh)。 使用高度分布式的下载器(downloader)来绕过禁止(ban)，您就只需要专注分析处理页面。这样的例子有: Crawlera ","date":"2019-03-20","objectID":"/scrapy/:6:0","tags":["Python","scrapy","爬虫"],"title":"[Python]Scrapy Scan","uri":"/scrapy/"},{"categories":["算法"],"content":"在谈红黑树之前，可以先看看红黑树的根源，234树...","date":"2019-03-20","objectID":"/rbtree/","tags":["红黑树","数据结构","算法"],"title":"[数据结构]深入理解红黑树","uri":"/rbtree/"},{"categories":["算法"],"content":"平衡树 在谈红黑树之前，可以先看看红黑树的根源，234树。234树也是一种平衡树。 平衡树的原型都是二叉查找树，即左面的节点比他小，右边的节点比他大。但是在二叉查找树的过程中，很有可能变成树朝一边严重倾斜的情况。为了解决这个问题，设计了如下变种： avl：严格控制树的平衡，左右树的高度差不大于1。所以查找性能是logn。在插入和删除操作时，最差的情况是每一级的父节点都会旋转。时间复杂度都是O(logn)。 红黑树：红黑树的左右子树最高差时，一个子树是另一个子树的一倍。最坏查找性能是2logn。在插入操作时，最差旋转2次，删除操作最差旋转三次，可以减少avl的平衡操作，但是依然是O(logn)的复杂度（在找到节点的插入位置就要花费logn时间）。 splay：插入删除复杂度也是O(logn)，可以用数组实现，不需要额外维护树的节点信息。但在最坏情况下他会退化成一条链。而且只读操作也会影响树的结构，在多线程环境访问下比较复杂。 替罪羊树：在查找树不平衡的时候，找到最高的一个节点（满足左右子树不差0.7倍的平衡点），重构整个子树 查找问题还可以用哈希表解决。哈希表是无序的，而且会耗费大块的内存。 一些常见的面试题：常见面试题-cnblog 各种树的性能 ","date":"2019-03-20","objectID":"/rbtree/:1:0","tags":["红黑树","数据结构","算法"],"title":"[数据结构]深入理解红黑树","uri":"/rbtree/"},{"categories":["算法"],"content":"2-3-4树 2-3-4树-CSDN 234树是红黑树的等价变种。先来看看2-3树，这种树有两种节点，2节点和3节点。 2-节点：普通节点，有两个子连接 3-节点：有两个值A、B，三个连接（分别指向小于A，介于AB之间，大于B的儿子） 2-3树可以保证插入的时候所有叶子到根节点的距离是相同的。我们看看他如何插入： (1) 如果值插入2节点，把他扩充成一个3节点。 (2) 如果插入插入3节点 A. 整个树只有一个3节点：把他扩展成4-节点，然后分解4-节点，然后将分解后的新树的父节点融入到2-节点的父节点中去。 B. 3-节点有一个2-节点的父节点，此时的操作是，3-节点扩充为4-节点，然后分解4-节点，然后将分解后的新树的父节点融入到2-节点的父节点中去。 C. 3-节点有一个3-节点的父节点，此时操作是：3-节点扩充为4-节点，然后分解4-节点，新树父节点向上融合，上面的3-节点继续扩充，融合，分解，新树继续向上融合，直到父节点为2-节点为止，如果向上到根节点都是3-节点，将根节点扩充为4-节点，然后分解为新树，至此，整个树增加一层，仍然保持平衡。 23树的流程比较复杂，而且涉及不同节点的转换，所以出现了红黑树来简化操作。我们把3节点的两个元素红色连接连起来。这时候红色连接出去的那个节点就成了红黑树的红节点，其余的都是黑节点。如果你将红黑树中所有的红色链接放平，那么它所有的叶子节点到根节点的距离都是相同的，所以是一个完美的黑色平衡。 所以，红黑树的另一种定义是满足下列条件的二叉查找树： ⑴ 红链接均为左链接。 ⑵ 没有任何一个结点同时和两条红链接相连。(这样会出现4-节点) ⑶ 该树是完美黑色平衡的，即任意空链接到根结点的路径上的黑链接数量相同。 ","date":"2019-03-20","objectID":"/rbtree/:2:0","tags":["红黑树","数据结构","算法"],"title":"[数据结构]深入理解红黑树","uri":"/rbtree/"},{"categories":["算法"],"content":"红黑树 github红黑树(有比较好的图解) cnblog红黑树流程详解 红黑树的五条性质： 1）每个结点要么是红的，要么是黑的。 2）根结点是黑的。 3）每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。 4）如果一个结点是红的，那么它的俩个儿子都是黑的。 5）对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。 如果我们插入一个节点，并把他染红，则树的1235项原则都不会被破坏。如何保证原则4呢？调整的原则是把红色问题向上修正到根节点，最后把根节点染黑，来达到平衡。 我们先把插入的节点染红，然后进行修正操作： 插入修复情况1：当前结点的父结点是红色且叔叔结点是红色。 将当前结点的父结点和叔叔结点涂黑，祖父结点涂红。在以祖父节点为新的当前结点再做一遍。 A. 为了解决本节点和父节点都是红色，把父节点染黑。 B. 但是父节点的在子树多了个黑色，所以要把叔叔也染黑来平衡。 C. 此时爷爷节点的子树也多了个黑色，所以把他染红。 D. 爷爷节点被染红了上面的节点曾爷爷有可能是红的，在做一次。 插入修复情况2：当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的右子 对策：当前结点的父结点做为新的当前结点，以新当前结点为支点左旋。左旋后，本节点上移，把问题向上修正。可以转化到情况3 插入修复情况3：当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的左子 解法：父结点变为黑色，祖父结点变为红色，在祖父结点为支点右旋 A. 为了解决本节点和父节点都为红，把父节点染黑 B. 为了解决父节点在的子树多了一个黑色，把叔叔染红并右旋解决 ","date":"2019-03-20","objectID":"/rbtree/:3:0","tags":["红黑树","数据结构","算法"],"title":"[数据结构]深入理解红黑树","uri":"/rbtree/"},{"categories":["机器学习"],"content":"deeplearning.ai 课程1 Week1~Week2 课程笔记和推导、编码整理","date":"2018-08-14","objectID":"/c1w1-c1w2/","tags":["深度学习","deeplearning.ai"],"title":"[深度学习]C1W1~C1W2","uri":"/c1w1-c1w2/"},{"categories":["机器学习"],"content":"C1W1: 什么是deep learning ","date":"2018-08-14","objectID":"/c1w1-c1w2/:1:0","tags":["深度学习","deeplearning.ai"],"title":"[深度学习]C1W1~C1W2","uri":"/c1w1-c1w2/"},{"categories":["机器学习"],"content":"单一神经元 deeplearning是模拟大脑的一种机器学习算法。以房价预测为例： 上图把房子面积作为输入X，房价作为输出Y，通过拟合得到了一个一次函数 $$ Y=aX+b $$ 这个函数的负值均视为0，即使用了ReLU函数作为神经元的激活函数做了处理。 $$ f(x) = \\max(aX+b, 0) $$ Note: ReLU函数：f(x)=\\max(0, x)，近年来使用ReLU函数代替sigmoid函数为计算速度做了巨大的提升。 看看更多特征的情况： ","date":"2018-08-14","objectID":"/c1w1-c1w2/:1:1","tags":["深度学习","deeplearning.ai"],"title":"[深度学习]C1W1~C1W2","uri":"/c1w1-c1w2/"},{"categories":["机器学习"],"content":"飞速发展 上图中可以看到传统算法和神经网络的效果的一个对比，在数据多的情况下神经网络有明显的优势。近年来以下的一些原因导致deep learning飞速发展成为主流 计算速度飞速提升，使得训练较大的神经网络成为可能 数据变多（labeled data 变多） ","date":"2018-08-14","objectID":"/c1w1-c1w2/:1:2","tags":["深度学习","deeplearning.ai"],"title":"[深度学习]C1W1~C1W2","uri":"/c1w1-c1w2/"},{"categories":["机器学习"],"content":"生命周期 一个典型的深度学习的流程，即是一个Idea-Code-Train 的循环 ","date":"2018-08-14","objectID":"/c1w1-c1w2/:1:3","tags":["深度学习","deeplearning.ai"],"title":"[深度学习]C1W1~C1W2","uri":"/c1w1-c1w2/"},{"categories":["机器学习"],"content":"C1W2: 基本的神经网络 ","date":"2018-08-14","objectID":"/c1w1-c1w2/:2:0","tags":["深度学习","deeplearning.ai"],"title":"[深度学习]C1W1~C1W2","uri":"/c1w1-c1w2/"},{"categories":["机器学习"],"content":"问题描述 这里从一个简单的问题开始说起：识别一个64x64的图像是否为猫： 每个像素有RGB三个值组成，64*64个像素就是12228个值。所以X可以表示为一个12228维的向量。Y则是0或1（是或不是猫咪）。 这里需要很多(X, Y)组成的labeled data数据用来学习。每个样本用如下的数学方式表示： $$ X\\in R^{n_x}, Y\\in{0,1} \\qquad 其中n_x为每个图片的维度(12288) $$ 训练集可以用很多样本表示： $$ \\textrm{m training examples: } \\{(X^{(1)}, Y^{(1)}), (X^{(2)}, Y^{(2)}), … ,(X^{(3)}, Y^{(3)})\\} $$ 其中每个X都有n_x列，所以整个样本集可以表示为 $$ X\\in R^{n_x\\times m},Y \\in R^{1 \\times m} $$ ","date":"2018-08-14","objectID":"/c1w1-c1w2/:2:1","tags":["深度学习","deeplearning.ai"],"title":"[深度学习]C1W1~C1W2","uri":"/c1w1-c1w2/"},{"categories":["机器学习"],"content":"逻辑回归 Sigmoid函数 在开始正题之前，先看一个函数： $$ \\sigma(z) = \\frac{1}{1+e^{-z}} $$ 如果Z为正无穷，这个函数将会是 1/(1+0) = 1 如果Z为负无穷，这个函数将会是1/bignum = 0 这个S型函数非常适用于取值0~1之间的x的映射。 同时，这个函数的导数也十分有趣： $$ \\begin{aligned} f’(z) \u0026= (\\frac{1}{1+e^{-z}})’= \\frac{e^{-z}}{(1+e^{-z})^{2}} = \\frac{1+e^{-z}-1}{(1+e^{-z})^{2}} \\ \u0026= \\frac{1}{(1+e^{-z})}(1-\\frac{1}{(1+e^{-z})}) \\ \u0026= f(z)(1-f(z)) \\ \\end{aligned} $$ 逻辑回归 判断单一图片是否为猫的图片，可以表示为给定图片X，预估y为1的概率： $$ \\textrm{Given } x , \\textrm{ want } \\hat{y}=P(y=1|x) \\qquad let \\ x \\in R^{n_x}, 0\\leq\\hat{y}\\leq1 $$ 设参数 $$ w \\in R^{n_x},b \\in R $$ 输出参数和X的乘积，然后用sigmoid做区间化： $$ \\hat{y} = \\sigma(w^Tx+b) $$ 现在的问题就是从样本中估计出参数w和b的值。 Cost Function 我们对样本做训练的目标，就是使得w和b对每一个样本的估计都损失最小。用数学的语言就是： $$ \\hat{y} = \\sigma(w^Tx+b),\\textrm{ where }\\sigma(z) = \\frac{1}{1+e^{-z}} $$ $$ \\textrm{ Given } \\{(X^{(1)}, Y^{(1)}), … ,(X^{(3)}, Y^{(3)})\\}, \\textrm{ want } \\hat{y} \\approx y $$ $\\hat{y}$和$y$之间的差距，就是我们的损失。我们当然可以用平方损失函数 $$ L(\\hat{y}, y) = \\frac{1}{2}(\\hat{y}-y)^2 $$ 不过这里却有更好的函数： $$ L(\\hat{y}, y) = -(y\\log{\\hat{y}} + (1-y)\\log{(1-\\hat{y})}) $$ 当 y = 1时，$L(\\hat{y}, y) = -\\log{\\hat{y}}$。如果要L小，就要$\\hat{y}$尽可能大 当 y = 0 时，$L(\\hat{y}, y)= -\\log{(1-\\hat{y})}$。如果要L小，就要$\\hat{y}$尽可能小 这两条性质证明了这是个很好的损失函数。总的损失函数可以写成： $$ J(w,b) = \\frac{1}{m} \\sum^{m}_{i=1} L(\\hat{y^{(i)}}, y^{(i)}) = -\\frac{1}{m} \\sum^{m}_{i=1}(y^{(i)}\\log{\\hat{y^{(i)}}} + (1-y^{(i)})\\log{(1-\\hat{y^{(i)}})}) $$ 梯度下降 我们要找到上述函数J(w,b)的最小值。J(w,b)可能是下面的简化曲线： 假设我们先随机初始化w和b，在曲线上左上方的某一点。要让J的值变小，可以增加w的值。如果点在曲线的右上方，我们就需要减少w的值。事实上增加或减少w的值是有J对w的导数决定的。我们可以每次运行： $$ w := w - \\alpha \\frac{dJ(w,b)}{dw} \\qquad \\alpha为学习速率，后面的是偏导数 $$ 还有参数b： $$ b := b - \\alpha \\frac{dJ(w,b)}{db} \\qquad \\alpha为学习速率，后面的是偏导数 $$ 学习速率是用来决定每次参数迈的步子的大小。事实上J不会是一个凸函数，所以他拥有多个最小值，学习速率可以帮助参数不收敛到局部最小值。 计算图 计算图可以让我们清晰地通过反向传播计算每个参数的导数。如下是一个代价函数求导的例子： 反向传播是一个从后向前的计算导数的过程，可以避免重复的计算。 先求根据上面的损失函数求出da： $$ \\frac{dL(a,y)}{da}=\\frac{dL}{da} = -\\frac{y}{a}+\\frac{1-y}{1-a} $$ 然后求出dz： $$ \\frac{dL}{dz}=\\frac{dL}{da} \\cdot \\frac{da}{dz} = (-\\frac{y}{a}+\\frac{1-y}{1-a})a(1-a)=(a-1)y+(1-y)a=a-y $$ 参数的导数更加容易： $$ \\frac{dL}{dw_1}=\\frac{dL}{da} \\cdot \\frac{da}{dz} \\cdot \\frac{dz}{dw_1}=\\frac{dL}{dz} \\cdot \\frac{dz}{dw_1}=\\frac{dL}{dz} \\cdot x_1 $$ 链式求导可以很方便地运用在程序中，只要先记下前几步求导的值。同理， $$ dw_2=dz \\cdot x_2 , \\quad db=dz $$ Vectorization 现在已经做完了所有求得参数的准备工作。一个标准的过程可以被表示为： J = 0; dw1 = 0; dw2 = 0; db = 0 # 遍历样本 for i = 1 to m: z(i) = w * x(i) + b a(i) = theta(z(i)) J += -(y(i)log(a(i)) + (1-y(i))log(1-a(i))) dz(i) = a(i) - y(i) dw1 += x1(i)*dz(i) dw2 += x2(i)*dz(i) ... db += dz(i) J /= m dw1 /= m; dw2 /= m; db /= m 在实际的计算中，分步去算参数的值非常不利于GPU进行加速。矩阵化运算可以提速400倍以上。下面是本次PA，也就是整个模型的全过程： train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset() train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T def sigmoid(z): s = 1/(1+np.exp(-z)) return s def init(dim): w = np.zeros(dim).reshape(dim,1) b = 0 return w,b def propagate(w, b, X, Y): m = X.shape[1] A = sigmoid(np.dot(w.T, X)+b) # compute activation cost = -1/m*np.sum(Y*np.log(A) + (1-Y)*np.log(1-A)) # compute cost dw = 1/m*np.dot(X, (A-Y).T) db = 1/m*np.sum(A-Y) cost = np.squeeze(cost) grads = {\"dw\": dw, \"db\": db} return grads, cost def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False): costs = [] for i in range(num_iterations): grads, cost = propagate(w, b, X, Y) dw = grads[\"dw\"] db = grads[\"db\"] w = w - learning_rate*dw b = b - learning_rate*db if i % 100 == 0: costs.append(cost) if print_cost and i % 100 == 0: print (\"Cost after iteration %i: %f\" %(i, cost)) params = {\"w\": w, \"b\": b} grads = {\"dw\": dw, \"db\": db} return params, grads, costs def predict(w, b, X): m = X.shape[1] Y_prediction = np.zeros((1,m)) w = w.reshape(X.shape[0], 1) A = sigmoid(np.dot(w.T, X) + b) for i in range(A.shape[1]): Y_prediction[0][i] = 1 if A[0][i] \u003e 0.5 else 0 return Y_prediction def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False): # initialize parame","date":"2018-08-14","objectID":"/c1w1-c1w2/:2:2","tags":["深度学习","deeplearning.ai"],"title":"[深度学习]C1W1~C1W2","uri":"/c1w1-c1w2/"},{"categories":["C++"],"content":"本文从介绍一个coredump分析开始，全面介绍了GDB的各种指令。","date":"2017-12-17","objectID":"/gdb/","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"命令行参数 gdb有下面几种运行方式： // 1. 通过coredump文件，或者存在的进程id分析，不会拉起新进程 gdb [options] [executable-file [core-file or process-id]] // 2. 带参数运行程序 gdb [options] --args executable-file [inferior-arguments ...] // 3. redhat等含有用于调试python的工具 // gdb [options] [--python|-P] script-file [script-arguments ...] 几个值得注意的参数： // 和上面的类似，使用参数指定的 --args Arguments after executable-file are passed to inferior --core=COREFILE Analyze the core dump COREFILE. --pid=PID Attach to running process PID. --exec=EXECFILE Use EXECFILE as the executable. // 远程调试 -b BAUDRATE Set serial port baud rate used for remote debugging. -l TIMEOUT Set timeout in seconds for remote debugging. // 运行某个文件中的gdb指令 --command=FILE, -x Execute GDB commands from FILE. // 运行某gdb指令，如gdb a.out -ex r开启文件并立即运行 --eval-command=COMMAND, -ex Execute a single GDB command. --directory=DIR Search for source files in DIR. --se=FILE Use FILE as symbol file and executable file. ","date":"2017-12-17","objectID":"/gdb/:1:0","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"简单的例子：coredump分析 gdb的一大用处是通过coredump文件分析程序哪里发生了错误。首先要打开coredump生成开关： // 可以先运行 ulimit -a 查看所有限制，或者运行 ulimit -c 查看当前coredump设置 // 设置成无限可能会生成数GB的coredump文件 // 这条命令重启后无效 ulimit -c unlimited coredump文件会默认生成在程序相同目录下。如果没有对应文件，可以查看/etc/sysctl.conf: // 生成目录格式，%e 程序名 %p 进程id %s 信号 %t 时间 %e 命令名 kernel.core_pattern =/data/coredump/core%e%p // 1表示使用procid命名，0表示不使用 kernel.core_uses_pid= 0 我们先编写一个简单的c程序main.c，它试图从非法地址读取数据： int main(){ int a = *((int *)NULL); return 0; } 编译，一定要加上-g选项： gcc -o test_worker main.c -g 运行，果然dump： ./test_worker Segmentation fault (core dumped) 然后使用第一节里的第一种方式启动， 携带coredump文件： gdb ./test_worker core.xxx.xxx 进去后就能看到dump的地方以及原因。使用bt查看coredump时栈顶的信息： Core was generated by `./t'. Program terminated with signal 11, Segmentation fault. #0 0x0000000000400564 in main () at t.c:13 13 int a = *((int *)NULL); Missing separate debuginfos, use: debuginfo-install glibc-2.17-106.el7_2.4.x86_64 (gdb) bt #0 0x0000000000400564 in main () at t.c:13 ","date":"2017-12-17","objectID":"/gdb/:2:0","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"GDB的用法 GDB Online Docs GDB启动时会读取二进制文件的符号表，然后进入调试命令行。这里可以运行各种命令查看程序的符号表、变量、内存值以及控制程序的运行。 ","date":"2017-12-17","objectID":"/gdb/:3:0","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"控制命令 file 加载一个二进制文件，直接进入gdb时可以用这个加载。参数为文件名。 run (或者r) 从头运行程序一直到断点。没有断点会一直运行结束，或者直到遇到异常。可以r \u003c a.in 重定向输入输出。 continue (或者c) 运行程序一直到下一个断点。 next/step (或者n/s) 单步调试，next不会在行内进入函数体，step则会跳入函数体。 参数为跳多行。 until (或者 u) 直接跳出当前循环。（但是还是会被断点卡住）。参数为跳到指定行。 finish 直接运行到函数返回 call 运行某函数，参数为函数和参数，如 call foo(2, \"hello\") 回车键 重复上个指令 ","date":"2017-12-17","objectID":"/gdb/:3:1","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"断点 break n (或者b) 在第n行打断点 b main.c:n 指定文件打断点； b main 指定函数入口处打断点； b main:label 指定函数的标签处打断点 b n if i == 5 满足条件打断点，对循环尤其有效。 info b 查看断点号和信息，或者 i b delete no (或者d) 删除对应编号的断点； d breakpoints 删除所有断点 clear lineno 删除对应行的断点 disable/enable no 屏蔽/使用对应编号的断点 ","date":"2017-12-17","objectID":"/gdb/:3:2","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"查看代码和变量 list (或者l) 列出10行源文件。每次从上次结束的地方开始列。 list lineno 列出某行的前后源码；l main 列出某函数的源码 print exp (或者p) 打印任意变量、表达式、函数、字符串、数组的值 display exp 每次单步完打印该表达式 watch exp 如果该表达式值改变了，打印并停止程序 whatis 查询变量，函数的类型 info (或者i) 查询信息 i locals 所有变量的值 i args 所有参数的值 i function 函数信息 i frame 栈信息 i program 程序信息 i threads 线程信息 ","date":"2017-12-17","objectID":"/gdb/:3:3","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"堆栈 bt 查看栈信息； bt n 栈顶n层；bt -n 栈底n层 (gdb) bt #0 foot () at t.c:7 #1 0x0000000000400525 in main () at t.c:15 frame (或者f)查看帧信息。上面一个#号（一层）是一帧。 frame n 查看第n帧 ；up n 上面n帧； down n 下面n帧；frame addr 查看某地址的帧 info frame n/addr 帧详细信息 ip是下条命令的地址（pc），bp是栈底的地址，sp是栈顶的地址。 64位机的帧信息： (gdb) i f 0 // 帧地址 Stack frame at 0x7fffffffe560: // rip：帧PC 帧函数名 saved rip：caller帧PC rip = 0x4004fd in foot (t.c:7); saved rip 0x400525 // caller帧地址 called by frame at 0x7fffffffe570 source language c. // 帧参数地址 Arglist at 0x7fffffffe550, args: // 帧局部变量地址，caller的栈顶地址 Locals at 0x7fffffffe550, Previous frame sp is 0x7fffffffe560 // 帧寄存器列表 Saved registers: rbp at 0x7fffffffe550, rip at 0x7fffffffe558 32位机的帧信息： (gdb) i f Stack level 0, frame at 0xbffff630: // eip：帧PC 帧函数名 saved eip：caller帧PC eip = 0x80483e4 in main (a.c:8); saved eip = 0xb7e31637 source language c. // 帧参数地址 Arglist at 0xbffff628, args: // 帧局部变量地址，caller的栈顶地址 Locals at 0xbffff628, Previous frame sp is 0xbffff630 // 帧寄存器列表 Saved registers: ebp at 0xbffff628, eip at 0xbffff62c ​ ","date":"2017-12-17","objectID":"/gdb/:3:4","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"内存 100 GDB Tips gdb中使用x命令来打印内存的值，格式为x/nfu addr。 含义为以f格式打印从addr开始的n个长度单元为u的内存值。参数具体含义如下： a）n：输出单元的个数。 b）f：是输出格式。比如x是以16进制形式输出，o是以8进制形式输出,等等。 c）u：标明一个单元的长度。b是一个bytes，h是两个bytes（halfword），w是四个bytes（word），g是八个bytes（giant word）。 比如对一个字符串arr查看内存：（这个数组越界踩掉了总共10 char的内容，每个char在32位机上是32bit） (gdb) p arr $4 = \"\\000\\001\\002\\003\" // 显示11个byte，十六进制显示 (gdb) x/11xb arr 0x7fffffffe540: 0x00 0x01 0x02 0x03 0x04 0x05 0x06 0x07 0x7fffffffe548: 0x08 0x09 0x40 // 显示3个4-byte，十六进制显示 (gdb) x/3xw arr 0x7fffffffe540: 0x03020100 0x07060504 0x00400908 ","date":"2017-12-17","objectID":"/gdb/:3:5","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"信号 这部分的详细内容在GDB Online Docs-5.4 Signals中。你可以自由地对程序进行发送信号（signal）、捕获信号（catch）或者处理信号（handle）。 ","date":"2017-12-17","objectID":"/gdb/:3:6","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["C++"],"content":"线程 除了上文的查看线程信息之外，还可以查看详细的线程信息，参考GDB Online Docs-4 Threads，或者查看fork的情况，参考GDB Online Docs-5Forks 。 ","date":"2017-12-17","objectID":"/gdb/:3:7","tags":["GDB","C++"],"title":"[Linux]GDB调试技巧","uri":"/gdb/"},{"categories":["后台"],"content":"分布式的基础概念，包括CAP，BASE，和一些基本的原则","date":"2017-11-09","objectID":"/nosql_base/","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["后台"],"content":"CAP Brewer’s CAP Theorem, 2009 CAP理论是分布式系统的基石，他指出了分布式系统的以下特性： Consistency 强一致性(返回的数据时刻一致) Availability 高可用性(服务一直可用，响应时间正常) Tolerance of network Partition 分区容错性(保证有机器宕机服务依然正常) CAP理论表明，一个分布式系统不可能同时满足一致性，可用性和分区容错性这三个需求， 最多只能同时满足两个。证明可以看上面的链接。 所以架构师往往要做出牺牲某一特性的选择： CP：金融行业的数据库，价格昂贵，符合ACID CA：传统关系型数据库，用于小型系统或单机系统 AP：key-value数据库，现代UGC服务基本都是这种架构，用最终一致性来换取高可用和分区容错性。 电商：牺牲少量的可用性和一致性，比较平衡，符合BASE ","date":"2017-11-09","objectID":"/nosql_base/:1:0","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["后台"],"content":"ACID 老生常谈的数据库事务的特性： 原子性(Atomicity) 事务中有失败，立即回滚到执行前。没有失败，全部成功 一致性(Consistency) 事务执行后数据的约束没有被破坏 隔离性(Isolation） 事务之间不交叉进行 持久性(Durability） 事务完成，永久储存 ","date":"2017-11-09","objectID":"/nosql_base/:2:0","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["后台"],"content":"BASE 可伸缩性最佳实践：来自eBay的经验 BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（CAP的Consistency），但应用可以采用适合的方式达到最终一致性，来保证系统的容量和可用性。 ","date":"2017-11-09","objectID":"/nosql_base/:3:0","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["后台"],"content":"Basically Availble （基本可用） 基本可用是指系统只保证核心可用，在访问量突增时采用有损服务的策略，让部分用户使用降级的服务。 什么是基本可用的服务？以秒杀为例： 逻辑有损：秒杀时只执行重要逻辑，加载资源可以先使用预加载的或者小图等 业务有损：秒杀需要会员、抢秒杀资格 流程有损：比如秒杀时前段丢掉大部分请求，从后端少量请求中选取中奖的请求处理 ","date":"2017-11-09","objectID":"/nosql_base/:3:1","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["后台"],"content":"Soft-state （软状态/柔性事务） “Soft state” 可以理解为\"无连接\"的, 而 “Hard state” 是\"面向连接\"的。换句话说，软状态的数据库可能存在很多中间状态，不同节点到达最终统一的状态前会有延迟（如异步复制）。 ","date":"2017-11-09","objectID":"/nosql_base/:3:2","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["后台"],"content":"Eventual Consistency （最终一致性） 并非时刻保持一致，所有复制节点在某段时间后保持一致。 最终一致性是弱一致性的一种特例： Step 1. A首先write了一个值到存储系统 Step 2. 存储系统保证在A,B,C后续读取之前没有其它写操作更新同样的值 Step 3. 最终所有的读取操作都会读取到最A写入的最新值 从A写入到读取操作读取成功有一定的时间，即不一致性窗口。如果没有失败发生的话，“不一致性窗口”的大小依赖于以下的几个因素：交互延迟，系统的负载，以及备机slave的个数。最终一致性方面最出名的系统可以说是DNS系统，当更新一个域名的IP以后，根据配置策略以及缓存控制策略的不同，最终所有的客户都会看到最新的值。 在下一篇文章的中，会表明只要集群$V_r + V_w \\leq N$，即此时读取和写入操作是不重叠的， 就能保证最终一致性。这个时候不一致性的窗口依赖于存储系统的异步实现方式，不一致性的窗口大小就等于从更新开始到所有的节点都异步更新完成之间的时间。 ​ ","date":"2017-11-09","objectID":"/nosql_base/:3:3","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["后台"],"content":"Sharding 分片 当单库单表中的数据量特别大，查询就会非常慢。这个时候就要切分数据库存放在不同的Server上： 水平切分：行切分。比如按id的范围分表，或者hash分表 垂直切分：列切分。把一张表（库）中关系紧密的列（表）单独放入别的表（Server）中 ","date":"2017-11-09","objectID":"/nosql_base/:4:0","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["后台"],"content":"I/O五分钟法则 The Five-minute Rule, 2008 在一个内存页中维护一个内存页(64KB)的成本相当于在磁盘中维护五分钟的成本。 ","date":"2017-11-09","objectID":"/nosql_base/:5:0","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["后台"],"content":"不要删除数据 在数据库中删除数据会破坏数据库的完整性。比如删除一个商品会导致关联的订单也要删除，引发连锁反应。打个下架标记即可，不要删除数据。 ","date":"2017-11-09","objectID":"/nosql_base/:6:0","tags":["NOSQL","CAP","分布式"],"title":"[后台]分布式基础概念","uri":"/nosql_base/"},{"categories":["c++"],"content":"sizeof是什么？怎么用？返回了什么？怎么实现？本文详细回答了这些问题。","date":"2017-08-16","objectID":"/size_of_things/","tags":["c++","sizeof"],"title":"[C++]sizeof那些事儿","uri":"/size_of_things/"},{"categories":["c++"],"content":"sizeof 是什么 首先明确一点，sizeof是运算符，不是函数。运算符是一个对于编译器来说的概念，是由编译器处理的，在程序编译好之后所有的sizeof都已经被替换为实际的值。类似的还有decltype。所以像 sizeof(++i); 这类的语句是不会改变i的值的。在C99之后，sizeof增加了一些运行时特性，可以算出可变数组的大小，像这样： int num; scanf(\"%d\", \u0026num); //input 4 int arr[num]; sizeof(arr); //output 16 ","date":"2017-08-16","objectID":"/size_of_things/:1:0","tags":["c++","sizeof"],"title":"[C++]sizeof那些事儿","uri":"/size_of_things/"},{"categories":["c++"],"content":"sizeof 怎么用 sizeof 支持下面的语法： sizeof(type) (1) 以字节数返回type类型对象表示的大小 sizeof expression (2) 以字节数返回expression的类型对象表示的大小 其中，sizeof(char)、 sizeof(signed char)以及sizeof(unsigned char)始终返回1。 sizeof不能用于函数类型、不完整类型（含void）或位域左值。在一些编译器里，sizeof(void)会返回0，但这是没有定义的。 ","date":"2017-08-16","objectID":"/size_of_things/:2:0","tags":["c++","sizeof"],"title":"[C++]sizeof那些事儿","uri":"/size_of_things/"},{"categories":["c++"],"content":"普通的sizeof 几个上面用法的例子： int main(void) { // type argument: printf(\"sizeof(float) = %u\\n\", sizeof(float)); //4 printf(\"sizeof(void(*)(void)) = %u\\n\", sizeof(void(*)(void))); //4 printf(\"sizeof(char[10]) = %u\\n\", sizeof(char[10])); //10 // expression argument: printf(\"sizeof 'a' = %u\\n\", sizeof 'a'); // 'a'的类型是int, 4 // printf(\"sizeof main = %zu\\n\", sizeof main); // 错误：函数类型 printf(\"sizeof \u0026main = %u\\n\", sizeof main()); //类型为返回值int, 4 printf(\"sizeof \\\"hello\\\" = %u\\n\", sizeof \"hello\"); // 类型为char[6], 6 printf(\"sizeof(\\\"12345\\\" + 1) = %u\\n\", sizeof(\"12345\" + 1)); // 类型为指针, 4 } 需要注意的是，在函数传参等数组退化为指针的时候sizeof返回的当然是指针大小，切忌用它来计算数组大小。 ","date":"2017-08-16","objectID":"/size_of_things/:3:0","tags":["c++","sizeof"],"title":"[C++]sizeof那些事儿","uri":"/size_of_things/"},{"categories":["c++"],"content":"sizeof 和字节对齐 在sizeof用于非基本类型时，编译器会有字节对齐这样一个行为。它可以有效地用空间换时间，快速找到数据的地址。 字节对齐指的是每个变量的首地址和自身对齐值对齐，所以和变量顺序也有一定的关系。 字节对齐满足三个准则： 结构体变量的首地址：能够被其最宽基本类型成员的大小所整除； 结构体每个成员相对于结构体首地址的偏移量：都是该成员大小的整数倍，如有需要编译器会在成员之间加上填充字节。 结构体末尾填充：结构体的总大小为结构体最宽基本类型成员大小的整数倍，如有需要编译器会在最末一个成员之后加上填充字节。 基本类型的宽度：char=1，short=2，int=4，double=8，指针=4 例如下面一个例子： typedef struct{ int id; //0-7 由于下个元素要和4对齐，补齐了2字节 double weight; //8-15 float height; //16-23 由于结构体大小和8对齐，补齐了4字节 }Body_Info; typedef struct{ char name[2]; //0-3 由于下个元素要和4对齐，补齐了2字节 int id; //4-7 很齐 double score; //8-15 很齐　short grade; //16-23 由于下个元素要和8（BB中最长类型）对齐，补齐了6字节　Body_Info b; //24-47 很齐 }Student_Info; // 删除掉Student_Info的id或者name，大小都是不变的 // 删除掉Student_Info的grade或者把grade移动到name后，大小会成为40字节 ","date":"2017-08-16","objectID":"/size_of_things/:4:0","tags":["c++","sizeof"],"title":"[C++]sizeof那些事儿","uri":"/size_of_things/"},{"categories":["c++"],"content":"sizeof的实现 因为是个编译器行为，就没有函数代码了，也不在标准库里。在clang的编译器代码中可以看到一些对sizeof的处理，可以把玩一下： TypeInfo ASTContext::getTypeInfoImpl(const Type *T) const { uint64_t Width = 0; unsigned Align = 8; bool AlignIsRequired = false; switch (T-\u003egetTypeClass()){ case Type::Vector: { const VectorType *VT = cast\u003cVectorType\u003e(T); TypeInfo EltInfo = getTypeInfo(VT-\u003egetElementType()); Width = EltInfo.Width * VT-\u003egetNumElements(); .... case BuiltinType::UInt: case BuiltinType::Int: Width = Target-\u003egetIntWidth(); Align = Target-\u003egetIntAlign(); break; case BuiltinType::ULong: case BuiltinType::Long: Width = Target-\u003egetLongWidth(); Align = Target-\u003egetLongAlign(); break; ... case Type::Pointer: unsigned AS = getTargetAddressSpace(cast\u003cPointerType\u003e(T)-\u003egetPointeeType()); Width = Target-\u003egetPointerWidth(AS); Align = Target-\u003egetPointerAlign(AS); break; ... } 编译结束后，sizeof就会根据Width和Align被替换为常量。 ","date":"2017-08-16","objectID":"/size_of_things/:5:0","tags":["c++","sizeof"],"title":"[C++]sizeof那些事儿","uri":"/size_of_things/"},{"categories":["C++"],"content":"一个100行左右的简单线程池。用到了std::mutex和std::thread等新特性。 ","date":"2017-04-07","objectID":"/cpp_threadpool/:0:0","tags":["c++"," c++11"],"title":"[C++]C++ 100行实现线程池","uri":"/cpp_threadpool/"},{"categories":["C++"],"content":"线程池模型 首先把每个函数抽象为一个任务(Task)，任务的过程就是调用这个Task的run函数。 然后把线程池中的线程封装为一个线程类（Thread），一直等待调度器分配任务（空闲状态），如果有任务分配立即进入忙状态。等任务执行结束再次变为空闲状态。 最后是一个调度器类（TreadPool），包含任务队列（随时添加新任务），和一个包含了Thread的vector（线程池中的线程）。如果任务队列非空，调度器每次从中取出一个任务，然后轮询线程池，搜寻空闲线程并把这个任务交给线程。 模型如下图所示： ","date":"2017-04-07","objectID":"/cpp_threadpool/:1:0","tags":["c++"," c++11"],"title":"[C++]C++ 100行实现线程池","uri":"/cpp_threadpool/"},{"categories":["C++"],"content":"代码实现 下面的代码实现了上述模型。其中Task类通过睡眠一定的秒数模拟任务，可以看到T1先执行完毕（1秒完毕），T2和T3在之后同时完毕，说明调度非常成功。 //linux, g++ -std=c++14 -o t *.cpp -pthread #include \u003cqueue\u003e #include \u003ciostream\u003e #include \u003cmutex\u003e #include \u003cthread\u003e #include \u003cvector\u003e #include \u003cunistd.h\u003e class Task{ private: int no; public: Task(int n){ no = n; } //可以继承这个类重写该方法执行任务 virtual void run(){ sleep(no); //构造时决定执行几秒，模拟线程运行 std::cout \u003c\u003c no \u003c\u003c \"T\\n\"; } }; class Thread{ private: std::thread _thread; bool _isfree; Task *_task; std::mutex _locker; public: //构造 Thread() : _isfree(true), _task(nullptr){ _thread = std::thread(\u0026Thread::run, this); _thread.detach(); //放到后台， join是等待线程结束 } //是否空闲 bool isfree(){ return _isfree; } //添加任务 void add_task(Task *task){ if(_isfree){ _locker.lock(); _task = task; _isfree = false; _locker.unlock(); } } //如果有任务则执行任务，否则自旋 void run(){ while(true){ if(_task){ _locker.lock(); _isfree = false; _task-\u003erun(); _isfree = true; _task = nullptr; _locker.unlock(); } } } }; class ThreadPool{ private: std::queue\u003cTask *\u003e task_queue; std::vector\u003cThread *\u003e _pool; std::mutex _locker; public: //构造线程并后台执行，默认数量为10 ThreadPool(int n = 10){ while(n--){ Thread *t = new Thread(); _pool.push_back(t); } std::thread main_thread(\u0026ThreadPool::run, this); main_thread.detach(); } //释放线程池 ~ThreadPool(){ for(int i = 0;i \u003c _pool.size(); ++i){ delete _pool[i]; } } //添加任务 void add_task(Task *task){ _locker.lock(); task_queue.push(task); _locker.unlock(); } //轮询 void run(){ while(true){ _locker.lock(); if(task_queue.empty()){ _locker.unlock(); continue; } // 寻找空闲线程执行任务 for(int i = 0; i \u003c _pool.size(); ++i){ if(_pool[i]-\u003eisfree()){ _pool[i]-\u003eadd_task(task_queue.front()); task_queue.pop(); break; } } _locker.unlock(); } } }; int main(){ ThreadPool tp(2); Task t1(1); Task t2(3); Task t3(2); tp.add_task(\u0026t1); tp.add_task(\u0026t2); tp.add_task(\u0026t3); sleep(4); //等待调度器结束，不然会崩溃 return 0; } ","date":"2017-04-07","objectID":"/cpp_threadpool/:2:0","tags":["c++"," c++11"],"title":"[C++]C++ 100行实现线程池","uri":"/cpp_threadpool/"},{"categories":["C++"],"content":"各种锁的基本概念以及在C++里的使用，还有C的一个生产消费模型。 ","date":"2017-04-03","objectID":"/cpp_multithreading/:0:0","tags":["c++"," c++11"," 操作系统"],"title":"[C++]C++多线程基础","uri":"/cpp_multithreading/"},{"categories":["C++"],"content":"操作系统的知识 概念 临界区：访问和操作共享数据的代码段 避免死锁：嵌套加锁时按顺序加锁, 防止发生饥饿 原子操作：atomic_t 自旋锁 自旋锁：请求该锁的线程在等待时自旋（特别耗费处理器时间），所以只能轻量级加锁（一般锁的时间小于上下文切换的开销）。 注意：对数据而不是对代码加锁。 读写自旋锁：读时(允许读，不允许写)，写时（不允许读，不允许写）。 注意：不能把读锁升级为写锁，不然会死锁。读写操作要清晰地分开。 信号量 信号量：请求锁的进程在等待时加入等待队列并睡眠。一般用于长时间加锁（唤醒、睡眠、加入队列都是很大的开销）。 通过P/V或者down()/up()操作来控制允许同时进行的线程数。信号量减一就等同与获取一个锁，锁为负数时线程就会进入等待队列。 0/1信号量（互斥信号量）：只允许同时一个线程执行。 计数信号量：允许同时多个线程执行。 读写信号量：互斥信号量的一种。 互斥体 互斥体(mutex): 可以睡眠的强制互斥锁。比信号量更加首选。 mutex和自旋锁的区别： 需求 加锁方法 低开销加锁 优先自旋锁 短期加锁 优先自旋锁 长期加锁 优先mutex 中断上下文加锁 只能自旋锁 持有锁时需要睡眠 只能mutex ","date":"2017-04-03","objectID":"/cpp_multithreading/:0:1","tags":["c++"," c++11"," 操作系统"],"title":"[C++]C++多线程基础","uri":"/cpp_multithreading/"},{"categories":["C++"],"content":"C++11 的线程库 std::thread std::thread用于创建一个执行的线程实例，所以它是一切并发编程的基础，使用时需要包含头文件，它提供了很多基本的线程操作，例如get_id()来获取所创建线程的线程 ID，例如使用join()来加入一个线程等。 std::mutex, std::unique_lock, std::lock_guard 使用std::mutex创建互斥体，std::unique_lock上锁。由于C++保证了所有栈对象在声明周期结束时会被销毁，所以这样的代码是异常安全的。无论发生异常还是正常结束，都会自动调用unlock()。 #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cmutex\u003e std::mutex mtx; void block_area() { std::unique_lock\u003cstd::mutex\u003e lock(mtx); //...临界区 } int main() { std::thread thd1(block_area); thd1.join(); return 0; } ","date":"2017-04-03","objectID":"/cpp_multithreading/:0:2","tags":["c++"," c++11"," 操作系统"],"title":"[C++]C++多线程基础","uri":"/cpp_multithreading/"},{"categories":["C++"],"content":"C加锁示例：生产/消费模型 需求是两个进程维护一片共享内存，里面存十个产品（抽象为长度为10的一个循环队列）。生产者负责生产产品，注意队列满了就不能生产了，这时候进程陷入沉睡；消费者负责消费产品，消费完了队列的产品之后也要陷入沉睡。 Linux端代码如下： consumer.c #define __LIBRARY__ #include \u003csys/stat.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e #include \u003cfcntl.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003csemaphore.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/shm.h\u003e #define Total 500 #define BUFFERSIZE 10 int main(){ int id; int get_pos = 0, i; int *add; sem_t *empty, *full, *mutex; empty = (sem_t *)sem_open(\"empty\", O_CREAT, 0777, 10); //存货\u003e10锁死(锁生产者) full = (sem_t *)sem_open(\"full\", O_CREAT, 0777, 0); //存货\u003c0锁死(锁消费者) mutex = (sem_t *)sem_open(\"mutex\",O_CREAT, 0777, 1); //锁共享内存(都要锁) id = shmget( 555204, BUFFERSIZE*sizeof(int), IPC_CREAT|0666 );//获得共享内存id add = (int*)shmat(id, NULL, 0); //获得对应id的内存的真实地址 for(i = 0; i \u003c Total; i++){ sem_wait(full); //拿取前看产品还够不够，如果够，产品-1，不够就睡眠 sem_wait(mutex); //操作前锁内存 printf(\"%d\\n\", add[get_pos]); fflush(stdout); get_pos = ( get_pos + 1 ) % BUFFERSIZE; sem_post(mutex); //解锁内存 sem_post(empty); //消费完，产品-1 } sem_unlink(\"empty\"); sem_unlink(\"full\"); sem_unlink(\"mutex\"); return 0; } producer.c #define __LIBRARY__ #include \u003csys/stat.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e #include \u003cfcntl.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003csemaphore.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/shm.h\u003e #include \u003csys/sem.h\u003e #define Total 500 #define BUFFERSIZE 10 int main(){ int id; int put_pos = 0, i; int *add; sem_t *empty, *full, *mutex; empty = (sem_t *)sem_open(\"empty\", O_CREAT, 0777, 10); full = (sem_t *)sem_open(\"full\", O_CREAT, 0777, 0); mutex = (sem_t *)sem_open(\"mutex\",O_CREAT, 0777, 1); id = shmget( 555204, BUFFERSIZE*sizeof(int), IPC_CREAT|0666); add = (int*)shmat(id, NULL, 0); for( i = 0 ; i \u003c Total; i++){ sem_wait(empty); //生产前看满了没有 sem_wait(mutex); //锁共享内存 add[put_pos] = i; put_pos = ( put_pos + 1 ) % BUFFERSIZE; sem_post(mutex); //解锁共享内存 sem_post(full); //生产完，产品数量+1 } return 0; } ","date":"2017-04-03","objectID":"/cpp_multithreading/:0:3","tags":["c++"," c++11"," 操作系统"],"title":"[C++]C++多线程基础","uri":"/cpp_multithreading/"},{"categories":["C++"],"content":"本部分介绍了c++11的容器、智能指针和正则。 ","date":"2017-01-30","objectID":"/cpp11_3/:0:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（三）","uri":"/cpp11_3/"},{"categories":["C++"],"content":"std::array 代替原来的c数组，提供了size()，empty()，大小比较以及迭代器。 注意： 声明的第二个模板参数必须是编译期常量 不能隐式转换为指针，调用data()返回c数组地址 std::array\u003cint,4\u003e arr = {1,2,3,4}; // C 风格接口传参 // foo(arr, arr.size()); // 非法, 无法隐式转换 foo(\u0026arr[0], arr.size()); foo(arr.data(), arr.size()); // 使用 `std::sort` std::sort(arr.begin(), arr.end()); ","date":"2017-01-30","objectID":"/cpp11_3/:0:1","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（三）","uri":"/cpp11_3/"},{"categories":["C++"],"content":"std::forward_list 单向实现的列表，提供了O(1)的插入，并且比双向更省空间。 ","date":"2017-01-30","objectID":"/cpp11_3/:0:2","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（三）","uri":"/cpp11_3/"},{"categories":["C++"],"content":"无序容器 传统 C++ 中的有序容器 std::map/std::set，这些元素内部通过红黑树进行实现，插入和搜索的平均复杂度均为 O(log(size))。在插入元素时候，会根据 \u003c 操作符比较元素大小并判断元素是否相同，并选择合适的位置插入到容器中。当对这个容器中的元素进行遍历时，输出结果会按照 \u003c 操作符的顺序来逐个遍历。 而无序容器中的元素是不进行排序的，内部通过 Hash 表实现，插入和搜索元素的平均复杂度为 O(constant)，在不关心容器内部元素顺序时，能够获得显著的性能提升。 C++11 引入了两组无序容器：std::unordered_map, std::unordered_multimap 和std::unordered_set, std::unordered_multiset。 它们的用法和原有的std::map/std::multimap/std::set/set::multiset基本类似。 ","date":"2017-01-30","objectID":"/cpp11_3/:0:3","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（三）","uri":"/cpp11_3/"},{"categories":["C++"],"content":"std::tuple 提供了N元组的数据结构。 该数据结构在cpp14中还不够完善。 ","date":"2017-01-30","objectID":"/cpp11_3/:0:4","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（三）","uri":"/cpp11_3/"},{"categories":["C++"],"content":"智能指针 在传统 C++ 里我们使用 new 和 delete 去『记得』对资源进行释放。而 C++11引入了智能指针的概念，使用了引用计数的想法，让程序员不再需要关心手动释放内存。这些智能指针包括 std::shared_ptr/std::unique_ptr/std::weak_ptr，使用它们需要包含头文件 \u003cmemory\u003e。 std::shared_ptr std::shared_ptr是一种智能指针，它能够记录多少个shared_ptr共同指向一个对象，从而消除显示的调用 delete，当引用计数变为零的时候就会将对象自动删除。 std::make_shared会分配创建传入参数中的对象，并返回这个对象类型的std::shared_ptr指针。 std::shared_ptr\u003cint\u003e pointer = std::make_shared\u003cint\u003e(10); (*pointer)++; std::cout \u003c\u003c *pointer \u003c\u003c std::endl; // 11 // 离开作用域前，shared_ptr 会被析构，从而释放内存 std::shared_ptr可以通过get() 方法来获取原始指针，通过reset()来减少一个引用计数，并通过get_count()来查看一个对象的引用计数。 std::unique_ptr std::unique_ptr是一种独占的智能指针，它禁止其他智能指针与其共享同一个对象，从而保证了代码的安全： std::unique_ptr\u003cint\u003e pointer = std::make_unique\u003cint\u003e(10); // make_unique 从 C++14 引入 std::unique_ptr\u003cint\u003e pointer2 = pointer; // 非法 在c++11中需要手动实现 template\u003ctypename T, typename ...Args\u003e std::unique_ptr\u003cT\u003e make_unique( Args\u0026\u0026 ...args ) { return std::unique_ptr\u003cT\u003e( new T( std::forward\u003cArgs\u003e(args)... ) ); } 既然是独占，换句话说就是不可复制。但是，我们可以利用std::move将其转移给其他的unique_ptr。 std::weak_ptr 当对象相互引用导致内存泄露时，让其中一个使用std::weak_ptr就可以解决了。（弱引用） ","date":"2017-01-30","objectID":"/cpp11_3/:0:5","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（三）","uri":"/cpp11_3/"},{"categories":["C++"],"content":"正则 std::regex创建模式对象。（注意所有转义需要二次转义） std::regex_match(字符串, 模式对象)会返回是否匹配（true \u0026 false） std::string fnames[] = {\"foo.txt\", \"bar.txt\", \"test\", \"a0.txt\", \"AAA.txt\"}; std::regex txt_regex(\"[a-z]+\\\\.txt\"); for (const auto \u0026fname: fnames) std::cout \u003c\u003c fname \u003c\u003c \": \" \u003c\u003c std::regex_match(fname, txt_regex) \u003c\u003c std::endl; 更复杂的用法： std::regex base_regex(\"([a-z]+)\\\\.txt\"); std::smatch base_match; for(const auto \u0026fname: fnames) { if (std::regex_match(fname, base_match, base_regex)) { // sub_match 的第一个元素匹配整个字符串 // sub_match 的第二个元素匹配了第一个括号表达式 if (base_match.size() == 2) { std::string base = base_match[1].str(); std::cout \u003c\u003c \"sub-match[0]: \" \u003c\u003c base_match[0].str() \u003c\u003c std::endl; std::cout \u003c\u003c fname \u003c\u003c \" sub-match[1]: \" \u003c\u003c base \u003c\u003c std::endl; } } } ","date":"2017-01-30","objectID":"/cpp11_3/:0:6","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（三）","uri":"/cpp11_3/"},{"categories":["C++"],"content":"本部分介绍了c++11的Lambda、函数容器和右值引用。 ","date":"2017-01-29","objectID":"/cpp11_2/:0:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（二）","uri":"/cpp11_2/"},{"categories":["C++"],"content":"Lambda 结构： [捕获列表](参数列表) -\u003e 返回类型{ // 函数体 } 比如定义一个加法的lambda： auto add = [](auto x, auto y) { return x+y; }; add(1.0, 2.3); 捕获列表用于传递外部的变量，分为以下几种： [] 空捕获列表 [name1, name2, …] 捕获一系列变量 [=] 值捕获, 捕获的变量为lambda表达式被创建时的值 [\u0026] 引用捕获, 值会发生变化 ","date":"2017-01-29","objectID":"/cpp11_2/:0:1","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（二）","uri":"/cpp11_2/"},{"categories":["C++"],"content":"函数容器 std::function 函数的类型安全的容器。比如下面的std::function\u003cint(int)\u003e func2定义了一个返回值int,参数为(int)的一个函数对象。其中捕获列表是传引用的，所以返回的是调用func2时的1+value+important的值。 int important = 10; std::function\u003cint(int)\u003e func2 = [\u0026](int value) -\u003e int { return 1+value+important; }; std::bind/std::placeholder 有点像python的偏函数，它给函数一些预定的参数，以便于用更少的参数调用： int foo(int a, int b, int c) { return a + b + c; } int main() { // 将参数1,2绑定到函数 foo 上，但是使用 std::placeholders::_1 来对第一个参数进行占位 auto bindFoo = std::bind(foo, std::placeholders::_1, 1,2); // 这时调用 bindFoo 时，只需要提供第一个参数即可 bindFoo(1); } ","date":"2017-01-29","objectID":"/cpp11_2/:0:2","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（二）","uri":"/cpp11_2/"},{"categories":["C++"],"content":"右值引用 右值和左值 以赋值符号为界，左面的表示一个对象，右面的表示一个对象的值 右值引用 右值引用引用一个临时的值而非对象。 注意： 右值引用必须被初始化。不能int \u0026\u0026i; 右值引用只能绑定临时值。不能int \u0026\u0026i = b; int \u0026\u0026i = 1; int b = 2; i = b; b = 3; std::cout \u003c\u003c i \u003c\u003c std::endl; // 2 相比较而言，左值引用只是对象的一个别名。 右值引用可以延长值的生命周期，并完全接管值的操作。比如： const std::string \u0026i = \"hello\"; //声明后i不可修改 std::string \u0026\u0026i = \"hello\"; //i可变 i += \" wow!\" std::cout \u003c\u003c i \u003c\u003c std::endl; // hello wow! std::move std::move可以将一个变量的值取出并成为右值。 int b = 2; int \u0026\u0026i = std::move(b); 移动语义 传统c++没有移动的概念，一切视为拷贝。如果需要移动一个对象的值到另一个对象，就要把这个对象的值拷贝过去，然后销毁这个对象，造成了巨大的浪费。 而右值引用提供了不需要拷贝的方式： #include \u003ciostream\u003e // std::cout #include \u003cutility\u003e // std::move #include \u003cvector\u003e // std::vector #include \u003cstring\u003e // std::string int main() { std::string str = \"Hello world.\"; std::vector\u003cstd::string\u003e v; v.push_back(str); // 将使用 push_back(const T\u0026), 即产生拷贝行为 std::cout \u003c\u003c \"str: \" \u003c\u003c str \u003c\u003c std::endl; // 将输出 \"str: Hello world.\" v.push_back(std::move(str)); // 将使用 push_back(const T\u0026\u0026), 不会出现拷贝行为 std::cout \u003c\u003c \"str: \" \u003c\u003c str \u003c\u003c std::endl; // 这步操作后, str 中的值会变为空，将输出 \"str: \" return 0; } 完美转发 在传递参数时，并不区分左值右值，都当做左值传递。 使用std:move，可以把所有参数当右值传递。 使用std::forward，可以保留参数类型。 #include \u003ciostream\u003e #include \u003cutility\u003e void reference(int\u0026 v) { std::cout \u003c\u003c \"左值引用\" \u003c\u003c std::endl; } void reference(int\u0026\u0026 v) { std::cout \u003c\u003c \"右值引用\" \u003c\u003c std::endl; } template \u003ctypename T\u003e void pass(T\u0026\u0026 v) { std::cout \u003c\u003c \"普通传参:\"; reference(v); std::cout \u003c\u003c \"std::move 传参:\"; reference(std::move(v)); std::cout \u003c\u003c \"std::forward 传参:\"; reference(std::forward\u003cT\u003e(v)); } int main() { pass(1); int v = 1; pass(v); return 0; } ","date":"2017-01-29","objectID":"/cpp11_2/:0:3","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（二）","uri":"/cpp11_2/"},{"categories":["C++"],"content":"本部分介绍了c++11的崭新的类型推导、循环、模板和构造方法。 ","date":"2017-01-20","objectID":"/cpp11_1/:0:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["C++"],"content":"弃用的特性 1.　不允许以下赋值出现，应使用const char *后者auto。 char *str = \"hello world!\"; 2.　C语言风格的类型转换被弃用，应该使用 static_cast、reinterpret_cast、const_cast 来进行类型转换 3.　register， auto_ptr关键字被弃用。 ","date":"2017-01-20","objectID":"/cpp11_1/:1:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["C++"],"content":"语言增强 ","date":"2017-01-20","objectID":"/cpp11_1/:2:0","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["C++"],"content":"新的关键字 使用nullptr而不是NULL。新的nullptr为nullptr_t类型，可以隐式转换为任何类型，同时避免了NULL == 0这种类型冲突。 constexpr函数：告诉编译器返回的值为常量表达式 ","date":"2017-01-20","objectID":"/cpp11_1/:2:1","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["C++"],"content":"类型推导 auto类型 auto型可以作为变量的声明类型，函数的返回类型 auto型作为函数参数在c++17中才可使用，但要注意重载的问题 auto不能用于数组的类型推导 迭代器的样例： for(auto itr = vec.cbegin(); itr != vec.cend(); ++itr); decltype函数 返回值为一个类型。比如我们可以把z声明为推测的类型 decltype(x+y) z = x + y; ","date":"2017-01-20","objectID":"/cpp11_1/:2:2","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["C++"],"content":"for(item:array)循环 像Python一样地迭代： std::vector\u003cint\u003e arr(5, 100); // \u0026 启用了引用, 如果没有则对 arr 中的元素只能读取不能修改 for(auto \u0026i : arr) { std::cout \u003c\u003c i \u003c\u003c std::endl; } ","date":"2017-01-20","objectID":"/cpp11_1/:2:3","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["C++"],"content":"初始化列表 除了 拷贝构造 () 构造函数初始化 加入了使用列表来初始化的特性： class Magic { public: Magic(std::initializer_list\u003cint\u003e list) {} }; Magic magic = {1,2,3,4,5}; std::vector\u003cint\u003e v = {1, 2, 3, 4}; ","date":"2017-01-20","objectID":"/cpp11_1/:2:4","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["C++"],"content":"模板的强化 关键字 外部模板extern template推迟模板的实例化 \u003e\u003e不再只是右移运算符，可以视作括号嵌套： std::vector\u003cstd::vector\u003cint\u003e\u003e wow; using提供的类型别名 using提供了以下的别名： 函数指针作为新类型 模板类型作为新类型 typedef int (*func)(int *); // 定义了一个返回类型为 int，参数为 int* 的函数指针类型，名字叫做 func using func = int (*)(int *); // 同上, 更加直观 template \u003ctypename T\u003e using IntVec = std::vector\u003cint\u003e; // 合法 IntVec v; 默认模板类型 比如直接使用以下模板函数就可以不指定模板参数直接使用add： template\u003ctypename T = int, typename U = int\u003e auto add(T x, U y) -\u003e decltype(x+y) { return x+y; } 变长参数模板 template\u003ctypename... Ts\u003e class Magic; //任意数量参数 template\u003ctypename Require, typename... Args\u003e class Magic; //一个以上参数 ","date":"2017-01-20","objectID":"/cpp11_1/:2:5","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["C++"],"content":"OO的增强 委托构造 委托本类的其他构造函数构造 class Base { public: int value1; int value2; Base() { value1 = 1; } Base(int value) : Base() { // 委托 Base() 构造函数 value2 = 2; } }; int main() { Base b(2); std::cout \u003c\u003c b.value1 \u003c\u003c std::endl; std::cout \u003c\u003c b.value2 \u003c\u003c std::endl; } 继承构造 在子类中使用父类的构造函数 class Base { public: int value1; int value2; Base() { value1 = 1; } Base(int value) : Base() { // 委托 Base() 构造函数 value2 = 2; } }; class Subclass : public Base { public: int value3; Subclass(int value3, int value2) : Base(value2) { // 继承父类构造 this-\u003evalue3 = value3; } }; int main() { Subclass s(3,2); std::cout \u003c\u003c s.value1 \u003c\u003c std::endl; std::cout \u003c\u003c s.value2 \u003c\u003c std::endl; std::cout \u003c\u003c s.value3 \u003c\u003c std::endl; } 显式虚函数重载 当重载虚函数时，引入override关键字将显式的告知编译器进行重载，编译器将检查基函数是否存在这样的虚函数，否则将无法通过编译 final则是为了防止类被继续继承以及终止虚函数继续重载引入的。 ","date":"2017-01-20","objectID":"/cpp11_1/:2:6","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["C++"],"content":"强类型枚举 类型安全的枚举类： enum class new_enum : unsigned int { value1, value2, value3 = 100, value4 = 100 }; // 内部可以比较 if (new_enum::value3 == new_enum::value4) { std::cout \u003c\u003c \"new_enum::value3 EQ new_enum::value4\" \u003c\u003c std::endl; } //重载 \u003e\u003e template\u003ctypename T\u003e std::ostream\u0026 operator\u003c\u003c(typename std::enable_if\u003cstd::is_enum\u003cT\u003e::value, std::ostream\u003e::type\u0026 stream, const T\u0026 e) { return stream \u003c\u003c static_cast\u003ctypename std::underlying_type\u003cT\u003e::type\u003e(e); } //就可以直接输出 std::cout \u003c\u003c new_enum::value3 \u003c\u003c std::endl ","date":"2017-01-20","objectID":"/cpp11_1/:2:7","tags":["c++"," c++11"],"title":"[C++]C++ 11/14 笔记（一）","uri":"/cpp11_1/"},{"categories":["Python"],"content":"socket十行模板","date":"2017-01-20","objectID":"/socket_in_10_lines/","tags":["Python"," socket"],"title":"[Python]Python版socket十行模板","uri":"/socket_in_10_lines/"},{"categories":["Python"],"content":"以下的socket 都是python实现的服务端接受客户端键盘输入的信息，改为大写返回客户端的模板 都是同步、阻塞的 都会在数据长度大于1024时产生错误，请自己写协议 端口都是8080，请确保未被占用 ","date":"2017-01-20","objectID":"/socket_in_10_lines/:0:0","tags":["Python"," socket"],"title":"[Python]Python版socket十行模板","uri":"/socket_in_10_lines/"},{"categories":["Python"],"content":"tcp_server.py 6行控制监听的最大tcp链接数。 tcp是有链接的。9行建立链接，10行接受数据，11行发送数据，12行关闭链接。 import socket server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) server.bind((\"0.0.0.0\", 8080)) server.listen(1) while True: conn, addr = server.accept() data_from_client = conn.recv(1024).decode('utf8') conn.sendall(data_from_client.upper().encode('utf8')) conn.close() ","date":"2017-01-20","objectID":"/socket_in_10_lines/:1:0","tags":["Python"," socket"],"title":"[Python]Python版socket十行模板","uri":"/socket_in_10_lines/"},{"categories":["Python"],"content":"tcp_client.py 5行链接，6行发送数据，7行接收数据，9行关闭链接。 import socket while True: client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client.connect((\"0.0.0.0\", 8080)) client.sendall(input().encode('utf8')) data_from_server = client.recv(1024).decode('utf8') print('GET ' + data_from_server) client.close() ","date":"2017-01-20","objectID":"/socket_in_10_lines/:2:0","tags":["Python"," socket"],"title":"[Python]Python版socket十行模板","uri":"/socket_in_10_lines/"},{"categories":["Python"],"content":"udp_server.py 8行收，10行发。 需要注意的是，发送时的地址写收数据时得到的地址。 import socket SERVER_ADDR = (\"0.0.0.0\", 8080) server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) server.bind(SERVER_ADDR) while True: data, client_addr = server.recvfrom(1024) sending = data.decode('utf8').upper() server.sendto(sending.encode('utf8'), client_addr) ","date":"2017-01-20","objectID":"/socket_in_10_lines/:3:0","tags":["Python"," socket"],"title":"[Python]Python版socket十行模板","uri":"/socket_in_10_lines/"},{"categories":["Python"],"content":"udp_client.py 7行发，8行收。 import socket server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) SERVER_ADDR = (\"0.0.0.0\", 8080) while True: server.sendto(input().encode('utf8'), SERVER_ADDR) data, addr = server.recvfrom(1024) print('GET', data.decode('utf8')) ","date":"2017-01-20","objectID":"/socket_in_10_lines/:4:0","tags":["Python"," socket"],"title":"[Python]Python版socket十行模板","uri":"/socket_in_10_lines/"},{"categories":["后台"],"content":"可以通过这个样例学习select。实现了简单的非阻塞的HTTP代理，速度非常快，多线程+select。支持HTTPS。","date":"2017-01-12","objectID":"/select/","tags":["socket","后台"],"title":"[后台]用select写一个HTTP代理","uri":"/select/"},{"categories":["后台"],"content":"函数说明 18.3. select — Waiting for I/O completion — Python 3.6.0 documentation ","date":"2017-01-12","objectID":"/select/:1:0","tags":["socket","后台"],"title":"[后台]用select写一个HTTP代理","uri":"/select/"},{"categories":["后台"],"content":"select.select(rlist, wlist, xlist[, timeout]) Unix select()系统调用的一个简单接口。前三个参数是文件描述符（int类型）的序列。 rlist：等待准备读取 wlist：等待准备写作 xlist：等待一个异常 ","date":"2017-01-12","objectID":"/select/:1:1","tags":["socket","后台"],"title":"[后台]用select写一个HTTP代理","uri":"/select/"},{"categories":["后台"],"content":"参数说明 在Unix上序列可以为空，但在Windows则不可以。可选的timeout参数将超时指定为浮点数（以秒为单位）。当省略timeout参数时，该函数阻塞，直到至少一个文件描述符已准备好。该值为0时表示轮询从不停止。 ","date":"2017-01-12","objectID":"/select/:1:2","tags":["socket","后台"],"title":"[后台]用select写一个HTTP代理","uri":"/select/"},{"categories":["后台"],"content":"返回值 准备好的对象列表的三元组（前三个参数的子集）。当超时但没有文件描述符就绪时，返回三个空列表。 ","date":"2017-01-12","objectID":"/select/:1:3","tags":["socket","后台"],"title":"[后台]用select写一个HTTP代理","uri":"/select/"},{"categories":["后台"],"content":"序列对象 序列中可用的对象类型包括Python文件对象（例如sys.stdin或由open()或os.popen()返回的对象），由socket.socket()返回的socket对象。你也可以自己定义一个类，只要它有一个合适的fileno()方法（返回一个真正的文件描述符，而不只是一个随机整数）。 注意： Windows上的文件对象不可接受，但socket可以。在Windows上，底层的select()函数由WinSock库提供，不处理不是源自WinSock的文件描述符。 ","date":"2017-01-12","objectID":"/select/:1:4","tags":["socket","后台"],"title":"[后台]用select写一个HTTP代理","uri":"/select/"},{"categories":["后台"],"content":"实现HTTP代理 代理由两个部分组成：客户端-代理的socket，和代理-Web服务器的socket。 因为代理像两边接受数据时调用recv方法都会发生阻塞， 所以，在这个样例中，事件循环由两个事件组成：客户端-代理链接可以继续接受数据了，和代理-Web服务器链接可以接受数据了（指都是代理端）。 import select import socket import _thread BUFF_SIZE = 1024 # get http head data from a connection def get_post(conn): res = b'' while True: res += conn.recv(BUFF_SIZE) if b'\\r\\n\\r\\n' in res: break return res class Proxy: # init. in_conn: browser-proxy connection, out_conn: proxy-web_server connection def __init__(self, conn, timeout): self.in_conn = conn self.out_conn = None self.timeout = timeout self.run() # main function def run(self): action, url, http_ver, req, headers = self.__parse_header() # https if action in [\"CONNECT\"]: self.in_conn.send(b'HTTP/1.1 200 Connection established\\r\\nProxy-agent: God Proxy\\r\\n\\r\\n') self.__connect(headers) # http else: self.__connect(headers) self.out_conn.send(req) self.event_loop() # close connection self.in_conn.close() self.out_conn.close() # event loop def event_loop(self): count = 0 inputs = [self.in_conn, self.out_conn] outputs = [] while True: read_list, _, exception_list = select.select(inputs, outputs, inputs, self.timeout) count += 1 for future_object in read_list: # once could read, receive data data = future_object.recv(1024) if data: # read in_conn's data, send to out_conn or out_conn to in_conn if future_object is self.in_conn: # print(count, 'out conn', data[:10], '...', data[-10:]) self.out_conn.sendall(data) else: # print(count, 'in conn', data[:10], '...', data[-10:]) self.in_conn.sendall(data) if exception_list: break # time out if count \u003e 100: break # parse host from url and setting up out_conn socket def __connect(self, headers): host_list = headers['Host'].split(':') host = host_list[0] if host_list[-1].isdigit(): port = int(host_list[1]) else: port = 80 socket_info = socket.getaddrinfo(host, port)[0] self.out_conn = socket.socket(socket_info[0]) self.out_conn.connect(socket_info[4]) print('WEB SITE: ', host, socket_info[4]) # get headers from in_conn and parse def __parse_header(self): req = get_post(self.in_conn) str_req = req[:req.find(b'\\r\\n\\r\\n')].decode('utf8') headers = {} lines = str_req.split('\\r\\n') for line in lines[1:]: line = line.split(': ') headers[line[0]] = line[1] action, url, http_ver = lines[0].split() return action, url, http_ver, req, headers def main(): server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) server_address = ('0.0.0.0', 8899) server.bind(server_address) server.listen(0) # 1 connection to 1 thread while True: conn, addr = server.accept() _thread.start_new_thread(Proxy, (conn, 3)) if __name__ == '__main__': main() ","date":"2017-01-12","objectID":"/select/:2:0","tags":["socket","后台"],"title":"[后台]用select写一个HTTP代理","uri":"/select/"},{"categories":["后台"],"content":"学期初写代理的时候发现阻塞式socket并不能满足需要，多线程也不是一个很好的解决方案。这篇文章系统地介绍了epoll是什么以及如何使用。 英文好的同学可以直接看 How To Use Linux epoll with Python 本博客的大部分内容都是基于这篇文章的。 ","date":"2017-01-07","objectID":"/epoll/:0:0","tags":["epoll"," Python"],"title":"[后台]在Python中使用epoll","uri":"/epoll/"},{"categories":["后台"],"content":"什么是epoll （维基百科） 于Linux 2.5.44首度登场的epoll是Linux内核的可扩展I/O事件通知机制。它设计目的只在替换既有POSIX select(2)与poll(2)系统函数，让需要大量操作文件描述符的程序得以发挥更优异的性能(举例来说：旧有的系统函数所花费的时间复杂度为O(n)，epoll则耗时O(1))。epoll与FreeBSD的kqueue类似，底层都是由可配置的操作系统内核对象建构而成，并以文件描述符(file descriptor)的形式呈现于用户空间。 ","date":"2017-01-07","objectID":"/epoll/:1:0","tags":["epoll"," Python"],"title":"[后台]在Python中使用epoll","uri":"/epoll/"},{"categories":["后台"],"content":"为什么使用epoll 首先理解同步异步的概念： 怎样理解阻塞非阻塞与同步异步的区别？- 知乎 同步与异步 同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication) 所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。 换句话说，就是由调用者主动等待这个调用的结果。 而异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。 阻塞与非阻塞 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态. 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 阻塞式socket： 阻塞式socket使用单线程进行通信。主线程创建一个新的socket线程并侦听该socket，它一次性接受所有连接，然后让这个线程与客户端进行交互。因为创建的线程都只和一个客户端通信，所以阻塞并不妨碍其他线程工作 虽然多线程的阻塞式通信编码简单，但是在多线程共享资源时非常困难，在多核下表现也很差 非阻塞的socket： 于是很多替代并发阻塞式socket的方法出现了，例如基于事件系统设计的epoll，它并不会阻塞线程，它可以使用一个线程实现，大大节约了资源. 可见epoll是一个同步的非阻塞解决方案。 ","date":"2017-01-07","objectID":"/epoll/:2:0","tags":["epoll"," Python"],"title":"[后台]在Python中使用epoll","uri":"/epoll/"},{"categories":["后台"],"content":"一般步骤 使用python中的epoll一般有如下步骤： 创建epoll对象 告诉epoll对象监视特定socket上的特定事件 询问epoll对象哪些socket可能有自上次查询以来的指定事件 对这些socket执行一些操作 告诉epoll对象修改要监视的socket和事件的列表 重复步骤3到5直到完成 销毁epoll对象 ","date":"2017-01-07","objectID":"/epoll/:3:0","tags":["epoll"," Python"],"title":"[后台]在Python中使用epoll","uri":"/epoll/"},{"categories":["后台"],"content":"代码实例 epoll设有水平触发和边沿触发两种模式。 在边沿触发操作模式下，socket发生读或写事件后，调用epoll.poll()只会给socket返回一次事件。调用程序必须处理与该事件相关的所有数据。当事件的数据为空时，对socket的继续操作将导致异常。 在水平触发操作模式中，对epoll.poll()的重复调用将导致注册事件的重复通知，直到与该事件相关联的所有数据都已被处理。 边沿触发往往被用于程序员不想使用系统的事件管理机制时。 下面的示例是一个水平触发的典型样例。 需要注意的是，event \u0026 select.EPOLLIN 表示事件的掩码，当掩码值为0时对应的事件发生。 import socket, select EOL1 = b'\\n\\n' EOL2 = b'\\n\\r\\n' response = b'HTTP/1.0 200 OK\\r\\nDate: Mon, 1 Jan 1996 01:01:01 GMT\\r\\n' response += b'Content-Type: text/plain\\r\\nContent-Length: 13\\r\\n\\r\\n' response += b'Hello, world!' serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) serversocket.bind(('0.0.0.0', 8080)) serversocket.listen(1) # 由于socket在默认情况下阻塞，因此使用非阻塞（异步）模式 serversocket.setblocking(0) # 创建一个epoll对象 # 注册socket的读事件为偏好(读事件会在socket建立链接时发生) epoll = select.epoll() epoll.register(serversocket.fileno(), select.EPOLLIN) try: # connections字典将文件描述符（int类型）映射到它们对应的网络连接对象。 connections = {}; requests = {}; responses = {} while True: # 查询epoll对象并获取等待时间内发生的事件列表。参数“1”表示可以等待一秒钟。 events = epoll.poll(1) for fileno, event in events: # events 是(文件描述符，事件代码）二元组的数组 # 建立一个新的链接 if fileno == serversocket.fileno(): connection, address = serversocket.accept() connection.setblocking(0) # 设置为非阻塞模式 epoll.register(connection.fileno(), select.EPOLLIN) # 注册读事件（EPOLLIN） connections[connection.fileno()] = connection requests[connection.fileno()] = b'' responses[connection.fileno()] = response # 当服务端该收数据（客户端已经发出） elif event \u0026 select.EPOLLIN: requests[fileno] += connections[fileno].recv(1024) if EOL1 in requests[fileno] or EOL2 in requests[fileno]: # 一旦接收到完整的请求，则取消注册读事件并注册写事件（EPOLLOUT） # 将响应数据发送回客户端时可能会发生写事件 epoll.modify(fileno, select.EPOLLOUT) # 打印完整的请求(尽管与客户端的通信是交错的，但是该数据可以被组合并作为整个消息处理) print('-'*40 + '\\n' + requests[fileno].decode()[:-2]) # 当服务端该发数据（客户端可以收） elif event \u0026 select.EPOLLOUT: byteswritten = connections[fileno].send(responses[fileno]) # 一次一次发送响应数据 responses[fileno] = responses[fileno][byteswritten:] if len(responses[fileno]) == 0: # 直到完整响应已传送到OS准备进行传输 epoll.modify(fileno, 0) # 发送完整的响应后，禁止读写事件 connections[fileno].shutdown(socket.SHUT_RDWR) # 关闭连接 # HUP事件表示客户端socket已经断开连接(不需要注册, 默认发送) elif event \u0026 select.EPOLLHUP: epoll.unregister(fileno) connections[fileno].close() del connections[fileno] finally: # Python将在程序结束时自动关闭socket连接,不需显式关闭 epoll.unregister(serversocket.fileno()) epoll.close() serversocket.close() ","date":"2017-01-07","objectID":"/epoll/:4:0","tags":["epoll"," Python"],"title":"[后台]在Python中使用epoll","uri":"/epoll/"},{"categories":["后台"],"content":"TCP选项 TCP_CORK选项可用于“填满”消息，直到它们准备好发送。 这个选项适用于于使用HTTP 1.1流水线的HTTP服务器。 elif event \u0026 select.EPOLLIN: ...receive something... connections[fileno].setsockopt(socket.IPPROTO_TCP, socket.TCP_CORK, 1) elif event \u0026 select.EPOLLOUT: ...send something... connections[fileno].setsockopt(socket.IPPROTO_TCP, socket.TCP_CORK, 0) TCP_NODELAY选项用于告诉操作系统传递给socket.send()的任何数据应立即发送到客户端，而不被操作系统缓冲。 这个选项用于SSH客户端或其他“实时”应用程序。 serversocket.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) ","date":"2017-01-07","objectID":"/epoll/:5:0","tags":["epoll"," Python"],"title":"[后台]在Python中使用epoll","uri":"/epoll/"},{"categories":["编译原理"],"content":"语义分析是编译系统的第三部分,负责赋值检查,表达式检查以及代码生成. ","date":"2016-12-27","objectID":"/cmp_codegen/:0:0","tags":["编译原理"],"title":"[编译原理]Python实现的语义分析器","uri":"/cmp_codegen/"},{"categories":["编译原理"],"content":"基本思想 代码沿用了上一部分的文法表, 利用递归下降算法对每一个非终结符写一个函数. 但是文法多达70多条, 工作量太大, 就只实现了赋值语句, 表达式, 条件语句这几个代表性的文法规则. 其他实现起来也类似, 多写几个函数即可. ","date":"2016-12-27","objectID":"/cmp_codegen/:1:0","tags":["编译原理"],"title":"[编译原理]Python实现的语义分析器","uri":"/cmp_codegen/"},{"categories":["编译原理"],"content":"函数介绍 需要注意的几个细节: compare_var_type用于比较类型, 比较失败则raise一个CompileError 在生成代码过程中, 有的传入了其他的变量, 是为了回填 把if回填做成了label的方式, 可以在后阶段再处理 未初始化的变量调用也留给了后阶段处理. 函数表: 成员函数 对应非终结符 备注 init() 初始化 get_register() 分配寄存器 get_label_no() 分配记号 compare_var_type(var_type_1,var_type_2) 比较类型,raise错误 build_table(x) 建立符号表 check_factor(factor) \u003c因式\u003e 用于检查 check_factors(factor) \u003c因式递归\u003e 用于检查 check_factor_c(fc) \u003c因子\u003e 用于检查 check_term(term) \u003c项\u003e 用于检查 check_exp(x) \u003c表达式\u003e 用于检查 check_stm(x) \u003c赋值函数\u003e 用于检查 generate_factor(factor) \u003c因式\u003e 用于生成 generate_factors(factors,factor) \u003c因式递归\u003e 用于生成 generate_factor_c(fc) \u003c因子\u003e 用于生成 generate_term(term,factor) \u003c项\u003e 用于生成 generate_exp(x) \u003c表达式\u003e 用于生成 generate_stm(x) \u003c赋值函数\u003e 用于生成 generate_func_blocks(x) \u003c函数块闭包\u003e 用于生成 generate_func_block(x) \u003c函数块\u003e 用于生成 generate_else_block(x) \u003c否则语句\u003e 用于生成 generate_logical(x) \u003c逻辑表达式\u003e 用于生成 generate_if(x) \u003c条件语句\u003e 用于生成 generate_code(tree) \u003c函数定义\u003e 用于生成 dfs(tree,func) 搜索函数 run(code) 获取生成结果 ","date":"2016-12-27","objectID":"/cmp_codegen/:2:0","tags":["编译原理"],"title":"[编译原理]Python实现的语义分析器","uri":"/cmp_codegen/"},{"categories":["编译原理"],"content":"文法表 \u003c函数定义\u003e-\u003e\u003c修饰词闭包\u003e\u003c类型\u003e\u003c变量\u003e[(]\u003c参数声明\u003e[)][{]\u003c函数块\u003e[}] \u003c修饰词闭包\u003e-\u003e\u003c修饰词\u003e\u003c修饰词闭包\u003e \u003c修饰词闭包\u003e-\u003e[@] \u003c修饰词\u003e-\u003e[public] \u003c修饰词\u003e-\u003e[private] \u003c修饰词\u003e-\u003e[protected] \u003c类型\u003e-\u003e[int]\u003c取地址\u003e \u003c类型\u003e-\u003e[char]\u003c取地址\u003e \u003c类型\u003e-\u003e[boolean]\u003c取地址\u003e \u003c类型\u003e-\u003e[void]\u003c取地址\u003e \u003c取地址\u003e-\u003e\u003c星号\u003e\u003c取地址\u003e \u003c取地址\u003e-\u003e[@] \u003c星号\u003e-\u003e[*] \u003c变量\u003e-\u003e\u003c标志符\u003e\u003c数组下标\u003e \u003c标志符\u003e-\u003e[id] \u003c数组下标\u003e-\u003e[[]\u003c因式\u003e[]] \u003c数组下标\u003e-\u003e[@] \u003c因式\u003e-\u003e[(]\u003c表达式\u003e[)] \u003c因式\u003e-\u003e\u003c变量\u003e \u003c因式\u003e-\u003e\u003c数字\u003e \u003c数字\u003e-\u003e[digit] \u003c表达式\u003e-\u003e\u003c因子\u003e\u003c项\u003e \u003c因子\u003e-\u003e\u003c因式\u003e\u003c因式递归\u003e \u003c因式递归\u003e-\u003e[*]\u003c因式\u003e\u003c因式递归\u003e \u003c因式递归\u003e-\u003e[/]\u003c因式\u003e\u003c因式递归\u003e \u003c因式递归\u003e-\u003e[@] \u003c项\u003e-\u003e[+]\u003c因子\u003e\u003c项\u003e \u003c项\u003e-\u003e[-]\u003c因子\u003e\u003c项\u003e \u003c项\u003e-\u003e[@] \u003c参数声明\u003e-\u003e\u003c声明\u003e\u003c声明闭包\u003e \u003c参数声明\u003e-\u003e[@] \u003c声明\u003e-\u003e\u003c修饰词闭包\u003e\u003c类型\u003e\u003c变量\u003e\u003c赋初值\u003e \u003c赋初值\u003e-\u003e[=]\u003c右值\u003e \u003c赋初值\u003e-\u003e[@] \u003c右值\u003e-\u003e\u003c表达式\u003e \u003c右值\u003e-\u003e[{]\u003c多个数据\u003e[}] \u003c多个数据\u003e-\u003e\u003c数字\u003e\u003c数字闭包\u003e \u003c数字闭包\u003e-\u003e[,]\u003c数字\u003e\u003c数字闭包\u003e \u003c数字闭包\u003e-\u003e[@] \u003c声明闭包\u003e-\u003e[,]\u003c声明\u003e\u003c声明闭包\u003e \u003c声明闭包\u003e-\u003e[@] \u003c函数块\u003e-\u003e\u003c声明语句闭包\u003e\u003c函数块闭包\u003e \u003c声明语句闭包\u003e-\u003e\u003c声明语句\u003e\u003c声明语句闭包\u003e \u003c声明语句闭包\u003e-\u003e[@] \u003c声明语句\u003e-\u003e\u003c声明\u003e[;] \u003c函数块闭包\u003e-\u003e\u003c赋值函数\u003e\u003c函数块闭包\u003e \u003c函数块闭包\u003e-\u003e\u003cfor循环\u003e\u003c函数块闭包\u003e \u003c函数块闭包\u003e-\u003e\u003c条件语句\u003e\u003c函数块闭包\u003e \u003c函数块闭包\u003e-\u003e\u003c函数返回\u003e\u003c函数块闭包\u003e \u003c函数块闭包\u003e-\u003e[@] \u003c赋值函数\u003e-\u003e\u003c变量\u003e\u003c赋值或函数调用\u003e \u003c赋值或函数调用\u003e-\u003e[=]\u003c右值\u003e[;] \u003c赋值或函数调用\u003e-\u003e[(]\u003c参数列表\u003e[)][;] \u003c参数列表\u003e-\u003e\u003c参数\u003e\u003c参数闭包\u003e \u003c参数闭包\u003e-\u003e[,]\u003c参数\u003e\u003c参数闭包\u003e \u003c参数闭包\u003e-\u003e[@] \u003c参数\u003e-\u003e\u003c标志符\u003e \u003c参数\u003e-\u003e\u003c数字\u003e \u003c参数\u003e-\u003e\u003c字符串\u003e \u003c字符串\u003e-\u003e[string] \u003cfor循环\u003e-\u003e[for][(]\u003c赋值函数\u003e\u003c逻辑表达式\u003e[;]\u003c后缀表达式\u003e[)][{]\u003c函数块\u003e[}] \u003c逻辑表达式\u003e-\u003e\u003c表达式\u003e\u003c逻辑运算符\u003e\u003c表达式\u003e \u003c逻辑运算符\u003e-\u003e[\u003c] \u003c逻辑运算符\u003e-\u003e[\u003e] \u003c逻辑运算符\u003e-\u003e[==] \u003c逻辑运算符\u003e-\u003e[!=] \u003c后缀表达式\u003e-\u003e\u003c变量\u003e\u003c后缀运算符\u003e \u003c后缀运算符\u003e-\u003e[++] \u003c后缀运算符\u003e-\u003e[--] \u003c条件语句\u003e-\u003e[if][(]\u003c逻辑表达式\u003e[)][{]\u003c函数块\u003e[}]\u003c否则语句\u003e \u003c否则语句\u003e-\u003e[else][{]\u003c函数块\u003e[}] \u003c否则语句\u003e-\u003e[@] \u003c函数返回\u003e-\u003e[return]\u003c因式\u003e[;] ","date":"2016-12-27","objectID":"/cmp_codegen/:3:0","tags":["编译原理"],"title":"[编译原理]Python实现的语义分析器","uri":"/cmp_codegen/"},{"categories":["编译原理"],"content":"代码实现 知道了思路还是很好读的, 无非是看每个非终结符对应了哪条规则, 再利用分支调用对应的分支. import json from Parse import Parser # compile error class class CompileError(Exception): pass class Check: # init def __init__(self): self.TABLE = {} self.error_message = '' self.register_no = 0 self.label_no = 0 self.ADD_TABLE = {'+': 'ADD ', '-': 'SUB ', '*': 'MUL ', '/': 'DEV '} self.ADD_CODE = [] # allocate register def get_register(self): self.register_no += 1 return 'r' + str(self.register_no) # allocate label def get_label_no(self): self.label_no += 1 return 'LABEL ' + str(self.label_no) # compare two types and raise error def compare_var_type(self, var_type_1, var_type_2): if var_type_1 == var_type_2: return var_type_1 else: self.error_message = 'Expression err: can\\'t operate ' + var_type_1 + ' with ' + var_type_2 raise CompileError # build var table def build_table(self, x): if type(x) != list or type(x[0]) != str: return var_name = None var_type = None if x[0].startswith(\"\u003c函数定义\u003e\"): for v in x: if type(v) != list: continue if type(v[0]) == str and v[0].startswith(\"\u003c类型\u003e\"): var_type = v[1][\"raw_data\"] elif type(v[0]) == str and v[0].startswith(\"\u003c变量\u003e\"): var_name = v[1][1][\"raw_data\"] elif x[0].startswith(\"\u003c声明\u003e\"): for v in x: if type(v) != list: continue if type(v[0]) == str and v[0].startswith(\"\u003c类型\u003e\"): var_type = v[1][\"raw_data\"] elif type(v[0]) == str and v[0].startswith(\"\u003c变量\u003e\"): var_name = v[1][1][\"raw_data\"] if var_name and var_type: r = self.get_register() self.ADD_CODE.append('SET ' + var_name + ', ' + r) self.TABLE[var_name] = {'type': var_type, 'register': r} def check_factor(self, factor): if factor[0].endswith('17'): return self.check_exp(factor[2]) else: if factor[1][0].startswith('\u003c变量\u003e'): if factor[1][1][1][\"raw_data\"] in self.TABLE: return self.TABLE[factor[1][1][1][\"raw_data\"]]['type'] else: self.error_message = 'No define ' + factor[1][1][1][\"raw_data\"] + '.' raise CompileError else: return 'int' def check_factors(self, factor): if type(factor[3]) != list: return self.check_factor(factor[2]) else: return self.compare_var_type(self.check_factor(factor[2]), self.check_factors(factor[3])) def check_factor_c(self, fc): if type(fc[2]) != list: return self.check_factor(fc[1]) else: return self.compare_var_type(self.check_factor(fc[1]), self.check_factors(fc[2])) def check_term(self, term): if type(term[3]) != list: return self.check_factor_c(term[2]) else: return self.compare_var_type(self.check_factor_c(term[2]), self.check_term(term[3])) def check_exp(self, x): if type(x) != list or type(x[0]) != str: return if x[0].startswith(\"\u003c表达式\u003e\"): if type(x[2]) != list: # 项 return self.check_factor_c(x[1]) # check 因子 else: return self.compare_var_type(self.check_factor_c(x[1]), self.check_term(x[2])) def check_stm(self, x): if x[0].startswith(\"\u003c赋值函数\u003e\"): var_name = x[1][1][1][\"raw_data\"] if var_name in self.TABLE: var_type = self.TABLE[x[1][1][1][\"raw_data\"]]['type'] exp_type = self.check_exp(x[2][2][1]) if var_type != exp_type: self.error_message = 'Var ' + var_name + ' should be '+ var_type + ', but got ' + str(self.check_exp(x[2][2][1])) raise CompileError else: self.error_message = 'No define ' + x[1][1][1][\"raw_data\"] raise CompileError def generate_factor(self, factor): if factor[0].endswith('17'): return self.generate_exp(factor[2]) else: if factor[1][0].startswith('\u003c变量\u003e'): if factor[1][1][1][\"raw_data\"] in self.TABLE: return self.TABLE[factor[1][1][1][\"raw_data\"]]['register'] else: self.error_message = 'No define' + factor[1][1][1][\"raw_data\"] else: # is number return factor[1][1][\"raw_data\"] def generate_factors(self, factors, factor): r = self.get_register() if type(factors[3]) != list: self.ADD_CODE.append(self.ADD_TABLE[factors[1]['raw_data']] + factor + ', ' + self.generate_factor(factors[2]) + ', ' + r) else: self.ADD_CODE.append(self.ADD_TABLE[factors[1]['raw_data']] + self.generate_factor(factors[2]) + ', ' + self.generate_factors(factors[3], factor) + ', ' + r) return r def generate_factor_c(self, fc): if type(fc[2]) != list: return self.generate_factor(","date":"2016-12-27","objectID":"/cmp_codegen/:4:0","tags":["编译原理"],"title":"[编译原理]Python实现的语义分析器","uri":"/cmp_codegen/"},{"categories":["编译原理"],"content":"语法分析器是这套编译系统的第二部分,可以直接用上一篇中的词法分析器的结果继续做语法分析. ","date":"2016-12-27","objectID":"/cmp_grammar/:0:0","tags":["编译原理"],"title":"[编译原理]Python实现的语法分析器","uri":"/cmp_grammar/"},{"categories":["编译原理"],"content":"文法表 = =一直没时间更, 直到考试周格外闲… 借鉴了一个网络上的文法表, 覆盖了一些基础的C文法, 测试后发现该文法是LL(1)文法. 文法如下: \u003c函数定义\u003e-\u003e\u003c修饰词闭包\u003e\u003c类型\u003e\u003c变量\u003e[(]\u003c参数声明\u003e[)][{]\u003c函数块\u003e[}] \u003c修饰词闭包\u003e-\u003e\u003c修饰词\u003e\u003c修饰词闭包\u003e \u003c修饰词闭包\u003e-\u003e[@] \u003c修饰词\u003e-\u003e[public] \u003c修饰词\u003e-\u003e[private] \u003c修饰词\u003e-\u003e[protected] \u003c类型\u003e-\u003e[int]\u003c取地址\u003e \u003c类型\u003e-\u003e[char]\u003c取地址\u003e \u003c类型\u003e-\u003e[boolean]\u003c取地址\u003e \u003c类型\u003e-\u003e[void]\u003c取地址\u003e \u003c取地址\u003e-\u003e\u003c星号\u003e\u003c取地址\u003e \u003c取地址\u003e-\u003e[@] \u003c星号\u003e-\u003e[*] \u003c变量\u003e-\u003e\u003c标志符\u003e\u003c数组下标\u003e \u003c标志符\u003e-\u003e[id] \u003c数组下标\u003e-\u003e[[]\u003c因式\u003e[]] \u003c数组下标\u003e-\u003e[@] \u003c因式\u003e-\u003e[(]\u003c表达式\u003e[)] \u003c因式\u003e-\u003e\u003c变量\u003e \u003c因式\u003e-\u003e\u003c数字\u003e \u003c数字\u003e-\u003e[digit] \u003c表达式\u003e-\u003e\u003c因子\u003e\u003c项\u003e \u003c因子\u003e-\u003e\u003c因式\u003e\u003c因式递归\u003e \u003c因式递归\u003e-\u003e[*]\u003c因式\u003e\u003c因式递归\u003e \u003c因式递归\u003e-\u003e[/]\u003c因式\u003e\u003c因式递归\u003e \u003c因式递归\u003e-\u003e[@] \u003c项\u003e-\u003e[+]\u003c因子\u003e\u003c项\u003e \u003c项\u003e-\u003e[-]\u003c因子\u003e\u003c项\u003e \u003c项\u003e-\u003e[@] \u003c参数声明\u003e-\u003e\u003c声明\u003e\u003c声明闭包\u003e \u003c参数声明\u003e-\u003e[@] \u003c声明\u003e-\u003e\u003c修饰词闭包\u003e\u003c类型\u003e\u003c变量\u003e\u003c赋初值\u003e \u003c赋初值\u003e-\u003e[=]\u003c右值\u003e \u003c赋初值\u003e-\u003e[@] \u003c右值\u003e-\u003e\u003c表达式\u003e \u003c右值\u003e-\u003e[{]\u003c多个数据\u003e[}] \u003c多个数据\u003e-\u003e\u003c数字\u003e\u003c数字闭包\u003e \u003c数字闭包\u003e-\u003e[,]\u003c数字\u003e\u003c数字闭包\u003e \u003c数字闭包\u003e-\u003e[@] \u003c声明闭包\u003e-\u003e[,]\u003c声明\u003e\u003c声明闭包\u003e \u003c声明闭包\u003e-\u003e[@] \u003c函数块\u003e-\u003e\u003c声明语句闭包\u003e\u003c函数块闭包\u003e \u003c声明语句闭包\u003e-\u003e\u003c声明语句\u003e\u003c声明语句闭包\u003e \u003c声明语句闭包\u003e-\u003e[@] \u003c声明语句\u003e-\u003e\u003c声明\u003e[;] \u003c函数块闭包\u003e-\u003e\u003c赋值函数\u003e\u003c函数块闭包\u003e \u003c函数块闭包\u003e-\u003e\u003cfor循环\u003e\u003c函数块闭包\u003e \u003c函数块闭包\u003e-\u003e\u003c条件语句\u003e\u003c函数块闭包\u003e \u003c函数块闭包\u003e-\u003e\u003c函数返回\u003e\u003c函数块闭包\u003e \u003c函数块闭包\u003e-\u003e[@] \u003c赋值函数\u003e-\u003e\u003c变量\u003e\u003c赋值或函数调用\u003e \u003c赋值或函数调用\u003e-\u003e[=]\u003c右值\u003e[;] \u003c赋值或函数调用\u003e-\u003e[(]\u003c参数列表\u003e[)][;] \u003c参数列表\u003e-\u003e\u003c参数\u003e\u003c参数闭包\u003e \u003c参数闭包\u003e-\u003e[,]\u003c参数\u003e\u003c参数闭包\u003e \u003c参数闭包\u003e-\u003e[@] \u003c参数\u003e-\u003e\u003c标志符\u003e \u003c参数\u003e-\u003e\u003c数字\u003e \u003c参数\u003e-\u003e\u003c字符串\u003e \u003c字符串\u003e-\u003e[string] \u003cfor循环\u003e-\u003e[for][(]\u003c赋值函数\u003e\u003c逻辑表达式\u003e[;]\u003c后缀表达式\u003e[)][{]\u003c函数块\u003e[}] \u003c逻辑表达式\u003e-\u003e\u003c表达式\u003e\u003c逻辑运算符\u003e\u003c表达式\u003e \u003c逻辑运算符\u003e-\u003e[\u003c] \u003c逻辑运算符\u003e-\u003e[\u003e] \u003c逻辑运算符\u003e-\u003e[==] \u003c逻辑运算符\u003e-\u003e[!=] \u003c后缀表达式\u003e-\u003e\u003c变量\u003e\u003c后缀运算符\u003e \u003c后缀运算符\u003e-\u003e[++] \u003c后缀运算符\u003e-\u003e[--] \u003c条件语句\u003e-\u003e[if][(]\u003c逻辑表达式\u003e[)][{]\u003c函数块\u003e[}]\u003c否则语句\u003e \u003c否则语句\u003e-\u003e[else][{]\u003c函数块\u003e[}] \u003c否则语句\u003e-\u003e[@] \u003c函数返回\u003e-\u003e[return]\u003c因式\u003e[;] ","date":"2016-12-27","objectID":"/cmp_grammar/:1:0","tags":["编译原理"],"title":"[编译原理]Python实现的语法分析器","uri":"/cmp_grammar/"},{"categories":["编译原理"],"content":"Grammar.py 典型的LL(1)的分析过程, 构造NULLABLE集, FIRST集, FOLLOW集, 计算SELECT集,最后画出预测分析表, 生成AST. 其中simplify_tree是用来递归简化树上的节点的. 代码很好读,都是华老师课件上的步骤. import json import re import copy from Driver import Driver # build tree def simplify_tree(x: list): r = [] for i in x: if isinstance(i, list): v = simplify_tree(i) if v is not None: r.append(v) else: r.append(i) if len(r) == 0: return None elif len(r) == 1: return r[0] else: return r class Parser: # init sets def __init__(self): self.TERMINAL = [] self.NONTERMINAL = [] self.NULLABLE = set() self. FIRST = {} self.FOLLOW = {} self.FIRST_S = {} self.CFG = [] self.TABLE = {} self.error_message = '' # build terminal, nonterminal and CFG with open('wenfa.json', 'r') as f: raw_cfg = json.load(f) for v in raw_cfg: v = v.split('-\u003e') self.NONTERMINAL.append(v[0]) beta = v[1].split('|') for s in beta: item = s.split(' ') for l in item: if l not in self.TERMINAL and re.match('\u003c.*\u003e', l) is None: self.TERMINAL.append(l) self.CFG.append([v[0], item]) # init sets self.init_nullable() self.init_first() self.init_follow() self.init_first_s() # is x noterminal? def is_nonterminal_array(self, x): for v in x: if v not in self.NONTERMINAL: return False return True # can x be null? def is_nullable_array(self, x): for v in x: if v not in self.NULLABLE: return False return True # init nullable set def init_nullable(self): while True: tmp = copy.deepcopy(self.NULLABLE) for v in self.CFG: if v[1] == ['@']: self.NULLABLE |= {v[0]} if self.is_nonterminal_array(v[1]) and self.is_nullable_array(v[1]): self.NULLABLE |= {v[0]} if tmp == self.NULLABLE: break # init first set def init_first(self): for v in self.NONTERMINAL: self.FIRST[v] = set() change_flag = True while change_flag: raw_set = copy.deepcopy(self.FIRST) for v in self.CFG: for s in v[1]: if s in self.NONTERMINAL: self.FIRST[v[0]] |= self.FIRST[s] if s not in self.NULLABLE: break else: self.FIRST[v[0]] |= {s} break change_flag = False for v in raw_set: if raw_set[v] != self.FIRST[v]: change_flag = True # init follow set def init_follow(self): for v in self.NONTERMINAL: self.FOLLOW[v] = set() change_flag = True while change_flag: raw_set = copy.deepcopy(self.FOLLOW) for v in self.CFG: tmp = self.FOLLOW[v[0]] beta = copy.deepcopy(v[1]) beta.reverse() for s in beta: if s in self.NONTERMINAL: self.FOLLOW[s] |= tmp if s not in self.NULLABLE: tmp = self.FIRST[s] else: tmp |= self.FIRST[s] else: tmp = {s} change_flag = False for v in raw_set: if raw_set[v] != self.FOLLOW[v]: change_flag = True # init select set def init_first_s(self): for i in range(0, len(self.CFG)): self.FIRST_S[i] = set() for i in range(0, len(self.CFG)): self.calc_first_s(i, self.CFG[i]) # build table self.TABLE = {} for v in self.FIRST_S: if self.CFG[v][0] not in self.TABLE: self.TABLE[self.CFG[v][0]] = {} for s in self.FIRST_S[v]: if s not in self.TABLE[self.CFG[v][0]]: self.TABLE[self.CFG[v][0]][s] = v else: # occurs if self.CFG[self.TABLE[self.CFG[v][0]][s]][1] != ['@']: if self.CFG[v][1] == ['@']: pass else: print('Occur: ', v, 'and', self.TABLE[self.CFG[v][0]][s]) else: self.TABLE[self.CFG[v][0]][s] = v # this code could print predict table # print table # for v in self.TERMINAL: # print(v, end=' ') # print('') # for v in self.TABLE: # print(v, end=' ') # for s in self.TERMINAL: # try: # print(self.TABLE[v][s], end=' ') # except: # print('* ', end='') # print('') # calc first_s for every rule def calc_first_s(self, i, v): for s in v[1]: if s in self.NONTERMINAL: self.FIRST_S[i] |= self.FIRST[s] if s not in self.NULLABLE: return else: self.FIRST_S[i] |= {s} if s != '@': return self.FIRST_S[i] |= self.FOLLOW[v[0]] # drive code def parse(self, tokens): dom = [] stack = [('\u003c函数定义\u003e', dom)] i = 0 while stack: # EOF if i == len(tokens): self.error_message = 'Line ' + line_no + ' EOF_ERROR: unexpected end of file' return # get data if tokens[i]['raw_data'] in self.TERMINAL: ch = tokens[i]['raw_data'] else: ch = tokens[i]['symbol'] line_no = str(tokens[i]['line_no']) # operate stack if stack[-1][0] in self.","date":"2016-12-27","objectID":"/cmp_grammar/:2:0","tags":["编译原理"],"title":"[编译原理]Python实现的语法分析器","uri":"/cmp_grammar/"},{"categories":["算法"],"content":"普林斯顿算法公开课作业二, 双向队列和随机队列","date":"2016-11-15","objectID":"/princeton_pa2_deque/","tags":["普林斯顿算法公开课","算法","队列"],"title":"[普林斯顿算法公开课]双向队列和随机队列","uri":"/princeton_pa2_deque/"},{"categories":["算法"],"content":"思路 这次的内容是写一个双向队列和随机队列, 双向队列自不必说, 用链表即可, 注意一下表头表尾的操作以及只有一个元素时的删除操作. 随机队列实现随机的时候需要查询具体下标的元素, 是一个O(1)操作, 所以使用自增长内存池实现. 刷到满分的过程中逐步解决的一些问题: 1. 对题目要求的每一个Exception都要抛出.否则会有以下问题: case test 失败 测试中断: Warning: the grading output was truncated due to excessive length. 2. 删除的节点和数组需要置null释放, 比如Deque出队的节点, RandomizedQueue出队的元素, 否则会报 - loitering observed during 71 of 100 deletions 3. 注意RandomizedQueue的capacity大小调节的时机, 在size到达capacity一半时扩大, 在size到达capacity四分之一时减小.否则会有以下问题: 不缩小capacity: 会导致内存测试失败 调节时机不对: 会导致一半的时间测试失败, 或者测试中断: Warning: the grading output was truncated due to excessive length. size 不为正数的边界情况: 数组越界 = =这个capacity大小要求过于严格了, 导致我用自己习惯的增长方式没有AC… ","date":"2016-11-15","objectID":"/princeton_pa2_deque/:1:0","tags":["普林斯顿算法公开课","算法","队列"],"title":"[普林斯顿算法公开课]双向队列和随机队列","uri":"/princeton_pa2_deque/"},{"categories":["算法"],"content":"Deque.java /** * Created by chestnutheng on 16-11-14. */ import java.util.Iterator; public class Deque\u003cItem\u003e implements Iterable\u003cItem\u003e{ private Node first = null; private Node last = null; private int size = 0; private class Node { Item item; Node prev; Node next; } // construct an empty deque public Deque() {} // is the deque empty? public boolean isEmpty() { return size == 0; } // return the number of items on the deque public int size() { return size; } // add the item to the front public void addFirst(Item item){ if(item == null) { throw new java.lang.NullPointerException(); } Node tv = new Node(); tv.item = item; tv.next = first; if(first != null){ first.prev = tv; } first = tv; size++; if(last == null){ last = tv; } } // add the item to the end public void addLast(Item item) { if(item == null) { throw new java.lang.NullPointerException(); } Node tv = new Node(); tv.item = item; tv.next = null; tv.prev = last; if(last != null){ last.next = tv; } last = tv; size++; if(first == null){ first = tv; } } // remove and return the item from the front public Item removeFirst() { if(isEmpty()){ throw new java.util.NoSuchElementException(); } Item item = first.item; first = first.next; if(first != null) { first.prev = null; } size--; if(size == 0){ first = last = null; } return item; } // remove and return the item from the end public Item removeLast() { if(isEmpty()){ throw new java.util.NoSuchElementException(); } Item item = last.item; last = last.prev; if(last != null) { last.next = null; } size--; if(size == 0){ first = last = null; } return item; } // return an iterator over items in order from front to end public Iterator\u003cItem\u003e iterator(){ class DequeIterator implements Iterator\u003cItem\u003e{ private Node tv = first; public boolean hasNext() { return tv != null; } public void remove(){throw new java.lang.UnsupportedOperationException();} public Item next() { if(!hasNext()){ throw new java.util.NoSuchElementException(); } Item item = tv.item; tv = tv.next; return item; } } return new DequeIterator(); } // unit testing public static void main(String[] args) { Deque\u003cString\u003edeque = new Deque\u003c\u003e(); deque.addLast(\"0\"); deque.removeLast(); deque.size(); deque.size(); deque.isEmpty(); deque.addFirst(\"5\"); deque.removeFirst(); System.out.println(deque.size()); deque.addLast(\"7\"); System.out.println(deque.removeFirst()); } } ","date":"2016-11-15","objectID":"/princeton_pa2_deque/:2:0","tags":["普林斯顿算法公开课","算法","队列"],"title":"[普林斯顿算法公开课]双向队列和随机队列","uri":"/princeton_pa2_deque/"},{"categories":["算法"],"content":"RandomizedQueue.java /** * Created by chestnutheng on 16-11-14. */ import java.util.Iterator; import edu.princeton.cs.algs4.StdRandom; public class RandomizedQueue\u003cItem\u003e implements Iterable\u003cItem\u003e{ private int size = 0; private Item[] pool; // construct an empty randomized queue public RandomizedQueue(){ pool = (Item[])new Object[5]; } // check capacity size and resize private void check_capacity(){ if(size == pool.length - 1){ Item[] np = (Item[])new Object[size*2]; for (int i = 0; i \u003c size; ++i){ np[i] = pool[i]; } pool = np; }else if(size == pool.length/4 + 1 \u0026\u0026 size \u003e 0){ Item[] np = (Item[])new Object[size*2]; for (int i = 0; i \u003c size; ++i){ np[i] = pool[i]; } pool = np; } } // is the queue empty? public boolean isEmpty(){ return size == 0; } // return the number of items on the queue public int size(){ return size; } // add the item public void enqueue(Item item){ if(item == null) { throw new java.lang.NullPointerException(); } check_capacity(); pool[size] = item; size++; } // remove and return a random item public Item dequeue(){ if(isEmpty()){ throw new java.util.NoSuchElementException(); } int target = (int) (Math.random()*size); Item item = pool[target]; pool[target] = pool[size - 1]; pool[size - 1] = null; size--; check_capacity(); return item; } // return (but do not remove) a random item public Item sample(){ if(isEmpty()){ throw new java.util.NoSuchElementException(); } int target = (int) (Math.random()*size); return pool[target]; } // return an independent iterator over items in random order public Iterator\u003cItem\u003e iterator(){ class VectorIterator implements Iterator\u003cItem\u003e{ private int helicopter = 0; private Item[] random_array; public VectorIterator(){ random_array = (Item[])new Object[size]; for (int i = 0; i \u003c size; ++i){ random_array[i] = pool[i]; } StdRandom.shuffle(random_array); } public boolean hasNext() { return helicopter \u003c size; } public void remove(){throw new java.lang.UnsupportedOperationException();} public Item next() { if(!hasNext()){ throw new java.util.NoSuchElementException(); } return random_array[helicopter++]; } } return new VectorIterator(); } //test client public static void main(String[] args){ RandomizedQueue\u003cInteger\u003e r = new RandomizedQueue\u003c\u003e(); r.enqueue(1); r.enqueue(2); r.dequeue(); r.dequeue(); for (int s:r ) { System.out.println(s); } } } ","date":"2016-11-15","objectID":"/princeton_pa2_deque/:3:0","tags":["普林斯顿算法公开课","算法","队列"],"title":"[普林斯顿算法公开课]双向队列和随机队列","uri":"/princeton_pa2_deque/"},{"categories":["编译原理"],"content":"最近在上华保健老师的课, 在学习的过程中做了一套编译系统, 外加顺便应付学校的作业. 这个词法分析器是这套编译系统的第一部分. 其中RE到DFA, DFA到NFA的部分都是手工完成, 自己规定token格式(C语言格式), 得到一个NFA. 课程内容详见: 编译原理MOOC 算法都是课程中的算法, 不再详述.伪代码可以在华老师的课件中找到. ","date":"2016-11-15","objectID":"/cmp_lex/:0:0","tags":["编译原理"],"title":"[编译原理]Python实现的词法分析器","uri":"/cmp_lex/"},{"categories":["编译原理"],"content":"state_machine.json 第一部分是手写的DFA, 用类似树状数组的方式存储. 几个Key的含义如下: SS: 起始状态 FS: 接受状态 I: 接受字符 T: 转换表 //如\"8\": {\"3\": 10, \"5\": 9}表示状态8输入I[3]可以转换到状态10, 状态8输入I[3]可以转换到状态9 S: 状态表 //下标对应的状态的含义 json文件: state_machine.json ","date":"2016-11-15","objectID":"/cmp_lex/:1:0","tags":["编译原理"],"title":"[编译原理]Python实现的词法分析器","uri":"/cmp_lex/"},{"categories":["编译原理"],"content":"Driver.py 驱动文件,分析结果为三元组**(标识符, 内容, 行数)**的序列. #!/usr/bin/env python3 import json class Driver: STATE_MACHINE = None content_symbols = ['id', 'digit'] line_no = 0 NOW_POINT = -1 PREV_POINT = -1 STRING = '' uncommit = '' token_list = [] def __init__(self, file_name): with open(file_name, 'r') as f: self.STATE_MACHINE = json.load(f) # reset def reset(self): self.STRING = '' self.uncommit = '' self.token_list.clear() self.NOW_POINT = -1 #当前分析的字符下标 self.PREV_POINT = -1 #用于获得标识符对应的内容 self.line_no = 0 # next char of string def next_ch(self): self.NOW_POINT += 1 if self.NOW_POINT \u003c len(self.STRING): return self.STRING[self.NOW_POINT] else: return None # rollback def rollback(self): self.NOW_POINT -= 1 # drive code def next_token(self): state = \"0\" stack = [] # get a token while True: c = self.next_ch() if c is None: return False # accept state if int(state) in self.STATE_MACHINE[\"FS\"]: stack.clear() stack.append(state) # state change or state error num = None for i in range(0, len(self.STATE_MACHINE[\"I\"])): if c in self.STATE_MACHINE[\"I\"][i]: num = i if num is None: return False # not accepted try: state = str(self.STATE_MACHINE[\"T\"][state][str(num)]) except KeyError: break state = stack.pop(-1) self.rollback() # get idn and token idn = self.STATE_MACHINE['S'][int(state)] name = self.STRING[self.PREV_POINT + 1:self.NOW_POINT + 1] if idn != 'SPACE': self.token_list.append({'symbol': idn, 'raw_data': name, 'line_no': self.line_no}) self.PREV_POINT = self.NOW_POINT return True # print token to uncommit def print_token(self): for v in self.token_list: self.uncommit += v['raw_data'] + '\\t\u003c ' + v['symbol'] if v['symbol'] in self.content_symbols: self.uncommit += ' , ' + v['raw_data'] + '\u003e' + '\\n' else: self.uncommit += ' , - \u003e' + '\\n' # run a string def run(self, string): self.reset() STRING_ARRAY = string.replace('\\t', '').split('\\n') for v in STRING_ARRAY: self.NOW_POINT = -1 self.PREV_POINT = -1 self.line_no += 1 self.STRING = v + ';' while True: if not self.next_token(): break self.print_token() if __name__ == '__main__': d = Driver('state_machine.json') d.run('while(num!=100)\\n{\\nnum++;\\n}\\n') #简短的示例 print(d.uncommit) print(d.token_list) d.run('n++') print(d.uncommit) print(d.token_list) ","date":"2016-11-15","objectID":"/cmp_lex/:2:0","tags":["编译原理"],"title":"[编译原理]Python实现的词法分析器","uri":"/cmp_lex/"},{"categories":["算法"],"content":"普林斯顿算法公开课作业一, 并查集的应用","date":"2016-11-08","objectID":"/princeton_pa1_percolation/","tags":["普林斯顿算法公开课","算法","并查集"],"title":"[普林斯顿算法公开课]并查集解决渗透问题","uri":"/princeton_pa1_percolation/"},{"categories":["算法"],"content":"Percolation.java 题目见 渗透问题 运用题目给出的API来解决问题. 第一个文件是Percolation.java, 用来编写解决单个渗透问题相关代码. API: public class Percolation { public Percolation(int n) // create n-by-n grid, with all sites blocked public void open(int row, int col) // open site (row, col) if it is not open already public boolean isOpen(int row, int col) // is site (row, col) open? public boolean isFull(int row, int col) // is site (row, col) full? public boolean percolates() // does the system percolate? public static void main(String[] args) // test client (optional) } 大体思想是, 建立一个查是否渗透的并查集, 只要最上面一排和最下面一排属于一个集合就认为是渗透的. 但是判断每两个节点是否联通需要额外的$n^2$的时间, 显然不合适. 我们引入两个假节点分别为top节点和down节点, 再把top节点与最上一排的节点连接, down节点与最下一排的节点连接, 这样渗透问题就等价转换为上下两个节点是否联通. 之后,每次打开一个节点时,只需搜索它的上下左右是否打开,如果打开就把该节点加入打开的节点的集合即可. 需要注意的两点: 当n=1,2时的边界情况. 此时第一排和最后一排节点是同一个节点, 需要单独做处理. 倒灌的情况. 由于最后一排节点是相互联通的, 所以会发生倒灌情况. 解决方法是, 单独建立一个并查集, top节点连接方法不变, down节点不做连接. 这样, 查某节点有没有水只需要查是否和top节点连接即可. /** * Created by chestnutheng on 16-11-7. */ import edu.princeton.cs.algs4.WeightedQuickUnionUF; import java.lang.reflect.Array; import java.util.Arrays; import java.util.Scanner; public class Percolation { private WeightedQuickUnionUF uf; private WeightedQuickUnionUF uf_bk; private int size; private boolean [] isopen; public Percolation(int n){ if(n \u003c 1){ throw new IllegalArgumentException(); } //init this.size = n; this.uf = new WeightedQuickUnionUF(n*n + 2); this.uf_bk = new WeightedQuickUnionUF(n*n + 2); this.isopen = new boolean[n*n+2]; for(int i = 1; i \u003c n*n +1; ++i){ isopen[i] = false; } if(n == 1){ return; } //connect top-down for(int i = 1; i \u003c n + 1; ++i){ uf.union(0, i); uf_bk.union(0, i); } isopen[0] = true; for(int i = n*(n - 1) + 1; i \u003c n*n + 1; ++i){ uf.union(n*n + 1, i); } isopen[n*n + 1] = true; } // create n-by-n grid, with all sites blocked // open site (row, col) if it is not open already public void open(int row, int col){ if(row \u003e size || col \u003e size || row \u003c 1 || col \u003c 1){ throw new IndexOutOfBoundsException(); } if(size == 1){ uf.union(0,2); uf_bk.union(0,1); isopen[1] = true; return; } // search around and union int [] map_search; if (col == 1) map_search = new int[]{(row - 2)*size + col, row*size + col, (row - 1)*size + col + 1}; else if(col == size) map_search = new int[]{(row - 2)*size + col, row*size + col, (row - 1)*size + col - 1}; else map_search = new int[]{(row - 2)*size + col, row*size + col, (row - 1)*size + col - 1, (row - 1)*size + col + 1}; //System.out.println(Arrays.toString(map_search)); for (int v:map_search){ if(v \u003e 0 \u0026\u0026 v \u003c size*size + 1 \u0026\u0026 isopen[v]) { uf.union(v, (row - 1) * size + col); uf_bk.union(v, (row - 1) * size + col); } } isopen[(row - 1)*size + col] = true; } // is site (row, col) open? public boolean isOpen(int row, int col){ if(row \u003e size || col \u003e size || row \u003c 1 || col \u003c 1){ throw new IndexOutOfBoundsException(); } return isopen[(row - 1)*size + col]; } // is site (row, col) full? public boolean isFull(int row, int col){ if(row \u003e size || col \u003e size || row \u003c 1 || col \u003c 1){ throw new IndexOutOfBoundsException(); } return isopen[(row - 1)*size + col] \u0026\u0026 uf_bk.connected(0,(row - 1)*size + col); } // does the system percolate? public boolean percolates(){ return uf.connected(0, size*size + 1); } // test client (optional) public static void main(String[] args){ Scanner sc = new Scanner(System.in); int size = sc.nextInt(); int length = sc.nextInt(); Percolation pe=new Percolation(size); for(int i = 0; i \u003c length; ++i){ int m = sc.nextInt(); int n = sc.nextInt(); System.out.println(m + \",\" + n); pe.open(m, n); } System.out.println(pe.percolates()); //System.out.println(Arrays.toString(pe.uf.parent)); } } ","date":"2016-11-08","objectID":"/princeton_pa1_percolation/:1:0","tags":["普林斯顿算法公开课","算法","并查集"],"title":"[普林斯顿算法公开课]并查集解决渗透问题","uri":"/princeton_pa1_percolation/"},{"categories":["算法"],"content":"PercolationStats.java 第二个文件是PercolationStats.java, 用来模拟若干次随机渗透, 得到一些统计数据. 过程非常简单,只需每次open一个没有打开的点, 记录渗透的时候的开点数量即可. 需要注意的是, 置信区间的公式为 $$[\\overline{x} - \\frac{1.96s}{\\sqrt{T}}, \\overline{x} + \\frac{1.96s}{\\sqrt{T}}]$$ s 为标准差, T 为测试次数. 刚开始由于把T写成了size,所以test6没过!! =_= /** * Created by chestnutheng on 16-11-7. */ import edu.princeton.cs.algs4.StdRandom; import edu.princeton.cs.algs4.StdStats; import java.lang.reflect.Array; import java.util.Arrays; import java.util.Scanner; public class PercolationStats { private double []test_times_res; private double mean; private double dev; private int size; private int trials; // perform trials independent experiments on an n-by-n grid public PercolationStats(int n, int t){ if(n \u003c 1 || t \u003c= 0){ throw new IllegalArgumentException(); } size = n; trials = t; int test_times = 0; test_times_res = new double[trials]; while(test_times \u003c trials){ Percolation p = new Percolation(n); int count = 0; while(!p.percolates()){ int x,y; do{ x = StdRandom.uniform(size) + 1; y = StdRandom.uniform(size) + 1; }while (p.isOpen(x, y)); p.open(x, y); count++; } test_times_res[test_times] = (double)count/((double)n*(double)n); test_times++; } mean = StdStats.mean(test_times_res); dev = StdStats.stddev(test_times_res); } // sample mean of percolation threshold public double mean(){ return this.mean; } // sample standard deviation of percolation threshold public double stddev(){ return this.dev; } // low endpoint of 95% confidence interval public double confidenceLo(){ return this.mean-1.96*this.dev/Math.sqrt(trials); } // high endpoint of 95% confidence interval public double confidenceHi(){ return this.mean+1.96*this.dev/Math.sqrt(trials); } // test client public static void main(String[] args){ Scanner sc = new Scanner(System.in); int N = sc.nextInt(); int T = sc.nextInt(); PercolationStats p = new PercolationStats(N, T); System.out.println(\"mean = \" + p.mean()); System.out.println(\"stddev = \" + p.stddev()); System.out.println(\"95% confidence interval \" + p.confidenceLo() + \", \" + p.confidenceHi()); } } ","date":"2016-11-08","objectID":"/princeton_pa1_percolation/:2:0","tags":["普林斯顿算法公开课","算法","并查集"],"title":"[普林斯顿算法公开课]并查集解决渗透问题","uri":"/princeton_pa1_percolation/"},{"categories":["Python"],"content":"Python性能分析工具介绍, 包括内存和时间","date":"2016-08-09","objectID":"/python_profile/","tags":["Python","prof"],"title":"[Python]Python性能分析工具","uri":"/python_profile/"},{"categories":["Python"],"content":"时间分析 ","date":"2016-08-09","objectID":"/python_profile/:1:0","tags":["Python","prof"],"title":"[Python]Python性能分析工具","uri":"/python_profile/"},{"categories":["Python"],"content":"time 命令 用*nix自带的系统命令 $ time python3 reg.py real 0m1.617s user 0m1.504s sys 0m0.112s sys 系统调用时间 user 用户空间花费时间 real 实际时间 如果user + sys \u003c real 说明时间被花费在IO上。 ","date":"2016-08-09","objectID":"/python_profile/:1:1","tags":["Python","prof"],"title":"[Python]Python性能分析工具","uri":"/python_profile/"},{"categories":["Python"],"content":"profile和cProfile python自带了两个函数时间分析工具，cProfile和profile。cProfile是纯C写的，所以用起来快了很多。 查看帮助: $ python3 -m cProfile -h Usage: cProfile.py [-o output_file_path] [-s sort] scriptfile [arg] ... Options: -h, --help show this help message and exit -o OUTFILE, --outfile=OUTFILE Save stats to \u003coutfile\u003e -s SORT, --sort=SORT Sort order when printing to stdout, based on pstats.Stats class -o 输出的文件只能给pstats.Stats类使用。 -s 是对结果按照关键字排序，关键字有 calls, cumulative, file, line, module, name, nfl, pcalls, stdname, time 尝试分析一个测正则匹配次数的小程序： $ python3 -m cProfile -s time exp.py 4899025 function calls in 3.879 seconds Ordered by: internal time ncalls tottime percall cumtime percall filename:lineno(function) 1 1.583 1.583 3.879 3.879 exp.py:1(\u003cmodule\u003e) 1 0.777 0.777 0.859 0.859 {method 'readlines' of '_io._IOBase' objects} 2415450 0.720 0.000 0.720 0.000 {method 'search' of '_sre.SRE_Pattern' objects} 2415450 0.717 0.000 0.717 0.000 {method 'strip' of 'str' objects} 33967 0.048 0.000 0.048 0.000 {built-in method _codecs.utf_8_decode} 33967 0.033 0.000 0.082 0.000 codecs.py:318(decode) 1 0.000 0.000 0.000 0.000 {built-in method builtins.print} 1 0.000 0.000 0.000 0.000 {built-in method io.open} 1 0.000 0.000 0.000 0.000 sre_parse.py:491(_parse) 1 0.000 0.000 0.000 0.000 sre_compile.py:412(_compile_info) 1 0.000 0.000 0.000 0.000 sre_compile.py:531(compile) 1 0.000 0.000 0.000 0.000 re.py:278(_compile) 1 0.000 0.000 0.000 0.000 sre_parse.py:167(getwidth) 1 0.000 0.000 0.000 0.000 sre_compile.py:64(_compile) 15 0.000 0.000 0.000 0.000 sre_parse.py:226(__next) 65 0.000 0.000 0.000 0.000 {method 'append' of 'list' objects} 1 0.000 0.000 0.000 0.000 sre_compile.py:391(_generate_overlap_table) 14 0.000 0.000 0.000 0.000 sre_parse.py:247(get) 1 0.000 0.000 0.000 0.000 sre_parse.py:819(parse) 14 0.000 0.000 0.000 0.000 sre_parse.py:165(append) 1 0.000 0.000 0.000 0.000 sre_parse.py:217(__init__) 1 0.000 0.000 0.000 0.000 sre_parse.py:429(_parse_sub) 26 0.000 0.000 0.000 0.000 {built-in method builtins.len} ... 对结果做了运行时间的排序。输出的表格中 ncalls为函数运行次数 tottime为函数自身运行时间(不包括内部其他函数) percall为 tottime/ncalls cumtime为函数总运行时间（包括其他函数、递归） percall为 cumtime/ncalls ","date":"2016-08-09","objectID":"/python_profile/:1:2","tags":["Python","prof"],"title":"[Python]Python性能分析工具","uri":"/python_profile/"},{"categories":["Python"],"content":"line_profiler: 按行查看 安装: pip3 install line_profiler 安装后便可以使用kernprof分析性能, 先在要分析的函数上加修饰器@profile，然后运行: $ python3 -m kernprof -l -v exp.py 10 Wrote profile results to exp.py.lprof Timer unit: 1e-06 s Total time: 6.26415 s File: exp.py Function: main at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 @profile 2 def main(): 3 1 6 6.0 0.0 import re 4 1 673 673.0 0.0 reg = re.compile(r'DO_PATH_REPLAN') 5 1 1 1.0 0.0 count = 0 6 1 45 45.0 0.0 with open('log.46.log') as f: 7 2415451 2370592 1.0 37.8 for line in f.readlines(): 8 2415450 1674712 0.7 26.7 line = line.strip() 9 2415450 2218037 0.9 35.4 if reg.search(line) is not None: 10 10 6 0.6 0.0 count += 1 11 1 79 79.0 0.0 print(count) ","date":"2016-08-09","objectID":"/python_profile/:1:3","tags":["Python","prof"],"title":"[Python]Python性能分析工具","uri":"/python_profile/"},{"categories":["Python"],"content":"内存分析 ","date":"2016-08-09","objectID":"/python_profile/:2:0","tags":["Python","prof"],"title":"[Python]Python性能分析工具","uri":"/python_profile/"},{"categories":["Python"],"content":"memory_profiler 安装: pip3 install memory_profiler pip3 install psutil 同样，先在要分析的函数上加修饰器@profile，然后运行: $ python3 -m memory_profiler exp.py 10 Filename: exp.py Line # Mem usage Increment Line Contents ================================================ 1 14.891 MiB 0.000 MiB @profile 2 def main(): 3 14.891 MiB 0.000 MiB import re 4 14.891 MiB 0.000 MiB reg = re.compile(r'DO_PATH_REPLAN') 5 14.891 MiB 0.000 MiB count = 0 6 14.891 MiB 0.000 MiB with open('log.46.log') as f: 7 428.734 MiB 413.844 MiB for line in f.readlines(): 8 428.734 MiB 0.000 MiB line = line.strip() 9 428.734 MiB 0.000 MiB if reg.search(line) is not None: 10 428.734 MiB 0.000 MiB count += 1 11 15.250 MiB -413.484 MiB print(count) ","date":"2016-08-09","objectID":"/python_profile/:2:1","tags":["Python","prof"],"title":"[Python]Python性能分析工具","uri":"/python_profile/"},{"categories":["机器学习"],"content":"机器学习基石作业一, 机器学习感知机原理和实现","date":"2016-02-06","objectID":"/machine_learning_procetron/","tags":["机器学习","感知机"],"title":"[机器学习]感知机","uri":"/machine_learning_procetron/"},{"categories":["机器学习"],"content":"机器学习基石笔记 感知机 ","date":"2016-02-06","objectID":"/machine_learning_procetron/:0:0","tags":["机器学习","感知机"],"title":"[机器学习]感知机","uri":"/machine_learning_procetron/"},{"categories":["机器学习"],"content":"损失函数 给定一个数据集 $T ={(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)}$ , 其中 $x = R^n , , y={+1,-1}$ 若存在超平面S $w\\cdot x + b = 0$ 能将所有的正负实例点分到两侧，则称数据集是线性可分的，否则称线性不可分。 任意一点$x_0$到超平面的距离为 $$\\frac{1}{||w||}|w\\cdot x_0 + b|$$ 对于误分类数据$(x_i,y_i)$来说， $-y_i(w\\cdot x_i + b) \u003e 0$ 有误分类点到超平面距离 $$-\\frac{1}{||w||}y_i|w\\cdot x_0 + b|$$ 则所有误分类点到超平面距离为 $$-\\frac{1}{||w||}\\sum_{x_i \\in m }y_i|w\\cdot x_0 + b|$$ 所以感知机$sign(w\\cdot x + b)$学习损失函数为 $$L(w,b) = -\\sum_{x_i \\in m }y_i|w\\cdot x_0 + b|$$ ","date":"2016-02-06","objectID":"/machine_learning_procetron/:1:0","tags":["机器学习","感知机"],"title":"[机器学习]感知机","uri":"/machine_learning_procetron/"},{"categories":["机器学习"],"content":"学习算法 选取初值$w_0,b_0$ 在训练集中选取数据$(x_i,y_i)$ 如果$y_i(w\\cdot xi+ b) \\leq 0$（分类错误） $$w \\leftarrow w + x_iy_i$$ 转至2，直至没有误分类点。 ","date":"2016-02-06","objectID":"/machine_learning_procetron/:2:0","tags":["机器学习","感知机"],"title":"[机器学习]感知机","uri":"/machine_learning_procetron/"},{"categories":["机器学习"],"content":"收敛性 令$R=\\max || x_i || $ ， 令$\\rho = \\min \\frac{W_f}{||W_f||}x_iy_i$ 则有修正次数 $$k \\leq \\frac{R^2}{\\rho ^2}$$ 下面给出证明。 由 $$W_k \\cdot W_f = W_{k-1} W_f + x_i y_i \\geq W_{k-1} + \\rho \\geq \\cdots \\geq k \\rho$$ 得 $$||w_k||^2=||w_{k-1} + x_i y_i||^2=||w_{k-1}||^2 + 2w_{k-1}x_iy_i+||x_iy_i||^2 \\leq ||w_{k-1}||^2 +||x_iy_i||^2 \\leq ||w_{k-1}||^2 + R^2$$ 故 $$||w_k||^2\\leq ||w_{k-1}||^2 + R^2 \\leq \\cdots \\leq kR^2$$ 故 $$k \\rho \\leq w_k\\cdot w_f \\leq ||w_k|| \\cdot ||w_f|| \\leq ||w_k|| \\leq \\sqrt k R$$ 故 $k \\rho \\leq \\sqrt k R$,易得$k \\leq \\frac{R^2}{\\rho ^2}$，得证。 ","date":"2016-02-06","objectID":"/machine_learning_procetron/:3:0","tags":["机器学习","感知机"],"title":"[机器学习]感知机","uri":"/machine_learning_procetron/"},{"categories":["机器学习"],"content":"其他性质 一般用加上速度后的修正式：$ w \\leftarrow w + \\eta \\cdot x_iy_i$ 来修正直线。 读入数据的次序是影响修正次数的。 ","date":"2016-02-06","objectID":"/machine_learning_procetron/:4:0","tags":["机器学习","感知机"],"title":"[机器学习]感知机","uri":"/machine_learning_procetron/"},{"categories":["机器学习"],"content":"示范代码 import numpy as np def sign(x): if x \u003c 0: return -1 else: return 1 w = np.array([0.,0.,0.,0.,0.]) halts = 0 speed = 1 f = open('pla.dat') while True: data = f.readline() if data == '': break datas = data.split('\\t') xi = np.array([float(i) for i in ('1 ' + datas[0]).split()]) yi = float((datas[1].split())[0]) if not abs(yi) == 1 : exit(1) if not sign(np.inner(w,xi)) == yi: w = w + speed * yi * xi print(\"W: \" + str(w)) halts += 1 print('Halts :' + str(halts)) ","date":"2016-02-06","objectID":"/machine_learning_procetron/:5:0","tags":["机器学习","感知机"],"title":"[机器学习]感知机","uri":"/machine_learning_procetron/"},{"categories":["算法"],"content":"O(1)的最大值栈和最大值队列思路和实现","date":"2015-10-26","objectID":"/max_stack_and_max_queue/","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"最大值栈和最大值队列(Tsinghua OJ,PA2) ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:0:0","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"最大值栈 ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:1:0","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"要求 以O(1)的时间查询栈中的最大值. ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:1:1","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"思路 维护一个最大值栈，在原栈中数据发生改变时最大值栈也跟着改变。 每次输入一个数据，若最大值栈为空，则比较最大值栈栈顶和当前元素，如果当前元素较大或相等，就把当前元素推入栈中，反之出栈时，如果出栈元素和当前元素相等，则把最大值栈中元素也推出栈。 ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:1:2","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"实现 template \u003ctypename T\u003e class MaxStack { private: Stack \u003cT\u003e max_stack; Stack \u003cT\u003e _data; public: T max(){ return max_stack.top(); } void push(T ele){ _data.push(ele); if(max_stack.empty() || ele \u003e= max_stack.top()){ max_stack.push(ele); } } T pop(){ T tmp = _data.top(); if(_data.pop() == max_stack.top()){ max_stack.pop(); } return tmp; } }; ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:1:3","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"最大值队列 ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:2:0","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"要求 用o(n)时间查询队列的最大值 ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:2:1","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"思路 用两个最大值栈模拟队列。入队时把元素压入栈A，出队时弹出B的栈顶。（若B为空，则把A中元素全部弹出压入B再弹出）。取最大值时去A，B中的最大值的最大值。 ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:2:2","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"输入 第一行仅含一个整数，即高度查询和车辆出入操作的总次数n 以下n行，依次这n次操作。各行的格式为以下几种之一: E x //有一辆高度为x的车进入隧道（x为整数） D //有一辆车离开隧道 M //查询此时隧道中车辆的最大高度 ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:2:3","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"输出 若D和M操作共计m次，则输出m行 对于每次D操作，输出离开隧道车辆的高度 对于每次M操作，输出所查询到的最大高度 ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:2:4","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"实现 #include \"Stack.h\" #include \u003ciostream\u003e #include \u003ccstdio\u003e using namespace std; template \u003ctypename T\u003e class MaxStack { private: Stack \u003cT\u003e max_stack; Stack \u003cT\u003e _data; public: bool empty(){ return _data.empty(); } T max(){ return max_stack.top(); } void push(T ele){ _data.push(ele); if(max_stack.empty() || ele \u003e= max_stack.top()){ max_stack.push(ele); } } T pop(){ T tmp = _data.top(); if(_data.pop() == max_stack.top()){ max_stack.pop(); } return tmp; } T top(){ return _data.top(); } }; template \u003ctypename T\u003e class MaxQueue{ private: MaxStack \u003cT\u003e s1,s2; public: bool empty(){ return s1.empty() \u0026\u0026 s2.empty(); } void enqueue(T ele){ s1.push(ele); } T dequeue(){ if(s2.empty()){ while(!s1.empty()){ s2.push(s1.top()); s1.pop(); } } return s2.pop(); } T front(){ if(s2.empty()){ while(!s1.empty()){ s2.push(s1.top()); s1.pop(); } } return s2.top(); } T max(){ if((!s1.empty()) \u0026\u0026 (!s2.empty())) return (s1.max() \u003e s2.max() ? s1.max() : s2.max()); else if ((!s1.empty()) \u0026\u0026 (s2.empty())) return s1.max(); else return s2.max(); } }; int main(int argc, char const *argv[]) { MaxQueue \u003cint\u003equeue; int n; cin \u003e\u003e n; for (int i = 0; i \u003c n; ++i) { char op[2]; scanf(\"%s\", op); if (*op == 'E') { int num; cin \u003e\u003e num; queue.enqueue(num); } else if (*op == 'D') { printf(\"%d\\n\", queue.front()); queue.dequeue(); } else { printf(\"%d\\n\", queue.max());; } } return 0; } ","date":"2015-10-26","objectID":"/max_stack_and_max_queue/:2:5","tags":["队列","算法"],"title":"[算法]最大值栈和最大值队列","uri":"/max_stack_and_max_queue/"},{"categories":["算法"],"content":"逆序对计算问题","date":"2015-10-07","objectID":"/reversed_order/","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"逆序对计算的思考(Tsinghua OJ,PA1) 题目出自清华DSA的Programming Assignment作业灯塔(LightHouse)． ","date":"2015-10-07","objectID":"/reversed_order/:0:0","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"描述 海上有许多灯塔，为过路船只照明。 如图一所示，每个灯塔都配有一盏探照灯，照亮其东北、西南两个对顶的直角区域。探照灯的功率之大，足以覆盖任何距离。灯塔本身是如此之小，可以假定它们不会彼此遮挡。 若灯塔A、B均在对方的照亮范围内，则称它们能够照亮彼此。比如在图二的实例中，蓝、红灯塔可照亮彼此，蓝、绿灯塔则不是，红、绿灯塔也不是。 现在，对于任何一组给定的灯塔，请计算出其中有多少对灯塔能够照亮彼此。 ","date":"2015-10-07","objectID":"/reversed_order/:1:0","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"输入 共n+1行。 第1行为1个整数n，表示灯塔的总数。 第2到n+1行每行包含2个整数x, y，分别表示各灯塔的横、纵坐标。 ","date":"2015-10-07","objectID":"/reversed_order/:2:0","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"输出 1个整数，表示可照亮彼此的灯塔对的数量。 ","date":"2015-10-07","objectID":"/reversed_order/:3:0","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"样例 Input: 3 2 2 4 3 5 1 Output: 1 ","date":"2015-10-07","objectID":"/reversed_order/:4:0","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"限制 对于90%的测例：1 ≤ n ≤ 3×10^5 对于95%的测例：1 ≤ n ≤ 10^6 全部测例：1 ≤ n ≤ 4×10^6 灯塔的坐标x, y是整数，且不同灯塔的x, y坐标均互异 1 ≤ x, y ≤ 10^8 时间：2 sec 内存：256 MB ","date":"2015-10-07","objectID":"/reversed_order/:5:0","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"提示 注意机器中整型变量的范围，C/C++中的int类型通常被编译成32位整数，其范围为[-231, 231 - 1]，不一定足够容纳本题的输出。 ","date":"2015-10-07","objectID":"/reversed_order/:6:0","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"思考 我们把灯塔坐标抽象为坐标结构体 typedef struct pos{ long x,y; }Pos; 照亮的情况为一个灯塔在另一个灯塔的一四象限，即$tower1.x - tower2.x$与$tower1.y - tower2.y$同号． 思路一：通过检测每个元素和其他元素的配对情况解决．简单计算知时间复杂度 $$1 + 2 + 3 + \\dots + (n-1) = O(n^2) $$ 思路二：利用二维线段树求解 思路三：利用逆序对求解． 具体思路为先对Ｘ坐标排序，则排好序的数组中一定有$tower_pre.x \u003c tower_suc.x$ 只要统计Ｙ坐标中前面的元素Ｙ坐标比后面的元素小的即可．则不难得到 $$ X_y,Y_y逆序　\\Leftrightarrow X,Y 互不可照亮$$ $$ans = n(n-1)-\\tau(y_1y_2y_3\\dots y_n)$$ 如图，Ｘ已经排好序，Ｙ坐标为{2,1,3,4} 逆序对数量为１＋０＋０＋０＝１ 总对数N(N - 1)对，其中不可照亮的有１对，可照亮的有N(N - 1) - 1 = 5对． ","date":"2015-10-07","objectID":"/reversed_order/:7:0","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"代码实现 经过多次优化，把 $4\\times10^6$ 的用例用1.3s　A掉了． #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003ctime.h\u003e #include \u003cmath.h\u003e #include \u003csys/time.h\u003e #include \u003cctype.h\u003e //#define DBG_FLAG //检测用时 #define ISDIGIT(ch) (ch \u003e= '0' \u0026\u0026 ch \u003c= '9') long long detect; long long start_time; typedef struct pos //灯塔结构体 { long x,y; }Pos; typedef struct parser_ {　//解释器，用于快速IO char *buf; int pos; } Parser; void read_line(Parser *parser, char *buffer) { gets(buffer); parser-\u003ebuf = buffer; parser-\u003epos = 0; } void read_all(Parser *parser, char *buffer) { long sz = 0; long readed; repeat: readed = fread(buffer + sz, 1, 100*1024*1024, stdin); //100M的缓冲区,一次读完数据 if (readed == 0) { buffer[sz] = '\\0'; goto final; } sz += readed; goto repeat; final: parser-\u003ebuf = buffer; parser-\u003epos = 0; } inline long parse_long(Parser *parser) { while(!(ISDIGIT(parser-\u003ebuf[parser-\u003epos]) || parser-\u003ebuf[parser-\u003epos] == '-')) { parser-\u003epos++; } long ret = 0; int sign = 0; if (parser-\u003ebuf[parser-\u003epos] == '-') { sign = 1; parser-\u003epos++; } while(ISDIGIT(parser-\u003ebuf[parser-\u003epos])) { ret = ret * 10 + (parser-\u003ebuf[parser-\u003epos] - '0'); parser-\u003epos++; } if (sign) { return -ret; } return ret; } Pos *temp; inline int compare(const void *p1, const void *p2) { //本来在Qsort中用的比较函数 return (*(Pos*)p1).x - (*(Pos*)p2).x; } long get_tick_count() { #ifdef DBG_FLAG struct timeval tv; gettimeofday(\u0026tv, NULL); return tv.tv_sec * 1000 + tv.tv_usec / 1000; #else return 0; #endif } long read_long() { long ret = 0; while(1) { int ch = fgetc(stdin); if (isdigit(ch)) { ungetc(ch, stdin); break; } } while(1) { int ch = fgetc(stdin); if (isdigit(ch)) { ret = ret * 10 + (ch - '0'); } else { return ret; } } } void debug_time(const char *msg) { #ifdef DBG_FLAG FILE *fp = fopen(\"time.log\", \"a\"); fprintf(fp, \"[%lld] %s\\n\", get_tick_count() - start_time, msg); fclose(fp); #endif } inline long merge(Pos *array,int low,int mid,int high) { int i = low,j = mid+1,k = low; long count = 0; while(i \u003c= mid \u0026\u0026 j \u003c= high) if(array[i].y \u003c= array[j].y) { temp[k++] = array[i++]; } else{ temp[k++] = array[j++]; count += j-k; //逆序数计算 } while(i \u003c= mid) temp[k++] = array[i++]; while(j \u003c= high) temp[k++] = array[j++]; long long st = get_tick_count(); memcpy(array + low, temp + low, (high - low + 1) * sizeof(Pos)); //复制数组的优化 detect += (get_tick_count() - st); return count; } long mergeSort(Pos *array,int lo,int hi) { if(lo\u003chi) { int mid=(lo+hi)\u003e\u003e1; long count=0; count += mergeSort(array,lo,mid); count += mergeSort(array,mid+1,hi); count += merge(array,lo,mid,hi); return count; } return 0; } void QuickSort(Pos *data, int low, int high) { //手写快排的优化 if (low \u003e= high) { return; } int pivot_item = low + rand() % (high - low + 1); Pos swp; swp = data[pivot_item]; data[pivot_item] = data[high]; data[high] = swp; Pos pivot = data[high]; int i, j; i = low; for (j = low; j \u003c high; ++j) { if (data[j].x \u003c= pivot.x) { swp = data[i]; data[i] = data[j]; data[j] = swp; i++; } } swp = data[i]; data[i] = data[high]; data[high] = swp; QuickSort(data, low, i - 1); QuickSort(data, i + 1, high); } int main() { srand(time(NULL)); detect = 0; start_time = get_tick_count(); Pos * data = (Pos *)malloc(sizeof(Pos)*4000099); //数据区 debug_time(\"ALLOC.\"); int i; int t = 0; long n = 0; long ms; char *all_buf; all_buf = (char*)malloc(100*1024*1024); //缓冲区 Parser parser; read_all(\u0026parser, all_buf); debug_time(\"RALL.\"); n = parse_long(\u0026parser); Pos *pointer, *pend = data + n; for (pointer = data; pointer != pend; ++pointer) { //用解释器读取数据 pointer-\u003ex = parse_long(\u0026parser); pointer-\u003ey = parse_long(\u0026parser); } free(all_buf); debug_time(\"READ.\"); QuickSort(data, 0, n - 1); // qsort(data,n,sizeof(Pos),compare); #ifdef DBG_FLAG FILE *opt = fopen(\"sorted.txt\", \"w\"); for (pointer = data; pointer != pend; ++pointer) { fprintf(opt, \"%ld %ld\\n\", pointer-\u003ex, pointer-\u003ey); } fclose(opt); #endif debug_time(\"SORT.\"); temp = (Pos *)malloc(sizeof(Pos)*4000099); ms = n*(n-1)/2 - mergeSort(data,0,n - 1); printf(\"%ld\\n\",ms); #ifdef DBG_FLAG printf(\"%lld\\n\", detect); #endif deb","date":"2015-10-07","objectID":"/reversed_order/:8:0","tags":["排序","逆序对","算法"],"title":"[算法]逆序对计算的思考","uri":"/reversed_order/"},{"categories":["算法"],"content":"算法导论习题, DP解决钢条切割问题","date":"2015-06-01","objectID":"/max_iron_len/","tags":["动态规划","算法","DFS"],"title":"[算法]DP解决钢条切割问题","uri":"/max_iron_len/"},{"categories":["算法"],"content":"DP解决钢条切割问题 （原题见算法导论·动态规划） 对长度为n的钢条进行切割，对应的切割长度和价格对应如下： int cost[] = {0, 1, 5, 8, 9, 10, 17, 17, 20, 24, 30}; 比如1对应价值1,10对应价值30。即相应的下标和值的对应。现求切割所得最大效益mx。 ","date":"2015-06-01","objectID":"/max_iron_len/:0:0","tags":["动态规划","算法","DFS"],"title":"[算法]DP解决钢条切割问题","uri":"/max_iron_len/"},{"categories":["算法"],"content":"递归算法 int cut_rod(int *cost,int n) { if(n == 0) return 0; int limit = MIN(n,10); //分割第一条的上限 int mx = -1; for(int i = 1;i \u003c= limit; ++i) mx = maxnum(mx,cost[i]+cut_rod(cost,n-i)); //取当前值于递归值的最大值 return mx; } 由于对相同子问题的重复求解，T(n) = 2^n ","date":"2015-06-01","objectID":"/max_iron_len/:1:0","tags":["动态规划","算法","DFS"],"title":"[算法]DP解决钢条切割问题","uri":"/max_iron_len/"},{"categories":["算法"],"content":"递归标记数组算法（自顶而下）（DFS） int mem_cut_rod(int *cost,int n,int *mem) //mem数组长度为n,所有元素须在其他函数中初始化为-1 { int mx; if (mem[n] \u003e= 0) return mem[n]; //对于求过的问题，直接返回存储的值 if (n == 0) mx = 0; else mx = -1; int limit = MIN(n,10); for(int i = 1;i \u003c= limit; ++i) mx = maxnum(mx,cost[i]+mem_cut_rod(cost,n-i,mem)); //后面的内容和递归型是一样的 mem[n] = mx; //储存计算出的新值 return mx; } ","date":"2015-06-01","objectID":"/max_iron_len/:2:0","tags":["动态规划","算法","DFS"],"title":"[算法]DP解决钢条切割问题","uri":"/max_iron_len/"},{"categories":["算法"],"content":"逆拓扑序DP（自底向上） int bottom_cut_rod(int *cost,int n) { int mem[MEM_LEN+1]; //MEM_LEN = n，设置标记数组 mem[0] = 0; //i,j将从1开始，这里收益是0 for(int i = 1; i \u003c= n; ++i) //从第一个问题开始求解 { int mx = -1; int limit = MIN(i,10); for(int j = 1;j \u003c= limit; ++j) mx = maxnum(mx,cost[j] + mem[i-j]); //求解最小的问题 mem[i] = mx; } return mem[n]; } 我们可以看到，2,3 的解法复杂度均为O(n^2)。 ","date":"2015-06-01","objectID":"/max_iron_len/:3:0","tags":["动态规划","算法","DFS"],"title":"[算法]DP解决钢条切割问题","uri":"/max_iron_len/"},{"categories":["算法"],"content":"带解决方案的DFS typedef struct { string path; //方案路径 bool memoried; int value; } MEMORY; MEMORY *mem_pool; string num_to_str(int num) { char buf[120]; sprintf(buf, \"%d\", num); return string(buf); } MEMORY DFS(int remain) { int select, limit = MIN(remain, COST_LEN), mx = -1, cur_cost; string cur_path, mx_path; if (mem_pool[remain - 1].memoried) { return mem_pool[remain - 1]; } for (select = 1; select \u003c= limit; ++select) { if (select == remain) { cur_cost = cost[remain]; cur_path = num_to_str(remain); } else { MEMORY upper = DFS(remain - select); cur_cost = cost[select] + upper.value; cur_path = num_to_str(select) + \", \" + upper.path; } if (cur_cost \u003e mx) { mx = cur_cost; mx_path = cur_path; } } mem_pool[remain - 1].memoried = true; mem_pool[remain - 1].value = mx; mem_pool[remain - 1].path = mx_path; return mem_pool[remain - 1]; } int main() { int n, i; cin \u003e\u003e n; mem_pool = new MEMORY[n]; if (!mem_pool) { return 1; } for (i = 0; i \u003c n; ++i) { mem_pool[i].memoried = false; } MEMORY result = DFS(n); cout \u003c\u003c result.value \u003c\u003c endl; cout \u003c\u003c result.path \u003c\u003c endl; delete[] mem_pool; return 0; } ","date":"2015-06-01","objectID":"/max_iron_len/:4:0","tags":["动态规划","算法","DFS"],"title":"[算法]DP解决钢条切割问题","uri":"/max_iron_len/"},{"categories":["算法"],"content":"其他代码 最后我们附上一份c实现的代码： //2015.6.2 //copyright XJSoft #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003cstdbool.h\u003e typedef struct { bool memoried; int value; } MEMORY; int cost[] = {0, 1, 5, 8, 9, 10, 17, 17, 20, 24, 30}; MEMORY *mem_pool; #define COST_LEN 10 #define MIN(a,b) ((a)\u003c(b)?(a):(b)) int maxnum(const int v1,const int v2) { if (v1 \u003e v2) return v1; else return v2; } int DFS(int remain) { int select, limit = MIN(remain, COST_LEN), mx = -1, cur_cost; if (mem_pool[remain - 1].memoried) { return mem_pool[remain - 1].value; } for (select = 1; select \u003c= limit; ++select) { if (select == remain) { cur_cost = cost[remain]; } else { cur_cost = cost[select] + DFS(remain - select); } if (cur_cost \u003e mx) { mx = cur_cost; } } mem_pool[remain - 1].memoried = true; mem_pool[remain - 1].value = mx; return mx; } int DP(int n) { int remain, select, limit, mx, cur_cost; for (remain = 1; remain \u003c= n; ++remain) { mx = -1; limit = MIN(remain, COST_LEN); for (select = 1; select \u003c= limit; ++select) { if (select == remain) { cur_cost = cost[select]; } else { cur_cost = cost[select] + mem_pool[remain - select - 1].value; } if (cur_cost \u003e mx) { mx = cur_cost; } } mem_pool[remain - 1].value = mx; } return mem_pool[n - 1].value; } int main() { int n, i; scanf(\"%d\", \u0026n); mem_pool = (MEMORY*)malloc(n * sizeof(MEMORY)); if (!mem_pool) { printf(\"Mem error!\\n\"); return 1; } for (i = 0; i \u003c n; ++i) { mem_pool[i].memoried = false; } printf(\"%d\\n\", DP(n)); free(mem_pool); return 0; } ","date":"2015-06-01","objectID":"/max_iron_len/:5:0","tags":["动态规划","算法","DFS"],"title":"[算法]DP解决钢条切割问题","uri":"/max_iron_len/"},{"categories":null,"content":"数据输入 支付宝账头（16） 交易号 商家订单号 交易创建时间 付款时间 最近修改时间 交易来源地 类型 交易对方 商品名称 金额（元） 收/支 交易状态 服务费（元） 成功退款（元） 备注 资金状态 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 2023053122001420431448709679 visionpayF57BE6520BB10FD2D6878368 2023-05-3115:15:28 2023-05-3115:15:30 2023-05-3115:15:30 其他（包括阿里巴巴和外部商家） 即时到账交易 友宝 智能货柜消费 2.10 支出 交易成功 0.00 0.00 微信账头（11） 交易时间 交易类型 交易对方 商品 收/支 金额(元) 支付方式 当前状态 交易单号 商户单号 备注 0 1 2 3 4 5 6 7 8 9 10 2023-05-31 14:55:08 商户消费 easyopen “easyopen充值” 支出 ¥10.00 招商银行(8027) 支付成功 4200001853202305316421439877 02212305315369551305344 “/” 主要功能 ","date":"0001-01-01","objectID":"/drafts/docs/wudao-money-%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/:0:0","tags":null,"title":"","uri":"/drafts/docs/wudao-money-%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/"},{"categories":null,"content":"统一账务格式 标准账务格式 交易时间 账务号 收/支 交易对方 商品 金额(元) 商户单号 类目 科目 回款账务号 0 1 2 3 4 5 6 7 8 9 2023-05-31 14:55:08 ZW0001 收入/支出 盒马/姓名/Vita 群收款/滴滴 ¥10.00 112233 交通出行 [云南,旅游] / ","date":"0001-01-01","objectID":"/drafts/docs/wudao-money-%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/:1:0","tags":null,"title":"","uri":"/drafts/docs/wudao-money-%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/"},{"categories":null,"content":"匹配类目 一级类目不可以重复，只能归到某一类。用于分析花销的组成 吃喝（零食、饮料、本地生活） 文娱（门票、剧场、音乐节、会员） 服饰鞋帽 车船机酒（打车、租车、火车、飞机、酒店） 个护家清（护肤、发型、护理、卫生、摆件、花卉） 美妆 房租 游戏（游戏、充值） 母婴宠物 3C数码 烟酒 运动户外 红包转账 零用（小于50元的未归类项目） 医疗保健 图书学习 第一遍：粗筛，争取全部匹配到标签，讲究覆盖率 第二遍：纠错，把错误的标签匹配回来，讲究准确率 比如，“猫咪英雄”这个游戏，粗筛-\u003e母婴宠物，纠错-\u003e游戏娱乐 ","date":"0001-01-01","objectID":"/drafts/docs/wudao-money-%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/:2:0","tags":null,"title":"","uri":"/drafts/docs/wudao-money-%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/"},{"categories":null,"content":"匹配科目 科目用于解决专项的统计问题。 科目可以任意添加，比如一条云南的打车记录，同时属于云南旅游、旅游几个科目 系统自动添加的科目 大额消费（\u003e=198） 摄影 自己添加的科目 旅游A ","date":"0001-01-01","objectID":"/drafts/docs/wudao-money-%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/:3:0","tags":null,"title":"","uri":"/drafts/docs/wudao-money-%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/"},{"categories":null,"content":"功能 - 你会获得什么？ 记账自动分类，将你的 使用 解压后，寻找自己的操作系统对应的版本。注意不要把配置json删除 -rwxr-xr-x 1 chestnutheng staff 6.0M 6 28 19:59 GoldenKey_Linux_amd64 -rwxr-xr-x 1 chestnutheng staff 5.9M 6 28 19:59 GoldenKey_Mac_amd64 -rwxr-xr-x 1 chestnutheng staff 5.8M 6 28 19:59 GoldenKey_Windows_386.exe -rwxr-xr-x 1 chestnutheng staff 6.1M 6 28 19:59 GoldenKey_Windows_amd64.exe -rw-r--r-- 1 chestnutheng staff 3.7K 6 28 19:59 golden_conf.json 使用解压好的文件。直接双击或者命令行运行 Ξ money/ ▶ ./GoldenKey_Mac_amd64 2023/06/28 20:41:26 导入记录为0。请将导入的支付宝或者微信账单文件放在同目录！ 如果需要解析账单，需要把账单文件放入文件夹。 微信下载账单： 支付宝下载账单：https://consumeprod.alipay.com/record/standard.htm 个人版 - 选择开始日期到1月1日 - 下载明细 解压下载好的zip文件，和GoldenKey放入同级文件夹，如下图 Ξ tiny_projects/money ▶ tree . . ├── GoldenKey_Mac_amd64 ├── golden_conf.json ├── alipay_record_20230621_1123_1.csv ├── alipay_record_20230628_1735_1.csv ├── 微信支付账单(20230401-20230531).csv 运行GoldenKey，你会发现目录下生成了几个文件 . ├── GoldenKey_Mac_amd64 ├── golden_conf.json ├── alipay_record_20230621_1123_1.csv ├── alipay_record_20230628_1735_1.csv ├── 微信支付账单(20230401-20230531).csv ├── bill_fix.csv ├── bills.csv ├── 账单管理结果_20210101_20230531.xlsx 账单管理结果 就是你要的文件！ ","date":"0001-01-01","objectID":"/drafts/docs/wudao_money_readme/:0:0","tags":null,"title":"","uri":"/drafts/docs/wudao_money_readme/"},{"categories":null,"content":"$$ \\lim_{n \\to \\infty} \\sum_{k=1}^n \\frac{1}{k^2} = \\frac{\\pi^2}{6} \\qquad {for,all\\quad }x\\in \\mathbb{R} $$ $\\heartsuit$ $$\\sqrt[3] {2+3}$$ $$\\underbrace{a+b+\\cdots+z}_{26}$$ $$\\widehat{adfdsfsaf}$$ $$\\hat{x}\\overline{x}$$ $$[\\overline{x} - \\frac{1.96s}{\\sqrt{T}}]$$ $$y’’’’’’ = 4 \\csc\\sinh \\inf \\ \\liminf_{x \\rightarrow 0} \\liminf$$ $$x^{1/2} \\frac{yy}{xx} \\binom{n}{k}C^m_k $$ $$\\mathrm{C}^m_k $$ $$\\sum_{n=0}^k \\prod_{i=1}^n$$ $$x{\\Big{\\frac{\\frac{1}{2}}{x}\\Big}y}^3$$ $$\\left| \\begin{array}{} x_{11} \u0026 x_{12} \u0026 \\ldots \\ x_{21} \u0026 x_{22} \u0026 \\ldots \\ \\vdots \u0026 \\vdots \u0026 \\ddots \\end{array} \\right|$$ $$\\displaystyle ddd\\scriptstyle ttt\\scriptscriptstyle aa$$ $$\\times \\leq \\geq \u003e \u003c \\sim \\subset \\subseteq \\supset \\in \\notin \\Leftrightarrow \\pm \\div \\approx \\cdot$$ $$T(n) = \\left{ \\begin{array}{ll} \\Theta(1) \\ 2T(\\frac{n}{2}) + \\Theta(n) \\end{array} \\right. $$ $$\\begin{array} yy = \\left{ \\begin{array}{ll} a \u0026 \\textrm{if $d\u003ec$}\\ b+x \u0026 \\textrm{in the morning}\\ l \u0026 \\textrm{all day long} \\end{array} \\right. \\end{array}$$ ","date":"0001-01-01","objectID":"/drafts/latex/:0:0","tags":null,"title":"","uri":"/drafts/latex/"},{"categories":null,"content":"队列是最方便的线程间传递信息的方式。线程间传递信息，难免会引入锁，锁又会带来效率的大幅降低。我们从一个简单的队列开始，看看lock-free的思维如何解决问题。 加锁的队列 ","date":"0001-01-01","objectID":"/drafts/lock_free/:0:0","tags":null,"title":"","uri":"/drafts/lock_free/"},{"categories":null,"content":"api回顾 回顾一下互斥锁和条件变量的用法： // 锁：是互斥的。一个线程加锁后其他线程如果试图加锁，会陷入等待。 pthread_mutex_t mutex; //锁 // 给互斥体变量加锁，其他线程执行这里时会卡住 pthread_mutex_lock(\u0026mutex); // 给互斥体变量解除锁 phtread_mutex_unlock(\u0026mutex); // 条件变量：用条件控制线程是否继续。条件变量不是卡别人的，使用条件卡自己的，等待别人告诉自己可以继续。 pthread_cond_t qready = PTHREAD_COND_INITIALIZER; pthread_mutex_t qlock = PTHREAD_MUTEX_INITIALIZER; // wait用来等待条件就绪。如果陷入wait，只能通过别的线程被唤醒。一般情况下，wait会配合while和需要wait的条件使用，避免假死和资源竞争等问题 pthread_cond_wait(\u0026qready, \u0026mutex); // signal可以通知一个线程条件已经就绪 pthread_cond_signal(\u0026qready) // broadcast会通知所有线程就绪。这种通知是顺序进行的，因为只有一个线程可以拿到wait时指定的锁，然后执行完自己的操作，最后unlock，把锁让给下一个线程 pthread_cond_broadcast(\u0026qready) 我们可以根据这个用法写一个模板： void thread1(){ pthread_mutex_lock(\u0026lock); while(不满足条件，比如队列为空、文件未就绪) pthread_cond_wait(\u0026cond, \u0026lock); // ... 得到条件了，做一些事情，比如操作文件、推出队列的东西 pthread_mutex_unlock(\u0026lock); } ","date":"0001-01-01","objectID":"/drafts/lock_free/:1:0","tags":null,"title":"","uri":"/drafts/lock_free/"},{"categories":null,"content":"加锁队列的实现 // 是否为空 template \u003ctypename T\u003e bool BlockingQueue\u003cT\u003e::IsEmpty(){ bool rv; g_mutex_lock(m_mutex); rv = m_theQueue.empty(); g_mutex_unlock(m_mutex); return rv; } // 推出元素 template \u003ctypename T\u003e bool BlockingQueue\u003cT\u003e::Push(const T \u0026a_elem){ g_mutex_lock(m_mutex); // 如果队列已满，则等待，直到队列空出位置 while (m_theQueue.size() \u003e= m_maximumSize){ g_cond_wait(m_cond, m_mutex); } bool queueEmpty = m_theQueue.empty(); m_theQueue.push(a_elem); // 如果队列push之前为空，通知其余线程可以继续push if (queueEmpty){ // wake up threads waiting for stuff g_cond_broadcast(m_cond); } g_mutex_unlock(m_mutex); return true; } template \u003ctypename T\u003e void BlockingQueue\u003cT\u003e::Pop(T \u0026out_data){ g_mutex_lock(m_mutex); // 队列为空则陷入等待，直到队列有元素 while (m_theQueue.empty()){ g_cond_wait(m_cond, m_mutex); } bool queueFull = (m_theQueue.size() \u003e= m_maximumSize) ? true : false; out_data = m_theQueue.front(); m_theQueue.pop(); // 如果队列已经满了，通知其他线程来pop if (queueFull){ // wake up threads waiting for stuff g_cond_broadcast(m_cond); } g_mutex_unlock(m_mutex); } 我们举个例子： 队列m_maximumSize为10 连续push 20个消息，后面的10个push线程会卡住在wait 连续pop 10个消息，此时10个消息被pop出去，还有10个push线程卡死在wait（假设pop时有新的push，新的push会直接push进去） 此时队列为空，新来的pop卡死；之前步骤2卡死在push的线程都会被依次唤醒，push直到队列满 CAS实现的队列 https://www.codeproject.com/Articles/153898/Yet-another-implementation-of-a-lock-free-circul ","date":"0001-01-01","objectID":"/drafts/lock_free/:2:0","tags":null,"title":"","uri":"/drafts/lock_free/"},{"categories":null,"content":"CAS回顾 volatile int a; a = 1; // a不等于1的时候会一直循环 // a等于1的时候a会被赋值为2，并返回true while (!CAS(\u0026a, 1, 2)){ ; } ","date":"0001-01-01","objectID":"/drafts/lock_free/:3:0","tags":null,"title":"","uri":"/drafts/lock_free/"},{"categories":null,"content":"时序图 状态机 @startuml 待补贴 --\u003e 待一审 : 设置补贴 [*] --\u003e 待一审 : 设置补贴 待一审 : [强]保存货补记录 待一审 : [弱]更新ES数据 待一审 : [强]占用预算 待一审 --\u003e 补贴成功 : 审核通过a 补贴成功 : [强]保存货补记录 补贴成功 : [弱]更新ES数据（仅a） 补贴成功 : [强]通知报名审核成功（仅a） 待一审 --\u003e 待高阶审核: 发起高阶审核 待高阶审核 : [强]保存货补记录 待高阶审核 : [弱]更新ES数据 待高阶审核 : [强]发起bpm审核 待高阶审核 --\u003e 待补贴: 高阶审核拒绝 待一审 --\u003e 待补贴: 审核拒绝 待补贴 : [强]保存货补记录 待补贴 : [弱]更新ES数据 待补贴 : [强]释放预算信息 待补贴 : [强]通知报名审核拒绝 待一审 --\u003e 已取消: 报名系统取消 待补贴 --\u003e 已取消: 报名系统取消 待高阶审核 --\u003e 已取消: 报名系统取消 补贴成功 --\u003e 已取消: 报名系统取消 已取消 : [强]保存货补记录 已取消 : [弱]更新ES数据 已取消 : [强]释放预算信息 已取消 : [强]通知报名审核取消 已取消 : [强]取消高阶审核bpm 补贴成功 --\u003e 补贴成功: 修改报名信息b 补贴成功 --\u003e 补贴成功: 修改补贴/修改库存c 补贴成功 : [强]释放预算信息（仅c） @enduml ","date":"0001-01-01","objectID":"/drafts/plant-uml-%E7%A4%BA%E4%BE%8B/:0:0","tags":null,"title":"","uri":"/drafts/plant-uml-%E7%A4%BA%E4%BE%8B/"},{"categories":null,"content":"设计理念 构建一套事件监测、规则匹配、发送的系统 HK0700到达卖出点 -\u003e 发送邮件消息 触发器cron：分钟级扫描 值组件：price1=GetStockPrice(code1) 发射器：sendEmail() 规则引擎：if price1 \u003e conf1 : sendEmail() 聚合引擎：当日不再发 flight到达低点or日报 -\u003e 发送邮件消息 触发器cron：早晚扫描 值组件：priceList=GetFlight(A, B, day) 发射器：sendEmail() 规则引擎：if priceList0 \u003c conf1 : sendEmail() cron表达式： */10 * * * * 执行动作：getFlight 参数列表：杭州 北京 2023-08-08 规则：price[0] \u003c 1000 发射器： sendEmail { \"rule_name\" : \"杭州-北京flights监控\", \"crontab\" : \"*/10 * * * *\", \"event\" : \"getFlight\", \"params\" : [\"杭州\",\"北京\",\"2023-08-08\"], \"rule\" : { \"key\" : \"min_price\", \"val\" : \"1000\", \"op\" : \"\u003c\" }, \"action\" : \"sendEmail\" } // getFlight回包 { \"min_price\" : 1000.0 } ","date":"0001-01-01","objectID":"/drafts/push-x/:0:0","tags":null,"title":"","uri":"/drafts/push-x/"},{"categories":null,"content":" 车架 轮组 变速套件 组成 变速系统1：手变/指拨，前拨变速器，后拨变速器 传动系统2：牙盘，中轴，飞轮，链条 制动系统3：花鼓，刹车 小套（变速）中套（变速+传动）大套（变速+传动+制动） 品牌 禧玛诺shimano（最大） 速联sram campagnolo 牙盘：靠近脚的齿轮 飞轮：靠近后轮的齿轮 齿比：齿比=牙盘齿轮数/飞轮齿轮数=蹬一圈走几圈 9速为例 场景 小牙盘1 中牙盘2 大牙盘3 齿比 陡坡 1-2 ❎ ❎ 0.7~0.8 普通坡 3-5 2-3 ❎ 0.9~1.2 平路 5 3-6 3-5 1.3~2.1 下坡 ❎ ❎ 5-7 2.4~3.1 禧玛诺 系列 定位 型号 速度 重量 价格 备注 Claris 入门 R2000 8速 2942g 2000+ 4爪牙盘 双盘、三盘 SORA 娱乐 R3000 9速 2787g 3000+ 4爪牙盘、一体式中轴 TIAGR 娱乐入门 R4600 R4700 10速 2840g 4000+ 105级套件 比赛入门 R7000 11速 2576g 6000+ 一步到位 Ultegra 比赛 R8000 11速 2376g 15000+ 油压碟刹/Di2电子变速 Dura-Ace 专业比赛 R9000 11速 2011g 30000+ 圈刹/碟刹/机械变速/Di2电子变速 ","date":"0001-01-01","objectID":"/drafts/%E5%85%AC%E8%B7%AF%E8%BD%A6%E5%90%8D%E8%AF%8D/:0:0","tags":null,"title":"","uri":"/drafts/%E5%85%AC%E8%B7%AF%E8%BD%A6%E5%90%8D%E8%AF%8D/"},{"categories":null,"content":"增加 local key = KEYS[1] local val = tonumber(ARGV[1]) local upper = tonumber(ARGV[2]) local expireAt = tonumber(ARGV[3]) local cur = redis.call('get',key) if(cur == false) then cur = 0 else cur = tonumber(cur) end if(cur \u003e= upper) then return 0 end local new = cur + val if(new \u003e upper) then new = upper end redis.call('set',key,new) redis.call('expireat',key,expireAt) return new - cur 减少 local key = KEYS[1] local val = tonumber(ARGV[1]) local lower = tonumber(ARGV[2]) local expireAt = tonumber(ARGV[3]) local cur = redis.call('get',key) if(cur == false) then cur = 0 else cur = tonumber(cur) end if(cur \u003c= lower) then return 0 end local new = cur - val if(new \u003c lower) then new = lower end redis.call('set',key,new) redis.call('expireat',key,expireAt) return new - cur ","date":"0001-01-01","objectID":"/drafts/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E6%95%B0%E5%99%A8/:0:0","tags":null,"title":"","uri":"/drafts/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E6%95%B0%E5%99%A8/"},{"categories":null,"content":"幂等处理 ","date":"0001-01-01","objectID":"/drafts/%E5%B9%82%E7%AD%89/:0:0","tags":null,"title":"","uri":"/drafts/%E5%B9%82%E7%AD%89/"},{"categories":null,"content":"作用 幂等的作用：防止重复操作导致的脏数据 前端防抖 接口超时重试 消息重试 我们的upsert、分布式锁、乐观锁、for update、唯一索引、状态机其实都有幂等的功能，会在请求重复的时候报错。我们主要讨论在这些机制之外，用户自定义幂等键的时候的情形 ","date":"0001-01-01","objectID":"/drafts/%E5%B9%82%E7%AD%89/:1:0","tags":null,"title":"","uri":"/drafts/%E5%B9%82%E7%AD%89/"},{"categories":null,"content":"维度 接口维度的幂等：幂等的控制交给下游，由下游保证自己的请求是可以幂等/不被幂等的。比如下游直接传一个md5sum(req)作为幂等键进来（其他常用的包括req里的核心参数、reqid、时间戳、消息id） 幂等键一致：直接幂等。问题：下游可能传错了，不幂等的也结果被幂等，比如批量请求、同一个请求里发起多次请求等 幂等键不一致：不幂等，这个不会出错 数据维度的幂等：采用数据库的uniq key+幂等键联合判断 uk一致，幂等键不一致：说明用户希望再次操作同一个数据实体，不幂等 uk不一致，幂等键一致：说明用户希望再次操作其他数据实体，不幂等 uk、幂等键都一致：直接幂等 uk、幂等建都不一致：不幂等 ","date":"0001-01-01","objectID":"/drafts/%E5%B9%82%E7%AD%89/:2:0","tags":null,"title":"","uri":"/drafts/%E5%B9%82%E7%AD%89/"},{"categories":null,"content":"实现 实现方法： 方法一：令牌发放，服务端/客户端生成一个token（幂等键），给客户端用，客户端带着token前来请求，token是一次性的，用过就直接幂等 方法二：mysql的数据表里加一列幂等键，这个表一般是操作流水表，用来记操作。每次来请求的时候从流水表查幂等键存不存在，存在则直接幂等 方法三：redis里存幂等key，用setnx+幂等key+超时时间控制 其他要注意的： 如果接口要加锁，幂等判断是要被分布式锁锁住的。因为幂等的实现是要查数据库数据的话，是可能会有变化的 ","date":"0001-01-01","objectID":"/drafts/%E5%B9%82%E7%AD%89/:3:0","tags":null,"title":"","uri":"/drafts/%E5%B9%82%E7%AD%89/"},{"categories":["算法"],"content":"大数据算法MOOC内容实现","date":"0001-01-01","objectID":"/drafts/big_data_1/","tags":["算法"],"title":"[BigData]大数据算法","uri":"/drafts/big_data_1/"},{"categories":["算法"],"content":"水库抽样 ","date":"0001-01-01","objectID":"/drafts/big_data_1/:0:0","tags":["算法"],"title":"[BigData]大数据算法","uri":"/drafts/big_data_1/"},{"categories":["算法"],"content":"问题描述 Input：一组数据 Output：这组数据的K个均匀抽样 要求： 扫描一次 空间复杂度o(k) 扫描到前n个数字时，保存当前数据的均匀抽样 实现 收到第i个元素t时，以k/i的概率随机替换抽样数组ans[]中的元素 证明 均匀： $$\\frac{k}{i}\\times(1-\\frac{1}{i+1})\\times(1-\\frac{1}{i+2})\\times\\dots\\times(1-\\frac{1}{n})=\\frac{k}{n}$$ ","date":"0001-01-01","objectID":"/drafts/big_data_1/:1:0","tags":["算法"],"title":"[BigData]大数据算法","uri":"/drafts/big_data_1/"},{"categories":["算法"],"content":"实现代码 #include \u003ciostream\u003e #include \u003ccstdlib\u003e #include \u003cctime\u003e using namespace std; int random(int min ,int max) { return (min+(rand()%(max-min+1))); } int main() { srand(unsigned(time(0))); int k; int i; cout \u003c\u003c \"Input k:\" ; cin \u003e\u003e k; double *ans = new double[k+1]; double input; cout \u003c\u003c \"Input k numbers:\" \u003c\u003c endl; for(i = 1;i \u003c= k; ++i) { cin \u003e\u003e ans[i]; } cout \u003c\u003c \"Input stream numbers:(q to quit)\" \u003c\u003c endl; while(true) { int j = random(1,i); if(!(cin \u003e\u003e input)) break; if(j \u003c= k) ans[j] = input; //output cout \u003c\u003c \"Ans :\" ; for(int p = 1;p \u003c k; ++p) cout \u003c\u003c ans[p] \u003c\u003c \",\"; cout \u003c\u003c ans[k] \u003c\u003c endl; i++; } delete [] ans; return 0; } 平面图直径 ","date":"0001-01-01","objectID":"/drafts/big_data_1/:2:0","tags":["算法"],"title":"[BigData]大数据算法","uri":"/drafts/big_data_1/"},{"categories":["算法"],"content":"问题描述 Input：m个点的平面图，任意两点的距离储存在矩阵D中。 输入大小n = m^2 最大的$D_{ij}$为图的直径 点之间距离满足三角不等式 Output：该图的直径和距离最大的$D_{ij}$ 要求： 运行时间o(n) 实现 任意选择$k\\leq m$ 选择使得$D_{kl}$最大的l 输出$D_{kl}$和(k,l) 证明 近似比 $$D_{ij}\\leq D_{ik} + D_{kj}\\leq D_{kl} + D_{kl}\\leq 2D_{kl}$$ 运行时间 $O(m)=O(\\sqrt{n})=o(n)$ ","date":"0001-01-01","objectID":"/drafts/big_data_1/:3:0","tags":["算法"],"title":"[BigData]大数据算法","uri":"/drafts/big_data_1/"},{"categories":["算法"],"content":"代码实现 #include \u003ciostream\u003e #include \u003ccstdlib\u003e #include \u003cctime\u003e using namespace std; int random(int min ,int max) { return (min+(rand()%(max-min+1))); } int main() { srand(unsigned(time(0))); int m; cout \u003c\u003c \"Input m:\"; cin \u003e\u003e m; int **ans = new int * [m]; for(int i = 0; i \u003c m; ++i) { ans[i] = new int[m]; } cout \u003c\u003c \"Input martrix:\" \u003c\u003c endl; for(int i = 0; i \u003c m; ++i) { for(int j = 0;j \u003c m; ++j) { cin \u003e\u003e ans[i][j]; } } int line = random(0,m-1); int maxd = 0,maxi; for(int i = 0;i \u003c m; ++i) { if(ans[line][i] \u003e maxd) { maxd = ans[line][i]; maxi = i; } } cout \u003c\u003c \"MAX_D:\" \u003c\u003c maxd \u003c\u003c \", D_(i,j):(\" \u003c\u003c line \u003c\u003c \",\" \u003c\u003c maxi+1 \u003c\u003c\")\" \u003c\u003cendl; for(int i = 0; i \u003c m; ++i) { delete [] ans[m]; } delete [] ans; return 0; } ","date":"0001-01-01","objectID":"/drafts/big_data_1/:4:0","tags":["算法"],"title":"[BigData]大数据算法","uri":"/drafts/big_data_1/"}]