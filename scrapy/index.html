<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[Python]Scrapy Scan - 子恒的博客</title><meta name="Description" content="scrapy是个很简单强大的python爬虫框架，不需要处理网络相关逻辑就可以轻松爬取。本文介绍了一些基本的内容。"><meta property="og:title" content="[Python]Scrapy Scan" />
<meta property="og:description" content="scrapy是个很简单强大的python爬虫框架，不需要处理网络相关逻辑就可以轻松爬取。本文介绍了一些基本的内容。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://chestnutheng.github.io/scrapy/" /><meta property="og:image" content="http://chestnutheng.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-03-20T23:00:25+08:00" />
<meta property="article:modified_time" content="2019-03-20T23:00:30+08:00" /><meta property="og:site_name" content="子恒的博客" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://chestnutheng.github.io/logo.png"/>

<meta name="twitter:title" content="[Python]Scrapy Scan"/>
<meta name="twitter:description" content="scrapy是个很简单强大的python爬虫框架，不需要处理网络相关逻辑就可以轻松爬取。本文介绍了一些基本的内容。"/>
<meta name="application-name" content="我的网站">
<meta name="apple-mobile-web-app-title" content="我的网站"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://chestnutheng.github.io/scrapy/" /><link rel="prev" href="http://chestnutheng.github.io/rbtree/" /><link rel="next" href="http://chestnutheng.github.io/pthread/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[Python]Scrapy Scan",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/chestnutheng.github.io\/scrapy\/"
        },"genre": "posts","keywords": "Python, scrapy, 爬虫","wordcount":  715 ,
        "url": "http:\/\/chestnutheng.github.io\/scrapy\/","datePublished": "2019-03-20T23:00:25+08:00","dateModified": "2019-03-20T23:00:30+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "子恒"
            },"description": "scrapy是个很简单强大的python爬虫框架，不需要处理网络相关逻辑就可以轻松爬取。本文介绍了一些基本的内容。"
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="子恒的博客">子恒的博客</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/"> 主页 </a><a class="menu-item" href="/posts/"> 文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/freinds/"> 友链 </a><a class="menu-item" href="/about/"> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="子恒的博客">子恒的博客</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/" title="">主页</a><a class="menu-item" href="/posts/" title="">文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/freinds/" title="">友链</a><a class="menu-item" href="/about/" title="">关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content always-active" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[Python]Scrapy Scan</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="about" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>子恒</a></span>&nbsp;<span class="post-category">included in <a href="/categories/python/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Python</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2019-03-20">2019-03-20</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;715 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;4 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#安装scrapy">安装scrapy</a>
      <ul>
        <li><a href="#centos">CentOS</a></li>
      </ul>
    </li>
    <li><a href="#创建项目">创建项目</a></li>
    <li><a href="#shell测试代码">Shell：测试代码</a>
      <ul>
        <li><a href="#-调试您的spider">● 调试您的spider</a></li>
      </ul>
    </li>
    <li><a href="#选择器找到爬取的内容">选择器：找到爬取的内容</a>
      <ul>
        <li><a href="#-xpath-语法参考">● Xpath 语法参考</a></li>
        <li><a href="#-css-语法参考">● CSS 语法参考</a></li>
      </ul>
    </li>
    <li><a href="#item存储你爬取结果的桶">Item：存储你爬取结果的桶</a></li>
    <li><a href="#spider爬虫逻辑">Spider：爬虫逻辑</a></li>
    <li><a href="#pipeline处理item并输出">PipeLine：处理item并输出</a>
      <ul>
        <li><a href="#-feeds-export">● Feeds Export</a></li>
      </ul>
    </li>
    <li><a href="#高级特性">高级特性</a>
      <ul>
        <li><a href="#下载器中间件修改req和rsp的钩子">下载器中间件：修改req和rsp的钩子</a></li>
      </ul>
    </li>
    <li><a href="#最佳实践">最佳实践</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>scrapy是个很简单强大的python爬虫框架，不需要处理网络相关逻辑就可以轻松爬取。本文介绍了一些基本的内容。需要注意的是，本文档中所有的●表示非必须内容。<br>
本教程基于官方文档：<a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/settings.html" target="_blank" rel="noopener noreffer ">官方文档</a></p>
<h1 id="安装scrapy">安装scrapy</h1>
<h2 id="centos">CentOS</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yum install python34-devel.x86_64
</span></span><span class="line"><span class="cl">pip3 install scrapy
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="创建项目">创建项目</h1>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">//创建项目hello
</span></span><span class="line"><span class="cl">scrapy startproject hello
</span></span><span class="line"><span class="cl">//创建一个爬虫（在项目根目录运行，不要加http://），名字为baidu，域名为www.baidu.com
</span></span><span class="line"><span class="cl">scrapy genspider baidu &#34;www.baidu.com&#34;
</span></span></code></pre></td></tr></table>
</div>
</div><p>● 需要注意的是，如果要无视robots.txt文件，请在下面的<code>settings.py</code>中设置<code>ROBOTSTXT_OBEY = False</code><br>
● 刚才建好的项目目录文件树如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tree hello 
</span></span><span class="line"><span class="cl">hello
</span></span><span class="line"><span class="cl">|-- hello
</span></span><span class="line"><span class="cl">|   |-- __init__.py
</span></span><span class="line"><span class="cl">|   |-- items.py            // 输出结构体定义
</span></span><span class="line"><span class="cl">|   |-- middlewares.py
</span></span><span class="line"><span class="cl">|   |-- pipelines.py
</span></span><span class="line"><span class="cl">|   |-- __pycache__
</span></span><span class="line"><span class="cl">|   |-- settings.py         // 设置，记得把 ROBOTSTXT_OBEY = False
</span></span><span class="line"><span class="cl">|   |-- spiders
</span></span><span class="line"><span class="cl">|       |-- __init__.py
</span></span><span class="line"><span class="cl">|       |-- baidu.py        // 刚创建的爬虫
</span></span><span class="line"><span class="cl">|       |-- __pycache__
</span></span><span class="line"><span class="cl">|-- scrapy.cfg
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="shell测试代码">Shell：测试代码</h1>
<p>使用shell可以帮助实现爬虫的代码，查看网页的相关信息。结合浏览器中的审查元素查看会让你构造出需要选择的数据部分。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># 1. 在命令行中执行 scrapy shell 就可以进入shell。</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ● 下面改造了http头的USER_AGENT，一般可以防止请求因为USER_AGENT被拒绝</span>
</span></span><span class="line"><span class="cl"><span class="n">scrapy</span> <span class="n">shell</span> <span class="o">-</span><span class="n">s</span> <span class="n">USER_AGENT</span><span class="err">，</span><span class="o">=</span><span class="s2">&#34;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36-480&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 2. 进入shell后可用的对象：request、response、sel（选择器）、settings、spider、crawler</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 可用的函数 帮助shelp() 请求fetch(url) fetch(req) 浏览器打开view(rsp)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 3. 接下来可以拉取网页，下面是一些操作的实例:</span>
</span></span><span class="line"><span class="cl"><span class="n">fetch</span><span class="p">(</span><span class="s1">&#39;https://www.baidu.com&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 浏览器中打开爬取的网页</span>
</span></span><span class="line"><span class="cl"><span class="n">view</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 查看req和rsp</span>
</span></span><span class="line"><span class="cl"><span class="n">request</span><span class="o">.</span><span class="n">body</span>
</span></span><span class="line"><span class="cl"><span class="n">response</span><span class="o">.</span><span class="n">headers</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 选择网页中的元素</span>
</span></span><span class="line"><span class="cl"><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//title/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ● get 改为post</span>
</span></span><span class="line"><span class="cl"><span class="n">request</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&#34;POST&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="-调试您的spider">● 调试您的spider</h2>
<p>下面代码会在运行spider时，在这里进入shell调试。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scrapy.shell</span> <span class="kn">import</span> <span class="n">inspect_response</span>
</span></span><span class="line"><span class="cl"><span class="n">inspect_response</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="选择器找到爬取的内容">选择器：找到爬取的内容</h1>
<p>Scrapy选择器构建于 lxml 库之上，这意味着它们在速度和解析准确性上非常相似。选择器从如下的库中获取：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scrapy.http</span> <span class="kn">import</span> <span class="n">HtmlResponse</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 可以从rsp中构造，也可以 text=&#34;&lt;h&gt;&lt;/h&gt;&#34; 从字符串中构造</span>
</span></span><span class="line"><span class="cl"><span class="n">response</span> <span class="o">=</span> <span class="n">HtmlResponse</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s1">&#39;http://example.com&#39;</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span> <span class="c1"># [u&#39;good&#39;]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 幸运的是rsp提供了方法直接构造选择器：</span>
</span></span><span class="line"><span class="cl"><span class="n">response</span><span class="o">.</span><span class="n">selector</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 以及更短的快捷方式：</span>
</span></span><span class="line"><span class="cl"><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//title/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span> 
</span></span><span class="line"><span class="cl"><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>  
</span></span></code></pre></td></tr></table>
</div>
</div><p>● xpath和css是两种用来选择数据的工具，他们遵循不同的语法。但是他们都都返回一个selector对象。selector有几个成员函数很有用，他们是</p>
<ol>
<li>extract() 返回里面文字的值</li>
<li>re() 用正则过滤文字值，返回文字值</li>
<li>xpath() css() 返回的selector依然可以用这些工具，这意味着可以嵌套</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># 下面是一个从的img标签的text中获取括号内文字的方法</span>
</span></span><span class="line"><span class="cl"><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//a[contains(@href, &#34;image&#34;)]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Name:\s*(.*)&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 下面是用xpath的相对路径和选择器嵌套：</span>
</span></span><span class="line"><span class="cl"><span class="n">divs</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">divs</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;.//p&#39;</span><span class="p">):</span>    <span class="c1"># 父路径下的所有后代p</span>
</span></span><span class="line"><span class="cl">    <span class="o">...</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">divs</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">):</span>    <span class="c1"># 父路径下的所有直接</span>
</span></span><span class="line"><span class="cl">    <span class="o">...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="-xpath-语法参考">● Xpath 语法参考</h2>
<p><a href="http://www.w3school.com.cn/xpath/xpath_syntax.asp" target="_blank" rel="noopener noreffer ">w3s : Xpath语法参考</a><br>
Xpath是一种用于操作xml的选择器，可以快速操作想要的html标签。</p>
<table>
<thead>
<tr>
<th style="text-align:left">语法</th>
<th style="text-align:left">实例</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">a</td>
<td style="text-align:left">bookstore</td>
<td style="text-align:left">选取 bookstore 元素的所有子节点。</td>
</tr>
<tr>
<td style="text-align:left">/a</td>
<td style="text-align:left">/bookstore</td>
<td style="text-align:left">选取根元素 bookstore。</td>
</tr>
<tr>
<td style="text-align:left">a/b</td>
<td style="text-align:left">bookstore/book</td>
<td style="text-align:left">选取属于 bookstore 的子元素的所有 book 元素。</td>
</tr>
<tr>
<td style="text-align:left">//a</td>
<td style="text-align:left">//book</td>
<td style="text-align:left">选取所有 book 子元素，而不管它们在文档中的位置。</td>
</tr>
<tr>
<td style="text-align:left">a//b</td>
<td style="text-align:left">bookstore//book</td>
<td style="text-align:left">选择属于 bookstore 元素的后代的所有 book 元素，而不管它们位于 bookstore 之下的什么位置。</td>
</tr>
<tr>
<td style="text-align:left">@a</td>
<td style="text-align:left">//@lang</td>
<td style="text-align:left">选取名为 lang 的所有属性。</td>
</tr>
<tr>
<td style="text-align:left">*</td>
<td style="text-align:left">/bookstore/*</td>
<td style="text-align:left">选取 bookstore 元素的所有子元素。</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">//*</td>
<td style="text-align:left">选取文档中的所有元素。</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">//title[@*]</td>
<td style="text-align:left">选取所有带有属性的 title 元素。</td>
</tr>
</tbody>
</table>
<h2 id="-css-语法参考">● CSS 语法参考</h2>
<p><a href="http://www.w3school.com.cn/cssref/css_selectors.asp" target="_blank" rel="noopener noreffer ">w3s : CSS语法参考</a><br>
如果要操作一个类或者id而不是标签，CSS是最快的方法。</p>
<table>
<thead>
<tr>
<th style="text-align:left">例子</th>
<th style="text-align:left">例子描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">.intro</td>
<td style="text-align:left">选择 class=&ldquo;intro&rdquo; 的所有元素</td>
</tr>
<tr>
<td style="text-align:left">#firstname</td>
<td style="text-align:left">选择 id=&ldquo;firstname&rdquo; 的所有元素</td>
</tr>
<tr>
<td style="text-align:left">*</td>
<td style="text-align:left">选择所有元素</td>
</tr>
<tr>
<td style="text-align:left">p</td>
<td style="text-align:left">选择所有 p 元素</td>
</tr>
<tr>
<td style="text-align:left">div,p</td>
<td style="text-align:left">选择所有 div元素和所有 p 元素</td>
</tr>
<tr>
<td style="text-align:left">div p</td>
<td style="text-align:left">选择 div 元素内部的所有 p 元素</td>
</tr>
<tr>
<td style="text-align:left">div&gt;p</td>
<td style="text-align:left">选择父元素为 <div> 元素的所有 <p> 元素</td>
</tr>
<tr>
<td style="text-align:left">div+p</td>
<td style="text-align:left">选择紧接在 <div> 元素之后的所有 <p> 元素</td>
</tr>
<tr>
<td style="text-align:left">[target]</td>
<td style="text-align:left">选择带有 target 属性所有元素</td>
</tr>
<tr>
<td style="text-align:left">[target=_blank]</td>
<td style="text-align:left">选择 target=&quot;]_blank&quot; 的所有元素。</td>
</tr>
<tr>
<td style="text-align:left">[title~=flower]</td>
<td style="text-align:left">选择 title 属性包含单词 &ldquo;flower&rdquo; 的所有元素</td>
</tr>
<tr>
<td style="text-align:left">[lang|=en]</td>
<td style="text-align:left">选择 lang 属性值以 &ldquo;en&rdquo; 开头的所有元素</td>
</tr>
</tbody>
</table>
<h1 id="item存储你爬取结果的桶">Item：存储你爬取结果的桶</h1>
<p>好了，现在开始写爬虫。不过在这之前需要先定义好你想要爬下来的数据格式是怎么样的，待会把他们装进去。你需要修改<code>hello/items.py</code>，编写一个简单的类。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">HelloItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 用 scrapy.Field() 作为类型就可以了</span>
</span></span><span class="line"><span class="cl">    <span class="nb">id</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">description</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>● item和字典的API非常相似。可以使用get()、下标等读写item，甚至可以相互用对方初始化。</p>
<h1 id="spider爬虫逻辑">Spider：爬虫逻辑</h1>
<p>spider是爬取流程的主体。打开<code>hello/spiders/baidu.py</code>，编辑成员函数和成员变量：</p>
<ol>
<li><code>name</code> 爬虫的名字</li>
<li><code>allowed_domains</code> 只允许爬取<code>allowed_domains</code>的内容</li>
<li><code>start_urls</code> 运行时没指定url，就从这里开始爬</li>
<li><code>start_requests()</code> 可以重写这个来处理第一个<code>request</code>。否则，将会用<code>make_requests_from_url</code>爬url列表里的内容。</li>
<li><code>make_requests_from_url(url)</code> 可以重写这个来处理请求的发起。默认调用parse来处理rsp。</li>
<li><code>parse(rsp)</code> 处理rsp。需要返回item或者req的迭代对象作为输出和下一批爬取的内容，或者都返回。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">scrapy</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">hello.items</span> <span class="kn">import</span> <span class="n">HelloItem</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">scrapy</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">BaiduSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 创建爬虫时指定的名字</span>
</span></span><span class="line"><span class="cl">    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;baidu&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ● 设置中OffsiteMiddleware=True的时候，只允许爬取allowed_domains的内容</span>
</span></span><span class="line"><span class="cl">    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;baidu.com&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 爬取的目标链接</span>
</span></span><span class="line"><span class="cl">    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://www.baidu.com/&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># 用这个函数处理url的rsp</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">sel</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 选择所有的h3标题返回存储</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">h3</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//h3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="k">yield</span> <span class="n">HelloItem</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">h3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 返回链接继续爬取</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># ● 一个重写start_requests的样例，构造了req，并用logged_in函数处理rsp</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">FormRequest</span><span class="p">(</span><span class="s2">&#34;http://www.example.com/login&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                               <span class="n">formdata</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;user&#39;</span><span class="p">:</span> <span class="s1">&#39;john&#39;</span><span class="p">,</span> <span class="s1">&#39;pass&#39;</span><span class="p">:</span> <span class="s1">&#39;secret&#39;</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">                               <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">logged_in</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">logged_in</span><span class="p">(</span><span class="n">rsp</span><span class="p">):</span><span class="o">...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>写完后，在项目目录下运行scrapy crawl来运行spider：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">// 基础的运行
</span></span><span class="line"><span class="cl">scrapy crawl hello
</span></span><span class="line"><span class="cl">// 传递参数给myspider，并在构造函数中使用
</span></span><span class="line"><span class="cl">scrapy crawl myspider -a category=electronics
</span></span><span class="line"><span class="cl">class MySpider(Spider):
</span></span><span class="line"><span class="cl">    def __init__(self, category=None, *args, **kwargs):
</span></span><span class="line"><span class="cl">        super(MySpider, self).__init__(*args, **kwargs)
</span></span><span class="line"><span class="cl">        self.start_urls = [&#39;http://www.example.com/categories/%s&#39; % category]
</span></span><span class="line"><span class="cl">// 把爬到的item输出文件
</span></span><span class="line"><span class="cl">scrapy crawl dmoz -o items.json
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="pipeline处理item并输出">PipeLine：处理item并输出</h1>
<p>Pipeline提供了处理返回的item的几个函数。编辑<code>hello/pipeline.py</code>修改Pipeline的成员函数：</p>
<ol>
<li>process_item(item, spider) 每个item获取后都会用这个处理。这个函数会返回一个处理好的item。</li>
<li>open_spider(spider) 开启spider时被调用</li>
<li>close_spider(spider) 关闭spider时被调用</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># 下面是一个用id去重item的样例：</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DuplicatesPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">ids_seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ids_seen</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="n">DropItem</span><span class="p">(</span><span class="s2">&#34;Duplicate item found: </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">item</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">ids_seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">item</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scrapy.exporters</span> <span class="kn">import</span> <span class="n">CsvItemExporter</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 一个用导出器导出的样例：</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scrapy.exporters</span> <span class="kn">import</span> <span class="n">CsvItemExporter</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">ExportPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">open_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;test.csv&#34;</span><span class="p">,</span> <span class="s2">&#34;wb&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">exporter</span> <span class="o">=</span> <span class="n">CsvItemExporter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="p">,</span>       
</span></span><span class="line"><span class="cl">        <span class="n">fields_to_export</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;id&#34;</span><span class="p">,</span> <span class="s2">&#34;name&#34;</span><span class="p">,</span> <span class="s2">&#34;desc&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">exporter</span><span class="o">.</span><span class="n">start_exporting</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">exporter</span><span class="o">.</span><span class="n">export_item</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">item</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">close_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">exporter</span><span class="o">.</span><span class="n">finish_exporting</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>最后，修改<code>settings.py</code>中的<code>ITEM_PIPELINES</code>保证你的Pipeline生效。key表示路径，值表示执行的顺序。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;mybot.pipelines.validate.DuplicatesPipeline&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;mybot.pipelines.validate.ExportPipeline&#39;</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="-feeds-export">● Feeds Export</h2>
<p>序列化你的item结果有很多种方式：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">FEED_EXPORTERS_BASE</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;json&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.contrib.exporter.JsonItemExporter&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;jsonlines&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.contrib.exporter.JsonLinesItemExporter&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;csv&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.contrib.exporter.CsvItemExporter&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;xml&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.contrib.exporter.XmlItemExporter&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;marshal&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.contrib.exporter.MarshalItemExporter&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="高级特性">高级特性</h1>
<h2 id="下载器中间件修改req和rsp的钩子">下载器中间件：修改req和rsp的钩子</h2>
<p><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/downloader-middleware.html#topics-downloader-middleware-ref" target="_blank" rel="noopener noreffer ">官方文档：下载器中间件</a></p>
<h1 id="最佳实践">最佳实践</h1>
<p>下面是些处理这些站点的建议(tips):</p>
<ol>
<li>使用user agent池，轮流选择之一来作为user agent。池中包含常见的浏览器的user agent(google一下一大堆)</li>
<li>禁止cookies(参考 <a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/downloader-middleware.html#std:setting-COOKIES_ENABLED" target="_blank" rel="noopener noreffer ">COOKIES_ENABLED</a>)，有些站点会使用cookies来发现爬虫的轨迹。</li>
<li>设置下载延迟(2或更高)。参考 <a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/settings.html#std:setting-DOWNLOAD_DELAY" target="_blank" rel="noopener noreffer ">DOWNLOAD_DELAY</a> 设置。</li>
<li>如果可行，使用 Google cache 来爬取数据，而不是直接访问站点。</li>
<li>使用IP池。例如免费的 Tor项目 或付费服务(ProxyMesh)。</li>
<li>使用高度分布式的下载器(downloader)来绕过禁止(ban)，您就只需要专注分析处理页面。这样的例子有: Crawlera</li>
</ol>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2019-03-20</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/scrapy/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="http://chestnutheng.github.io/scrapy/" data-title="[Python]Scrapy Scan" data-hashtags="Python,scrapy,爬虫"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="http://chestnutheng.github.io/scrapy/" data-hashtag="Python"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="http://chestnutheng.github.io/scrapy/" data-title="[Python]Scrapy Scan"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="http://chestnutheng.github.io/scrapy/" data-title="[Python]Scrapy Scan"><i data-svg-src="/lib/simple-icons/icons/line.min.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="http://chestnutheng.github.io/scrapy/" data-title="[Python]Scrapy Scan" data-ralateuid="2461859532"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/python/"> Python</a>,&nbsp;<a href="/tags/scrapy/">scrapy</a>,&nbsp;<a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/rbtree/" class="prev" rel="prev" title="[数据结构]深入理解红黑树"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>[数据结构]深入理解红黑树</a>
            <a href="/pthread/" class="next" rel="next" title="[Linux]并行编程：进程、线程和同步">[Linux]并行编程：进程、线程和同步<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="giscus" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://giscus.app">Giscus</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.118.2">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2015 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="about" target="_blank">子恒</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/lightgallery/css/lightgallery-bundle.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lightgallery.min.js"></script><script type="text/javascript" src="/lib/lightgallery/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="/lib/lightgallery/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{"giscus":{"category":"Announcements","categoryId":"DIC_kwDOA9ikP84CQT5Y","darkTheme":"dark","emitMetadata":"0","inputPosition":"bottom","lang":"en","lazyLoading":true,"lightTheme":"light","mapping":"pathname","reactionsEnabled":"1","repo":"chestnutheng/chestnutheng.github.io","repoId":"MDEwOlJlcG9zaXRvcnk2NDUyOTQ3MQ=="}},"lightgallery":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":50,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
